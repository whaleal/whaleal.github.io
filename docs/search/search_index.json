{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"DocumentDataTransfer/","title":"Introduction to DDT (Document Data Transfer)","text":""},{"location":"DocumentDataTransfer/#part-1-ddt-overview","title":"Part 1: DDT Overview","text":"<p>DDT is a next-generation MongoDB database migration and synchronization tool developed by Shanghai Jinmu Information Technology Co., Ltd. (referred to as \"Jinmu Information\"). It is designed to meet various customer needs and leverages Jinmu Information's years of experience in MongoDB services and research and development.</p> <p>DDT is a versatile data transfer software developed in JAVA that offers high robustness, high transferability, and high availability. It allows for fast and stable data migration, helping users with tasks such as data backup, real-time migration, disaster recovery, and more. Users can also customize configuration parameters to achieve efficient data transfer for different scenarios.</p> <p>Given the limitations of the built-in primary-secondary synchronization in MongoDB replica sets for certain business scenarios, Jinmu Information developed the DDT synchronization tool. DDT can be used for instance-level, data center-level, and cross-data center replication, catering to disaster recovery and multi-active requirements.</p> <p>Traditional MongoDB data synchronization is limited to data transfers between similar architectures. However, DDT supports data transfers between three types of architectures: standalone nodes, replica sets, and sharded clusters. This flexibility enables data synchronization between different types of architectures, such as from a standalone node to a sharded cluster or from a sharded cluster to a standalone node.</p> <p>The core of DDT's real-time synchronization lies in its efficient parsing and application of the OPLOG log, allowing for high-performance and secure real-time synchronization. The source MongoDB can be a standalone instance, a replica set, or a sharded cluster, while the target can be a mongod or mongos instance. For replica sets, it's recommended to source data from secondary/hidden nodes to reduce the load on the primary node. For sharded clusters, each shard should connect to DDT.</p>"},{"location":"DocumentDataTransfer/#part-2-features","title":"Part 2: Features","text":"<p>DDT is characterized by its simplicity, security, versatility, multiple functionalities, and high performance.</p>"},{"location":"DocumentDataTransfer/#21-high-performance","title":"2.1 High Performance","text":""},{"location":"DocumentDataTransfer/#efficient-data-validation","title":"Efficient Data Validation","text":"<ul> <li>Ensures consistent data volume.</li> <li>Ensures consistent data information.</li> <li>Ensures consistent data indexes.</li> <li>Ensures consistent data structure.</li> </ul>"},{"location":"DocumentDataTransfer/#multiple-synchronization-scenarios","title":"Multiple Synchronization Scenarios","text":"<ul> <li>Full data replication.</li> <li>Real-time data synchronization.</li> <li>Incremental data synchronization.</li> <li>Customizable synchronization scope.</li> <li>Composite data synchronization scenarios.</li> </ul>"},{"location":"DocumentDataTransfer/#high-speed-synchronization-mechanism","title":"High-Speed Synchronization Mechanism","text":"<ul> <li>Utilizes 100% of available bandwidth.</li> <li>Controlled CPU utilization.</li> <li>Configurable memory usage.</li> <li>Supports parallel synchronization of multiple tables.</li> </ul>"},{"location":"DocumentDataTransfer/#compact-stable-and-efficient","title":"Compact, Stable, and Efficient","text":"<ul> <li>Compact in size.</li> <li>Supports seamless resume in case of interruption.</li> <li>Supports synchronization across multiple MongoDB versions.</li> </ul>"},{"location":"DocumentDataTransfer/#22-synchronization-modes","title":"2.2 Synchronization Modes","text":"<p>Synchronization Modes: Full, Real-time, Full and Incremental, Full and Real-time. Incremental synchronization refers to real-time synchronization with a specified time range for the Oplog.</p> <ul> <li> <p>Full Synchronization: Splits source MongoDB collections for querying, and multithreadedly writes the queried data into the target MongoDB collections. In this mode, higher resource availability generally leads to higher QPS.</p> </li> <li> <p>Real-time Synchronization: Replicates data from the source MongoDB to another MongoDB to create redundant copies. It captures the oplog from the source MongoDB and replays it in the target MongoDB.</p> </li> </ul>"},{"location":"DocumentDataTransfer/#23-resumable-transfer","title":"2.3 Resumable Transfer","text":"<p>In case of an unexpected source MongoDB shutdown, DDT can still synchronize data seamlessly upon restart. When DDT is unexpectedly closed, it can automatically resume from the last checkpoint and continue with the data transfer.</p>"},{"location":"DocumentDataTransfer/#24-multi-version-support","title":"2.4 Multi-Version Support","text":"<p>DDT currently supports MongoDB versions 3.2 to 6.0. It reliably supports the synchronization of tables and bucket collections in newer versions.</p>"},{"location":"DocumentDataTransfer/#25-ddl-operations","title":"2.5 DDL Operations","text":"<p>During real-time synchronization, users can customize the synchronization of certain DDL operations. Additionally, these DDL operations are recorded in logs for auditing purposes.</p>"},{"location":"DocumentDataTransfer/#26-oplog-delay","title":"2.6 Oplog Delay","text":"<p>Oplog delay synchronization allows for easy failover in case of issues.</p>"},{"location":"DocumentDataTransfer/#27-synchronization-scope","title":"2.7 Synchronization Scope","text":"<p>In real-time synchronization, users can set the start and end times for synchronizing the Oplog within a specified time range.</p> <p>There are additional features such as filtering the list of synchronized tables, data validation, and more.</p>"},{"location":"DocumentDataTransfer/#part-3-company-overview","title":"Part 3: Company Overview","text":"<p>Shanghai Jinmu Information Technology Co., Ltd. is a professional IT data consulting and service provider. The company is committed to delivering high-quality information products, consulting, and services to users. Established in 2015 in Shanghai, Jinmu Information has branches in Beijing, Shenzhen, and Guangzhou.</p> <p>Jinmu Information is a core partner for MongoDB in the Greater China region and a core partner for Akamai and Vonage in China. The company provides professional technical services, consulting, and application development to clients.</p> <p>As a technology-driven IT service provider prioritizing innovation and customer needs, Jinmu Information's products and services have gained recognition from leading domestic enterprises. The company has over 50 core clients and offers premium services and innovative product solutions in industries such as finance, insurance, securities, gaming, and e-commerce, covering mainland China and Hong Kong.</p> <p>Jinmu Information Website: www.jinmuinfo.com</p> <p>Consultation Email: support@jinmuinfo.com</p> <p>Contact Numbers: 021-58870038, 021-66696778</p>"},{"location":"DocumentDataTransfer/Install/Configuring/","title":"Configuring","text":""},{"location":"DocumentDataTransfer/Install/Configuring/#function-operation-instructions","title":"Function Operation Instructions","text":""},{"location":"DocumentDataTransfer/Install/Configuring/#1-parameter-meanings","title":"1. Parameter Meanings","text":"<p>When configuring a MongoDB data synchronization task, here is the detailed meaning of each parameter:</p> <ol> <li> <p>workName:</p> <ul> <li>Meaning: Task name</li> <li>Description: Used to identify the name of the data synchronization task. If not provided, it defaults to \"workNameDefault\".</li> </ul> </li> <li> <p>sourceDsUrl:</p> <ul> <li>Meaning: Source MongoDB connection URL</li> <li>Description: Specifies the connection URL of the source MongoDB database, which can be a single node, a replica set, or a sharded cluster.</li> </ul> </li> <li> <p>targetDsUrl:</p> <ul> <li>Meaning: Target MongoDB connection URL</li> <li>Description: Specifies the connection URL of the target MongoDB database, which can be a single node, a replica set, or a sharded cluster.</li> </ul> </li> <li> <p>syncMode:</p> <ul> <li>Meaning: Synchronization mode</li> <li>Description: Specifies the mode of data synchronization, which can be one of the following options:<ul> <li>\"all\": Full mode, sync all tables, excluding operations on source tables during synchronization.</li> <li>\"allAndRealTime\": Full plus real-time mode, performs full sync first and then starts real-time sync.</li> <li>\"allAndIncrement\": Full plus incremental mode, performs full sync first and then syncs only operations on source tables during synchronization.</li> <li>\"realTime\": Real-time mode, syncs based on configured start and end times.</li> </ul> </li> </ul> </li> <li> <p>realTimeType:</p> <ul> <li>Meaning: Real-time task type</li> <li>Description: Selects the type of real-time task, which can be \"oplog\" or \"changestream\".</li> <li>Additional Information:<ul> <li>\"oplog\": Uses MongoDB's oplog for real-time synchronization, suitable for source replica sets, supports DDL operations, and is faster.</li> <li>\"changestream\": Uses MongoDB's changestream for real-time synchronization, suitable for source replica sets or mongos, does not support DDL operations, and has moderate speed.</li> </ul> </li> </ul> </li> <li> <p>fullType:</p> <ul> <li>Meaning: Full task type</li> <li>Description: Selects the type of full task, which can be \"sync\" or \"reactive\".</li> <li>Additional Information:<ul> <li>\"sync\": Uses a stable transmission method for full synchronization.</li> <li>\"reactive\": Uses a faster transmission method for full synchronization.</li> </ul> </li> </ul> </li> <li> <p>dbTableWhite:</p> <ul> <li>Meaning: Tables to synchronize</li> <li>Description: Specifies tables to synchronize using regular expressions. For example, to sync all tables under the mongodb database: mongodb\\..+, the default is to sync all tables.</li> </ul> </li> <li> <p>ddlFilterSet:</p> <ul> <li>Meaning: DDL operations to synchronize</li> <li>Description: Specifies DDL operations to synchronize, separated by commas. The default is *, meaning sync all DDL operations.</li> </ul> </li> <li> <p>sourceThreadNum:</p> <ul> <li>Meaning: Source task thread number (full mode)</li> <li>Description: Specifies the number of threads to read source tasks in full synchronization.</li> </ul> </li> <li> <p>targetThreadNum:</p> <ul> <li>Meaning: Target task thread number (full mode)</li> <li>Description: Specifies the number of threads to write target tasks in full synchronization.</li> </ul> </li> </ol> <p>... (Continues with the rest of the parameter explanations)</p>"},{"location":"DocumentDataTransfer/Install/Configuring/#2-parameter-usage-scope","title":"2. Parameter Usage Scope","text":"<pre><code>| Parameter           | Real-Time Task | Full Task | Full + Increment Task | Full + Real-Time Task |\n|--------------------|--------------|----------|----------------------|-----------------------|\n| workName           | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| sourceDsUrl        | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| targetDsUrl        | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| syncMode           | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| realTimeType       | \u2714\ufe0f           |          | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| fullType           |              | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| dbTableWhite       | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| ddlFilterSet       | \u2714\ufe0f           |          | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| batchSize          | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| bucketNum          | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| bucketSize         | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| startOplogTime     | \u2714\ufe0f           |          |                      |                       |\n| endOplogTime       | \u2714\ufe0f           |          | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| delayTime          | \u2714\ufe0f           |          |                      |                       |\n| nsBucketThreadNum  | \u2714\ufe0f           |          |                      |                       |\n| writeThreadNum     | \u2714\ufe0f           |          |                      |                       |\n| ddlWait            | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| clusterInfoSet     | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n| bind_ip            | \u2714\ufe0f           | \u2714\ufe0f       | \u2714\ufe0f                   | \u2714\ufe0f                    |\n</code></pre>"},{"location":"DocumentDataTransfer/Install/Configuring/#3-data-validation","title":"3. Data Validation","text":"<pre><code># Data validation script\n# 0: Multi-threaded validation: Configure 1-8 validation methods after 0, which can be processed concurrently\n# 1: Estimate count validation for libraries and tables (may be inaccurate)\n# 2: Accurate count validation for libraries and tables\n# 3: Library and table dbHash validation (locks the library, use with caution)\n# 4: Validate 100 randomly selected data from libraries and tables, source side randomly selects 100 data, check if they exist on the target side\n# 5: Validate 100 data of each data type from libraries and tables, extract 100 data of each data type for _id (first 50 and last 50), check if they exist on the target side\n# 6: Check missing index information in libraries and tables\n# 7: Check missing index information in libraries and tables and create missing indexes\n# 8: Library dbHash validation (locks the library, use with caution)\n# 9: Output detailed validation log information. When not specified, the log only records abnormal validation information\n# Can be used in combination, e.g., 123456 123457 1237. If not specified, the default is combination 16\ncheckData=12456\n</code></pre>"},{"location":"DocumentDataTransfer/Install/Installation/","title":"Installation","text":""},{"location":"DocumentDataTransfer/Install/Installation/#installation-and-deployment","title":"Installation and Deployment","text":""},{"location":"DocumentDataTransfer/Install/Installation/#deploying-ddt-on-centos","title":"Deploying DDT on CentOS","text":""},{"location":"DocumentDataTransfer/Install/Installation/#jdk-installation","title":"JDK Installation","text":"<ol> <li>Download JDK 11 tgz package:</li> </ol> <pre><code>wget https://download.java.net/java/GA/jdk11/9/GPL/openjdk-11.0.9_linux-x64_bin.tar.gz\n</code></pre> <ol> <li>Extract the downloaded tar package:</li> </ol> <pre><code>tar -zxvf openjdk-11.0.9_linux-x64_bin.tar.gz\n</code></pre> <ol> <li>Move the extracted directory:</li> </ol> <pre><code>mv jdk-11.0.9 /usr/local/jdk11\n</code></pre> <ol> <li>Configure environment variables:</li> </ol> <pre><code>vi /etc/profile\nexport JAVA_HOME=/usr/local/jdk11\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib\nexport PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin\n</code></pre> <ol> <li>Refresh the environment:</li> </ol> <pre><code>source /etc/profile\n</code></pre> <ol> <li>Verify the installation:</li> </ol> <pre><code>java --version\n</code></pre>"},{"location":"DocumentDataTransfer/Install/Installation/#running-ddt","title":"Running DDT","text":""},{"location":"DocumentDataTransfer/Install/Installation/#prerequisites","title":"Prerequisites","text":"<p>Ensure that the installation and configuration files are in place and the Java environment is correctly set up before starting the DDT process.</p>"},{"location":"DocumentDataTransfer/Install/Installation/#starting-the-service","title":"Starting the Service","text":"<ol> <li>Navigate to the <code>bin</code> directory.</li> <li>Run the startup script: <code>./start-DDT.sh</code>. This starts the data transfer functionality.</li> <li>Run the startup script: <code>./start-monitor.sh</code>. This starts the web monitoring functionality.</li> </ol>"},{"location":"DocumentDataTransfer/Install/Installation/#stopping-the-service","title":"Stopping the Service","text":"<ol> <li>Navigate to the <code>bin</code> directory.</li> <li>Run the shutdown script: <code>./stop-DDT.sh</code>. This stops the data transfer functionality.</li> <li>Run the shutdown script: <code>./stop-monitor.sh</code>. This stops the web monitoring functionality.</li> </ol>"},{"location":"DocumentDataTransfer/Install/Installation/#ddt-features","title":"DDT Features","text":"<ol> <li>DDT supports full, real-time, full + incremental, and full + real-time synchronization modes. Incremental mode refers to real-time synchronization with a time range restriction on the Oplog.</li> <li>DDT currently supports MongoDB versions 3.2 to 6.0. Newer version features such as time-series tables and bucket tables are fully supported for synchronization.</li> <li>During real-time synchronization, users can customize the synchronization of specific DDL operations. Additionally, DDL operations are logged for auditing purposes.</li> </ol> <p>Currently, synchronizing data with the same version has no impact. When synchronizing from a higher version to a lower version, new types introduced in the higher version cannot be synchronized to the lower version. Similarly, when synchronizing from a lower version to a higher version, certain types removed in the higher version cannot be synchronized. For example, deleting an index in version 3.2 or adding a time-series table in version 5.0.</p>"},{"location":"DocumentDataTransfer/Install/QuickStart/","title":"QuickStart","text":""},{"location":"DocumentDataTransfer/Install/QuickStart/#quickstart","title":"QuickStart","text":""},{"location":"DocumentDataTransfer/Install/QuickStart/#startup-steps","title":"Startup Steps","text":""},{"location":"DocumentDataTransfer/Install/QuickStart/#1-download-ddt","title":"1. Download DDT","text":"<p>Visit https://github.com/whaleal/DocumentDataTransfer/releases</p> <p>Download the latest version of DDT.tar.gz.</p>"},{"location":"DocumentDataTransfer/Install/QuickStart/#2-extract","title":"2. Extract","text":"<pre><code>mkdir DDT\ntar -zxvf DDT.tar.gz -C DDT\n</code></pre>"},{"location":"DocumentDataTransfer/Install/QuickStart/#3-modify-configuration-files","title":"3. Modify Configuration Files","text":"<p>Introduction to Configuration</p> <pre><code>cd DDT/config\nvi DDT.properties\n</code></pre>"},{"location":"DocumentDataTransfer/Install/QuickStart/#4-prepare-to-start","title":"4. Prepare to Start","text":"<pre><code>cd bin\n./start-all.sh\n</code></pre>"},{"location":"DocumentDataTransfer/Install/QuickStart/#5-check-the-running-status","title":"5. Check the Running Status","text":"<p>Access the web monitoring page: http://bind_ip:58000/DDT_WEB/#/home</p>"},{"location":"DocumentDataTransfer/Install/QuickStart/#6-check-the-data-consistency-of-the-target","title":"6. Check the Data Consistency of the Target","text":"<ol> <li>Use the built-in validation tool of MongoDB (may lock the database):</li> </ol> <pre><code>use xxx\ndb.runCommand({ dbHash: 1 })\n</code></pre> <ol> <li>Manually validate the data:</li> </ol> <pre><code>java -jar checkData.jar /path/to/configuration/DDT.properties\n</code></pre> <p>Please replace <code>/path/to/configuration/DDT.properties</code> with the actual path to your DDT configuration file.</p>"},{"location":"DocumentDataTransfer/Install/Requirements/","title":"Requirements","text":""},{"location":"DocumentDataTransfer/Install/Requirements/#ddt-system-requirements","title":"DDT System Requirements","text":""},{"location":"DocumentDataTransfer/Install/Requirements/#hardware-requirements","title":"Hardware Requirements","text":"<ul> <li>Operating System: Linux distribution (such as Ubuntu, CentOS).</li> <li>Recommended Configuration: 8 cores, 16GB RAM.</li> <li>Storage Space: At least 100GB of available disk space.</li> <li>Network Adapter: Wired or wireless network adapter.</li> </ul>"},{"location":"DocumentDataTransfer/Install/Requirements/#network-requirements","title":"Network Requirements","text":""},{"location":"DocumentDataTransfer/Install/Requirements/#network-access-requirements","title":"Network Access Requirements","text":"<ul> <li>Bandwidth: Gigabit or Fast Ethernet.</li> <li>Network Policy: Configure network policies to allow connectivity between the source and target MongoDB instances.</li> </ul>"},{"location":"DocumentDataTransfer/Install/Requirements/#port-requirements","title":"Port Requirements","text":"<ul> <li>Open the specified ports (e.g., port 27017 for MongoDB communication, ports used by the program at startup, or custom ports for source and target MongoDB instances).</li> </ul>"},{"location":"DocumentDataTransfer/Install/Requirements/#software-requirements","title":"Software Requirements","text":""},{"location":"DocumentDataTransfer/Install/Requirements/#operating-system-requirements","title":"Operating System Requirements","text":"<ul> <li>Supported on Linux CentOS 7 and above.</li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/","title":"Introduction to DDT Architecture","text":""},{"location":"DocumentDataTransfer/Introduction/Architecture/#background","title":"Background","text":"<pre><code>The need for full migration and real-time synchronization of MongoDB databases led to the development of the new data migration project at our company, resulting in the DDT project.\n</code></pre>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#project-overview","title":"Project Overview","text":"<ul> <li>Name: DDT (Document Data Transfer)</li> <li>Language: Developed purely in Java</li> <li>Purpose: Full migration and real-time synchronization of MongoDB databases</li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#functionality-overview","title":"Functionality Overview","text":"<p>DDT is a MongoDB data synchronization component.</p> <p>Migration features include:</p>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#synchronization-modes","title":"Synchronization Modes","text":"<ul> <li> <p>Full Synchronization: Syncs all data in tables. Only data from tables existing before the program startup is synchronized.</p> </li> <li> <p>Real-time Synchronization: Real-time sync of oplogs (operation logs) generated by the source.</p> </li> <li> <p>Full + Incremental Synchronization: After full synchronization, only operations on source tables during the sync period are synchronized. The start time of real-time sync is the start time of full synchronization, and the end time of real-time sync is the end time of full synchronization.</p> </li> <li> <p>Full + Real-time Synchronization: After full synchronization, real-time sync begins. The start time of real-time sync is the start time of full synchronization.</p> </li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#additional-features","title":"Additional Features","text":"<ul> <li> <p>Delayed Synchronization: During real-time sync, the reading of oplogs can be delayed.</p> </li> <li> <p>Syncing DDL Operations: During real-time sync, users can customize the synchronization of certain DDL operations.</p> </li> <li> <p>Source Table Indexes: During full synchronization, users can specify whether to sync the source table indexes list after 60% of the total data is synced.</p> </li> <li> <p>Multi-Table Parallelism: During full synchronization, choose between synchronizing multiple source tables simultaneously or synchronizing them one by one.</p> </li> <li> <p>Sync Source Table List: Use regular expressions to specify the desired list of tables to sync.</p> </li> <li> <p>Time-Interval Real-time Sync: During real-time sync, you can set to sync oplogs within a certain time interval.</p> </li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#mongodb-versions","title":"MongoDB Versions","text":"<ul> <li>Supported Versions: DDT supports MongoDB versions 3.2, 3.4, 3.6, 4.0, 4.4, 5.0, and 6.0.</li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#architecture","title":"Architecture","text":"<p>Explanation:</p> <ul> <li>A JVM container corresponds to multiple instances, with each instance corresponding to a migration program.</li> <li>Each instance comprises three parts:   a. Source (extracts data from the source database, supports full/real-time implementation)   b. Cache (caches data from the source according to target requirements)   c. Target (updates data to the target database, supports full/real-time/comparison implementation)</li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#ddt-process-diagram","title":"DDT Process Diagram","text":""},{"location":"DocumentDataTransfer/Introduction/Architecture/#real-time-migration","title":"Real-Time Migration","text":"<p>Note:</p> <ul> <li>Use CAS mechanism to ensure that only one thread accesses each table's buckets at a time.</li> <li>Use CAS mechanism to ensure that only one thread writes data to a bucket of a table at a time.</li> <li>When splitting buckets for a table, if a DDL operation is encountered, the data before that DDL is written, followed by executing the DDL.</li> </ul>"},{"location":"DocumentDataTransfer/Introduction/Architecture/#full-migration","title":"Full Migration","text":"<p>Note:</p> <ul> <li>Use CAS mechanism to ensure that only one thread writes/reads bucket queues in the same partition at the same time.</li> <li>Data from a source table can be placed in any partition. A target table can retrieve data from any partition. However, only one thread can operate on a partition at a time.</li> </ul>"},{"location":"DocumentDataTransfer/Introduction/CustomerCase/","title":"CustomerCase","text":""},{"location":"DocumentDataTransfer/Introduction/CustomerCase/#ddt-application-scenarios","title":"DDT Application Scenarios","text":"<p>Let's introduce some use cases of users employing DDT, including business scenarios, durations, and performance comparisons.</p>"},{"location":"DocumentDataTransfer/Introduction/CustomerCase/#case-1-securities-company","title":"Case 1: Securities Company","text":"<p>Benefits of Disaster Recovery: In addition to local backups in the production center, business operations can also be backed up in the disaster recovery center. In a dual-active architecture, support for dual-center mutual backup enhances business resilience, providing a double insurance for the business. By utilizing the DDT synchronization tool, remote data is written to the target center in real time.</p>"},{"location":"DocumentDataTransfer/Introduction/CustomerCase/#case-2-airline-company","title":"Case 2: Airline Company","text":"<p>There is a need for a cross-major-version upgrade of a MongoDB replica set cluster, upgrading from version 3.2 to 4.4. Due to the need for rapid upgrade changes on the application side, the traditional MongoDB replica set would require step-by-step version upgrades, which is time-consuming. Also, in case of anomalies, the transition back to the correct state might not be timely.</p> <p>Our solution for the airline company is to set up a new 4.4 version database, using DDT to migrate old data to the new cluster in real time. When both new and old clusters have no delay, the application-side database address is switched.</p> <p>In this case, the original data size is 700GB, with a real-time data rate of 10,000 records per second, including intermittent DDL operations like table creation and deletion. DDT took a total of 6 hours to complete the transfer, with 5 hours for the full migration and 1 hour for real-time migration.</p>"},{"location":"DocumentDataTransfer/Usecase/FullTesting/","title":"DDT Full-scale Testing","text":""},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-environment","title":"Test Environment","text":"<p>Hardware Resources Configuration:</p> <ul> <li>CPU: 40 cores, Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz</li> <li>Memory: 4*32GB</li> <li>Network Card: 1Gbps</li> <li>Operating System: Linux x86_64</li> <li>MongoDB Version: 0.1</li> <li>Disk: SSD</li> </ul> <p>Test Conditions</p> <p>The test data covers the following dimensions: Latency, QPS (Queries Per Second), CPU Usage, Memory Usage. All values are provided as the average over 10 seconds.</p> <p>QPS is derived from log outputs on the data platform, with OPLOG write counts per second recorded. CPU and memory usage information is also provided.</p>"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-results","title":"Test Results","text":"<pre><code>When cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128:\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-one","title":"Test One","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GBTarget MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each OPLOG document is around 140 bytes Source Read Threads 5 Target Write Threads 15 Cache Settings cacheBucketSize=32cacheBucketNum=32dataBatchSize=128 <p>Test Results:</p> Measurement Description QPS 145062 CPU Usage 400% Memory Usage 13631MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-two","title":"Test Two","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GBTarget MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 6 Target Write Threads 20 Cache Settings cacheBucketSize=32cacheBucketNum=32dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 160837 CPU Usage 440% Memory Usage 16384MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-three","title":"Test Three","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GBTarget MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 6 Target Write Threads 24 Cache Settings cacheBucketSize=32cacheBucketNum=32dataBatchSize=128 <p>Test Results</p> Description Measurement QPS 155232 CPU Usage 440% Memory Usage 15860MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#summary","title":"Summary","text":"Cache Settings cacheSize Source Read Threads Target Write Threads QPS Memory Usage CPU Usage cacheBucketSize=32 cacheBucketNum=32 dataBatchSize=128 30GB 5 15 145062 13631MB 400% 6 20 160837 16384MB 440% 6 24 155232 15860MB 440% <p>Summary: When cacheBucketSize=32, cacheBucketNum=32, and dataBatchSize=128, it can be observed that increasing the number of threads:</p> <p>(1) Does not improve QPS, as the read volume is lower than the write volume;</p> <p>(2) Does not increase memory usage significantly due to cache size limitations.</p> <pre><code>When cacheBucketSize=48, cacheBucketNum=48, and dataBatchSize=128:\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-one_1","title":"Test One","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 5 Target Write Threads 15 Cache Settings cacheBucketSize=48 cacheBucketNum=48 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 315702 CPU Usage 400% Memory Usage 31326MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-two_1","title":"Test Two","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 6 Target Write Threads 20 Cache Settings cacheBucketSize=48 cacheBucketNum=48 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 340716 CPU Usage 800% Memory Usage 24773MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-three_1","title":"Test Three","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 6 Target Write Threads 24 Cache Settings cacheBucketSize=48 cacheBucketNum=48 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 367178 CPU Usage 880% Memory Usage 23986MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-four","title":"Test Four","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 8 Target Write Threads 24 Cache Settings cacheBucketSize=48 cacheBucketNum=48 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 371528 CPU Usage 1120% Memory Usage 27132MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#summary_1","title":"Summary","text":"Cache Settings cacheSize Source Read Threads Target Write Threads QPS Memory Usage CPU Usage cacheBucketSize=48 cacheBucketNum=48 dataBatchSize=128 30GB 5 15 315702 31326MB 400% 6 20 340716 24773MB 800% 6 24 367178 23986MB 880% 8 24 371528 27132MB 1120% <p>Summary: When cacheBucketSize=48, cacheBucketNum=48, and dataBatchSize=128, it can be observed that increasing the number of threads:</p> <p>(1) Increases QPS.</p> <pre><code>When cacheBucketSize=64, cacheBucketNum=64, and dataBatchSize=128:\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-one_2","title":"Test One","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 5 Target Write Threads 15 Cache Settings cacheBucketSize=64 cacheBucketNum=64 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 370042 CPU Usage 812% Memory Usage 25159MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-two_2","title":"Test Two","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 6 Target Write Threads 20 Cache Settings cacheBucketSize=64 cacheBucketNum=64 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 390000 CPU Usage 1080% Memory Usage 26522MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-three_2","title":"Test Three","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 6 Target Write Threads 24 Cache Settings cacheBucketSize=64 cacheBucketNum=64 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 400138 CPU Usage 1160% Memory Usage 26655MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#test-four_1","title":"Test Four","text":"<p>Configuration Information</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize 30GB; Target MongoDB: Single-node replica set, cacheSize 30GB Data Volume One database with 10 collections, each document has 7 columns, total size of each document is around 140 bytes Source Read Threads 8 Target Write Threads 24 Cache Settings cacheBucketSize=64 cacheBucketNum=64 dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 360209 CPU Usage 1120% Memory Usage 25252MB"},{"location":"DocumentDataTransfer/Usecase/FullTesting/#summary_2","title":"Summary:","text":"Cache Settings cacheSize Source Read Threads Target Write Threads QPS Memory Usage CPU Usage cacheBucketSize=64 cacheBucketNum=64 dataBatchSize=128 30GB 5 15 370042 25159MB 812% 6 20 390000 26522MB 1080% 6 24 400138 26655MB 1160% 8 24 360209 25252MB 1120% <p>Summary:</p> <p>(1) CPU and QPS:</p> <p></p> <p>(2) Memory Usage and QPS:</p> <p></p>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/","title":"Full Data Transfer","text":""},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#1-start-preparation","title":"1. Start Preparation","text":"<pre><code>use photon\nCreate ten tables. Each table has no indexes other than _id.\nInsert approximately 50 million records into each table.\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#2-source-side-data-insertion","title":"2. Source-side Data Insertion","text":"<pre><code>Single record:\n{\n    \"_id\": ObjectId(\"61bad4f68a27d20b123ed7e8\"),\n    \"BsonTimestamp1\": Timestamp(1639634166, 78),\n    \"String\": \"str\",\n    \"Doc\": {\n        \"1\": 1\n    },\n    \"javaInt\": 71916,\n    \"bytes\": BinData(0, \"AQ==\"),\n    \"Array\": [],\n    \"Binary data\": BinData(0, \"AQID\"),\n    \"ObjectId\": ObjectId(\"61bad4f68a27d20b123ed7e6\"),\n    \"Boolean\": false,\n    \"Date\": ISODate(\"2021-12-16T05:56:06.688Z\"),\n    \"Null\": null,\n    \"Regular Expression\": /lhp.*/,\n    \"DBPointer\": DBPointer(\"1\", ObjectId(\"61bad4f68a27d20b123ed7e7\")),\n    \"Undefined\": undefined,\n    \"JavaScript\": {\n        \"code\": \"var i=0\"\n    },\n    \"Symbol\": \"var i=0\",\n    \"BsonStr\": \"var i=0\",\n    \"BsonJavaScriptWithScope\": {\n        \"code\": \"var i=0\",\n        \"scope\": {}\n    },\n    \"32integer\": 12,\n    \"Timestamp\": ISODate(\"2021-12-16T05:56:06.688Z\"),\n    \"64int\": NumberLong(123),\n    \"Min key\": { \"$minKey\": 1 },\n    \"Max key\": { \"$maxKey\": 1 },\n    \"BsonTimestamp\": Timestamp(1639634166, 457)\n}\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#3-source-side-data-volume-calculation","title":"3. Source-side Data Volume Calculation","text":"<pre><code>show dbs;\nDisk usage on source: photon 35.885GB\ndb.stats()\n{\n    \"db\": \"photon\",\n    \"collections\": 10,\n    \"views\": 0,\n    \"objects\": 474281344, // Estimated total number of records\n    \"avgObjSize\": 132.06465577958498, // Average size per record in bytes\n    \"dataSize\": 57890360946,\n    \"storageSize\": 14807171072,\n    \"freeStorageSize\": 4571136,\n    \"indexes\": 20,\n    \"indexSize\": 23723704320,\n    \"indexFreeStorageSize\": 14454784,\n    \"totalSize\": 38530875392,\n    \"totalFreeStorageSize\": 19025920,\n    \"scaleFactor\": 1,\n    \"fsUsedSize\": 587772825600,\n    \"fsTotalSize\": 11939478503424,\n    \"ok\": 1,\n    \"$clusterTime\": {\n        \"clusterTime\": Timestamp(1640065750, 1),\n        \"signature\": {\n            \"hash\": BinData(0, \"v3ySiE7Zub+VPOJpQ/K3IaCJBxM=\"),\n            \"keyId\": NumberLong(\"7025843880893349893\")\n        }\n    },\n    \"operationTime\": Timestamp(1640065750, 1)\n}\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#4-start-ddt","title":"4. Start DDT","text":"<p>Refer to QuickStart</p> <p>Test environment using the following parameters:</p> <pre><code># DDT.properties Configuration File\n# Task name. If not specified, defaults to workNameDefault.\nworkName = mongoTask\n# Source-side MongoDB URL, required. Can be a URL for a single node, replica set, or sharded cluster.\nsourceDsUrl = mongodb://192.168.12.200:24578\n# sourceDsUrl = mongodb://192.168.12.100:3999\n# Target-side MongoDB URL, required. Can be a URL for a single node, replica set, or sharded cluster.\ntargetDsUrl = mongodb://192.168.12.100:24578\n# Synchronization mode, default is all.\n# all: Full data transfer, synchronizes tables while ignoring operations on the source during synchronization.\nsyncMode = all\n# During full data transfer, choose between sync or reactive.\n# sync: Stable data transfer.\n# reactive: Faster data transfer.\nfullType = reactive\n# Tables to be synchronized, using regular expressions. Default is to synchronize all tables: .+\ndbTableWhite = .+\n# Number of threads for reading source data during full data transfer, minimum is 2, maximum is 100. Default is system-calculated value.\nsourceThreadNum = 10\n# Number of threads for writing data to the target during full data transfer, minimum is 4, maximum is 100. Default is system-calculated value. It's recommended that targetThreadNum is three times sourceThreadNum.\ntargetThreadNum = 20\n# Number of threads for concurrent index creation during full data transfer, minimum is 1, maximum is 100. Default is system-calculated value.\ncreateIndexThreadNum = 15\n# The following three parameters, bucketSize, bucketNum, and batchSize, collectively determine the number of data records cached in memory during full data transfer. Be cautious about potential memory overflow.\n# Default batchSize is 128.\nbatchSize = 128\n# Default bucketNum is 20.\nbucketNum = 20\n# Default bucketSize is 20.\nbucketSize = 20\n# Maximum time allowed for each DDL operation during synchronization, in seconds.\nddlWait = 1200\n# During full data transfer:\n# Before data transmission, pre-process: synchronize DDL information in the cluster.\n# 0: Whether to delete existing tables on the target.\n# 1: Print all user information in the cluster.\n# 2: Synchronize table structure.\n# 3: Synchronize table index information.\n# 4: Enable sharding for all databases.\n# 5: Synchronize shard key for tables.\n# 6: Synchronize config.setting table.\n# 7: Pre-split chunk for tables.\n# Combine numbers using commas. For example: 1,2,3,4,5,6.\nclusterInfoSet = 0,1,2,3,4,5,6,7\n# When monitor is enabled, configure the IP address of the local machine.\nbind_ip = 192.168.12.190\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#real-time","title":"Real-time","text":""},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#1-start-ddt","title":"1. Start DDT","text":"<p>Refer to QuickStart</p> <p>Test environment using the following parameters:</p> <pre><code># DDT.properties Configuration File\n# Task name. If not specified, defaults to workNameDefault.\nworkName = mongoTask\n# Source-side MongoDB URL, required. Can be a URL for a single node, replica set, or sharded cluster.\nsourceDsUrl = mongodb://192.168.12.200:24578\n# sourceDsUrl = mongodb://192.168.12.100:3999\n# Target-side MongoDB URL, required. Can be a URL for a single node, replica set, or sharded cluster.\ntargetDsUrl = mongodb://\n\n192.168.12.100:24578\n# Synchronization mode, default is all.\n# realTime: Real-time synchronization. startOplogTime and endOplogTime can be configured.\nsyncMode = realTime\n# Choose between oplog and changestream for real-time or incremental tasks.\n# Choose oplog for advantages such as faster synchronization speed when the source is a replica set and support for DDL operations.\n# Choose changestream for sources that are replica sets or mongos, but it doesn't support DDL operations and is generally slower.\nrealTimeType = changestream\n# Tables to be synchronized, using regular expressions. Default is to synchronize all tables: .+\ndbTableWhite = .+\n# In real-time synchronization, you can specify which DDL operations to synchronize: drop, create, createIndexes, dropIndexes, renameCollection, convertToCapped, dropDatabase, modify, shardCollection.\n# Default is *, which means all DDL operations are synchronized.\nddlFilterSet = *\n# The following three parameters, bucketSize, bucketNum, and batchSize, collectively determine the number of data records cached in memory during real-time synchronization. Be cautious about potential memory overflow.\n# Default batchSize is 128.\nbatchSize = 128\n# Default bucketNum is 20.\nbucketNum = 20\n# Default bucketSize is 20.\nbucketSize = 20\n# When using real-time synchronization, set the start time to read oplog. Default is the 10-digit timestamp when the program starts.\nstartOplogTime = 1692843646\n# When using real-time synchronization, set the end time to read oplog. Default is 0, meaning no end time. Use a 10-digit timestamp if needed.\nendOplogTime = 1692847246\n# When using real-time synchronization, set the delay time for reading oplog. Default is 0, meaning no delay time.\ndelayTime = 0\n# Number of threads for parsing namespaces (buckets) during real-time synchronization. Minimum is 8, maximum is 100. Default is system-calculated value.\nnsBucketThreadNum = 15\n# Number of threads for writing data during real-time synchronization. Minimum is 8, maximum is 100. Default is system-calculated value.\nwriteThreadNum = 15\n# Maximum time allowed for each DDL operation during synchronization, in seconds.\nddlWait = 1200\n# When monitor is enabled, configure the IP address of the local machine.\nbind_ip = 192.168.12.190\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#2-source-side-data-insertion_1","title":"2. Source-side Data Insertion","text":"<pre><code>Use the source-side script for CRUD operations.\nThe script performs CRUD operations on 10 tables.\nSingle insert data model:\n{\n    \"_id\": ObjectId(\"61bad4f68a27d20b123ed7e8\"),\n    \"BsonTimestamp1\": Timestamp(1639634166, 78),\n    \"String\": \"str\",\n    \"Doc\": {\n        \"1\": 1\n    },\n    \"javaInt\": 71916,\n    \"bytes\": BinData(0, \"AQ==\"),\n    \"Array\": [],\n    \"Binary data\": BinData(0, \"AQID\"),\n    \"ObjectId\": ObjectId(\"61bad4f68a27d20b123ed7e6\"),\n    \"Boolean\": false,\n    \"Date\": ISODate(\"2021-12-16T05:56:06.688Z\"),\n    \"Null\": null,\n    \"Regular Expression\": /lhp.*/,\n    \"DBPointer\": DBPointer(\"1\", ObjectId(\"61bad4f68a27d20b123ed7e7\")),\n    \"Undefined\": undefined,\n    \"JavaScript\": {\n        \"code\": \"var i=0\"\n    },\n    \"Symbol\": \"var i=0\",\n    \"BsonStr\": \"var i=0\",\n    \"BsonJavaScriptWithScope\": {\n        \"code\": \"var i=0\",\n        \"scope\": {}\n    },\n    \"32integer\": 12,\n    \"Timestamp\": ISODate(\"2021-12-16T05:56:06.688Z\"),\n    \"64int\": NumberLong(123),\n    \"Min key\": { \"$minKey\": 1 },\n    \"Max key\": { \"$maxKey\": 1 },\n    \"BsonTimestamp\": Timestamp(1639634166, 457)\n}\nSource-side CRUD concurrency is 100,000/s.\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/FunctionalTest/#3-conclusion","title":"3. Conclusion","text":"<p>During real-time synchronization, the source-side CRUD concurrency is 100,000/s.</p> <p>The target-side executes an average of 58,000 data records per second.</p> <p>When the data volume of source-side CRUD operations is large, it may cause DDT to be unable to synchronize the source oplog in a timely manner. Observe the 'Reading oplog delay xxxs' data and avoid missing the sliding window time for reading oplog.</p>"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/","title":"DDT Real-time Testing","text":""},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-environment","title":"Test Environment","text":"<p>Hardware Configuration:</p> <ul> <li>CPU: 40 cores, Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz</li> <li>Memory: 4*32GB</li> <li>Network Card: 1Gbps</li> <li>Operating System: Linux x86_64</li> <li>MongoDB Version: 0.1</li> <li>Disk: SSD</li> </ul> <p>Test Conditions</p> <p>The test data covers the following dimensions: Latency, QPS (Queries Per Second), CPU Usage, Memory Usage. All values are given as the average over a 10-second period.</p> <p>QPS is obtained from the data platform's log output, which counts the number of OPLOG writes per second. We also provide CPU and memory usage information.</p>"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-results","title":"Test Results","text":"<pre><code>When cacheBucketSize=16, cacheBucketNum=16, dataBatchSize=128:\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-1","title":"Test 1","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=6, oplogRead=1, oplogNsBucket=2} Cache Area cacheBucketSize=16, cacheBucketNum=16, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 72398 CPU Usage 280% Memory Usage 8258MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-2","title":"Test 2","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=9, oplogRead=1, oplogNsBucket=3} Cache Area cacheBucketSize=16, cacheBucketNum=16, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 80385 CPU Usage 240% Memory Usage 14418MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-3","title":"Test 3","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=12, oplogRead=1, oplogNsBucket=4} Cache Area cacheBucketSize=16, cacheBucketNum=16, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 79365 CPU Usage 280% Memory Usage 15728MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-4","title":"Test 4","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=15, oplogRead=1, oplogNsBucket=5} Cache Area cacheBucketSize=16, cacheBucketNum=16, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 75388 CPU Usage 280% Memory Usage 14025MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#summary","title":"Summary","text":"Cache Area oplogNS oplogWrite oplogRead oplogNsBucket QPS CPU Usage Memory Usage cacheBucketSize=16 cacheBucketNum=16 dataBatchSize=128 1 6 1 2 72398 280% 8258MB 1 9 1 3 80385 240% 14418MB 1 12 1 4 79365 280% 15728MB 1 15 1 5 75388 280% 14025MB <p>Summary: When cacheBucketSize=16, cacheBucketNum=16, dataBatchSize=128, it can be observed that increasing the number of threads does not increase QPS, due to the limitation of the cache area size.</p> <pre><code>When cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128:\n</code></pre>"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-1_1","title":"Test 1","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with <p>10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes | | Real-time Sync Threads   | {oplogNS=1, oplogWrite=6, oplogRead=1, oplogNsBucket=2} | | Cache Area               | cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128 |</p> <p>Test Results</p> Measurement Description QPS 87719 CPU Usage 240% Memory Usage 13107MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-2_1","title":"Test 2","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=9, oplogRead=1, oplogNsBucket=3} Cache Area cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 100000 CPU Usage 320% Memory Usage 11534MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-3_1","title":"Test 3","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=12, oplogRead=1, oplogNsBucket=4} Cache Area cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 112370 CPU Usage 320% Memory Usage 11796MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#test-4_1","title":"Test 4","text":"<p>Configuration</p> Parameter Description MongoDB Type Source MongoDB: Single-node replica set, cacheSize30GB  Target MongoDB: Single-node replica set, cacheSize30GB Data Volume One database with 10 collections, each document contains 7 columns, and the total size of each document is approximately 140 bytes Real-time Sync Threads {oplogNS=1, oplogWrite=15, oplogRead=1, oplogNsBucket=5} Cache Area cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128 <p>Test Results</p> Measurement Description QPS 120030 CPU Usage 360% Memory Usage 12845MB"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#summary_1","title":"Summary","text":"Cache Area oplogNS oplogWrite oplogRead oplogNsBucket QPS CPU Usage Memory Usage cacheBucketSize=32 cacheBucketNum=32 dataBatchSize=128 1 6 1 2 87719 240% 13107MB 1 9 1 3 100000 320% 11534MB 1 12 1 4 112370 320% 11796MB 1 15 1 5 120030 360% 12845MB <p>Summary: When cacheBucketSize=32, cacheBucketNum=32, dataBatchSize=128, it can be observed that increasing the number of threads increases QPS, due to the limitation of the Oplog read rate.</p>"},{"location":"DocumentDataTransfer/Usecase/RealTimeTest/#conclusion","title":"Conclusion:","text":"<p>(1) CPU vs. QPS:</p> <p></p> <p>(2) Memory Usage vs. QPS:</p> <p></p> <p>Make the necessary translation adjustments and ensure that the formatting and image paths are not modified.</p>"},{"location":"DocumentDataTransfer/Usecase/mongo%E5%90%84%E7%89%88%E6%9C%AC%E5%BD%B1%E5%93%8D/","title":"Mongo\u5404\u7248\u672c\u5f71\u54cd","text":""},{"location":"DocumentDataTransfer/Usecase/mongo%E5%90%84%E7%89%88%E6%9C%AC%E5%BD%B1%E5%93%8D/#mongo","title":"mongo\u5404\u7248\u672c\u95f4\u540c\u6b65\u5f71\u54cd","text":""},{"location":"Support/","title":"Support","text":"<p>whaleal</p>"},{"location":"WhalealPlatform/","title":"Whaleal Architecture","text":"<p>Whaleal Platform (WAP) is an intelligent operation, maintenance and hosting platform that provides real-time monitoring and management of your MongoDB services 7*24 hours a day.</p> <p></p> <p>As an open source MongoDB database monitoring solution, WAP provides instant troubleshooting and diagnostic capabilities to ensure the continued stable operation of your MongoDB database and increase productivity. At the same time, WAP also supports automatic backup and recovery, providing you with comprehensive data protection to ensure data security and reliability. </p> <p>By choosing WAP, you will experience the convenience and efficiency of intelligent operation and maintenance.</p>"},{"location":"WhalealPlatform/#whaleal-application","title":"Whaleal Application","text":"<p>The Whaleal application provides a user interface and a MongoDB agent for HTTP services to transfer data to and from Whaleal. These are stateless and automatically start when the Whaleal application is launched.</p> <p>By default, the Whaleal Web application runs on port 80, the Whaleal backend interface runs on port 8080, and the Whaleal initialization boot page runs on port 9599.</p> <p>For a list of default ports and health check endpoints for Whaleal, please refer to the firewall configuration.</p>"},{"location":"WhalealPlatform/#whaleal-backup","title":"Whaleal Backup","text":"<p>Whaleal performs MongoDB database backup through DDT or DUMP.</p> <p>For information on how to start, check status, stop, and restart the MongoDB backup process, refer to Starting and Stopping MongoDB Backup.</p> <p>Regarding DDT's support for MongoDB versions, it covers versions 5.0 - 7.0.</p>"},{"location":"WhalealPlatform/#dedicated-storage-for-operational-data","title":"Dedicated Storage for Operational Data","text":""},{"location":"WhalealPlatform/#whaleal-application-database","title":"Whaleal Application Database","text":"<p>Whaleal uses a dedicated MongoDB to store operational data. The application database should run as a replica set to ensure redundancy and high availability. This replica set is only used to store Whaleal data. Before installing Whaleal, you must first install and configure the application database. This database contains metadata for the Whaleal application.</p> <ul> <li> <p>MongoDB monitoring data collected from agents.</p> </li> <li> <p>Metadata for Whaleal users, projects, hosts, monitoring data, and backup data.</p> </li> </ul>"},{"location":"WhalealPlatform/#snapshot-storage","title":"Snapshot Storage","text":"<p>Whaleal creates deployment snapshots to back up the MongoDB database. You can store these snapshots in snapshot storage. The snapshot store is S3. Each project can have multiple snapshot stores. And Whaleal records the newly generated Oplog into a separate database.</p>"},{"location":"WhalealPlatform/03-Projects/","title":"Projects","text":"<p>All server resources and MongoDB resource management on the platform are based on Project. </p> <p>When new resources are added to the platform, Project must be allocated before they can be operated and managed through the platform. Resources between different Projects are isolated from each other. </p> <p>Server resources and MongoDB resources do not allow resource configuration across projects, but users can manage multiple Projects. </p> <p>All user rights isolation is also based on Project.</p> <p></p> <p>The platform has two projects by default: DDT and public.</p> <ul> <li>DDT: Resource management used for backup processes.</li> <li>public: Used for public resource management. New users are assigned to this Project by default.</li> </ul>"},{"location":"WhalealPlatform/01-WhalealOverview/01-WhalealArchitecture/","title":"Whaleal Architecture","text":"<p>Whaleal Platform (WAP) is an intelligent operation, maintenance and hosting platform that provides real-time monitoring and management of your MongoDB services 7*24 hours a day.</p> <p></p> <p>As an open source MongoDB database monitoring solution, WAP provides instant troubleshooting and diagnostic capabilities to ensure the continued stable operation of your MongoDB database and increase productivity. At the same time, WAP also supports automatic backup and recovery, providing you with comprehensive data protection to ensure data security and reliability. </p> <p>By choosing WAP, you will experience the convenience and efficiency of intelligent operation and maintenance.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/01-WhalealArchitecture/#whaleal-application","title":"Whaleal Application","text":"<p>The Whaleal application provides a user interface and a MongoDB agent for HTTP services to transfer data to and from Whaleal. These are stateless and automatically start when the Whaleal application is launched.</p> <p>By default, the Whaleal Web application runs on port 80, the Whaleal backend interface runs on port 8080, and the Whaleal initialization boot page runs on port 9599.</p> <p>For a list of default ports and health check endpoints for Whaleal, please refer to the firewall configuration.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/01-WhalealArchitecture/#whaleal-backup","title":"Whaleal Backup","text":"<p>Whaleal performs MongoDB database backup through DDT or DUMP.</p> <p>For information on how to start, check status, stop, and restart the MongoDB backup process, refer to Starting and Stopping MongoDB Backup.</p> <p>Regarding DDT's support for MongoDB versions, it covers versions 5.0 - 7.0.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/01-WhalealArchitecture/#dedicated-storage-for-operational-data","title":"Dedicated Storage for Operational Data","text":""},{"location":"WhalealPlatform/01-WhalealOverview/01-WhalealArchitecture/#whaleal-application-database","title":"Whaleal Application Database","text":"<p>Whaleal uses a dedicated MongoDB to store operational data. The application database should run as a replica set to ensure redundancy and high availability. This replica set is only used to store Whaleal data. Before installing Whaleal, you must first install and configure the application database. This database contains metadata for the Whaleal application.</p> <ul> <li> <p>MongoDB monitoring data collected from agents.</p> </li> <li> <p>Metadata for Whaleal users, projects, hosts, monitoring data, and backup data.</p> </li> </ul>"},{"location":"WhalealPlatform/01-WhalealOverview/02-ExampleDeployment/","title":"Example Deployment","text":"<p>Below is a description of deploying Whaleal and MongoDB in different environments.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/02-ExampleDeployment/#test-install-on-a-single-host","title":"Test Install on a Single Host","text":"<p>For a test deployment, you can deploy all of the WAP components to a single host, as described in Install a Simple Test WAP Installation.</p> <p>If you would like to test backup services, use the WAP Application to configure them. When configuring WAP, you can specify the backup settings.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/02-ExampleDeployment/#production-installs","title":"Production Installs","text":""},{"location":"WhalealPlatform/01-WhalealOverview/02-ExampleDeployment/#redundant-metadata-and-snapshots","title":"Redundant Metadata and Snapshots","text":"<p>This deployment provides redundancy for the WAP Application Database and Snapshot Storage in the event of host failure. The deployment runs the database in a MongoDB replica set with three data-bearing members with copies of the data.</p> <p>This deployment provides high availability for the WAP Application. WAP uses a w:majority write concern, and can tolerate the loss of one data-bearing node from the WAP Application Database. To make the deployment more durable, enable journaling.</p> <p>All hosts must satisfy the combined hardware and software requirements for systems specified in the System Requirements column.</p> <p>For an example tutorial on installing the minimally viable Whaleal installation, see QuickStart.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/","title":"Quick Start On Premise","text":"<p>This setup is not suitable for a production deployment.</p> <p>To evaluate WAP, you can install the WAP Application and WAP Application Database on a single host. This setup provides all the functionality of WAP monitoring and automation but provides no failover or high availability.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#considerations","title":"Considerations","text":"<p>This test installation includes the following caveats:</p> <ul> <li> <p>It uses one mongod for the WAP Application database. In production, the database requires a dedicated replica set.</p> </li> <li> <p>It uses MongoDB Community Edition. MongoDB Community doesn't need additional libraries.</p> </li> </ul>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#procedure","title":"Procedure","text":""},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#deploy-wap","title":"Deploy WAP","text":"<p>To install and configure an evaluation version of WAP on hosts running CentOS Linux release 7.9.2009:</p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#1-provision-an-wap","title":"1. Provision an WAP.","text":"<p>Provision a host for WAP. This host must meet the following requirements:</p> Parameters Value System Memory 16GB Disk Capacity 500GB Host OS Permissions root Host OS CentOS Linux release 7.9.2009 <p>Cloud-based instances must meet the memory and storage requirements.</p> <p>To verify the needed capacity, log in to the instance and execute the following commands:</p> <pre><code>vmstat -S M -s | grep \"total memory\"\n</code></pre> <p>The output for the command shows that this instance has 16 GB of RAM.</p> <pre><code>16384 M total memory\n</code></pre> <pre><code>df -h | grep \"/$\"\n</code></pre> <p>The output for the command shows that this instance has 557 GB of storage capacity.</p> <pre><code>/dev/sda        557G  1.4G  548G   1% /\n</code></pre> <p>Verify that the <code>ulimit</code> settings meet the minimum requirements.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#2-configure-yum-to-install-mongodb","title":"2. Configure yum to install MongoDB.","text":"<p>Create a <code>/etc/yum.repos.d/mongodb-org-5.0.repo</code> file so that you can install MongoDB directly using <code>yum</code>:</p> <pre><code>[mongodb-org-5.0]\nname=MongoDB Repository\nbaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/5.0/x86_64/\ngpgcheck=1\nenabled=1\ngpgkey=https://pgp.mongodb.com/server-5.0.asc\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#3-install-mongodb","title":"3. Install MongoDB.","text":"<p>Invoke the following command to install the latest stable release of MongoDB Community:</p> <pre><code>sudo yum install -y mongodb-org\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#4-optional-disable-the-mongod-service","title":"4. Optional: Disable the mongod service.","text":"<p>WAP connects to its application database on port 27017. If the host on which you want to install the application database has a running mongod, disable that existing database.</p> <p>To disable the mongod service, invoke the following command:</p> <pre><code>sudo systemctl disable mongod\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#5-create-the-wap-application-database-directory","title":"5. Create the WAP Application Database directory.","text":"<pre><code>sudo mkdir /data/\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#6-update-the-mongodb-configuration-file","title":"6. Update the MongoDB configuration file.","text":"<p>The installer creates a configuration file saved at <code>/etc/mongod.conf</code>.</p> <p>Edit the file to make the following changes:</p> <pre><code>net:\n  bindIp: 0.0.0.0\n  port: 27017\nprocessManagement:\n  fork: \"true\"\nsecurity:\n  authorization: enabled\n  keyFile: /data/keyfile\nstorage:\n  dbPath: /data\n  journal:\n      enabled: true\n  engine: wiredTiger\n  wiredTiger:\n    engineConfig:\n      cacheSizeGB: 4\nsystemLog:\n  destination: file\n  path: /data/mongodb.log\n  logAppend: true\n</code></pre> <p>Save the file when you have made the edits.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#7-create-the-mongodb-keyfile","title":"7. Create the MongoDB KeyFile.","text":"<pre><code>openssl rand -base64 756 &gt; /data/keyfile\nchmod 400 /data/keyfile\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#8-start-the-wap-application-database-mongod-instance","title":"8. Start the WAP Application Database mongod instance.","text":"<pre><code>sudo mongod -f /etc/mongod.conf\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#9-create-user-in-application-database","title":"9. Create User in Application Database.","text":"<pre><code>mongosh\n\nuser admin\ndb.createUser({\"user\": \"root\", \"pwd\": \"&lt;password&gt;\", \"roles\": [\"root\"]})\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#10-prepare-wap-package","title":"10. Prepare WAP Package.","text":"<pre><code>WAP.tar.gz\n</code></pre> <p>\u200b    </p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#11-start-wap-service","title":"11. Start WAP service.","text":"<pre><code>pkill -9 java\ntar -zxvf WAP.tar.gz -C /opt/\ncd /opt/WAP\n</code></pre> <p>Update the WAP config file <code>/opt/WAP/start.sh</code>:</p> <pre><code># Configure external access IP address\nbind_ip=&lt;public IP&gt;\n# Configure the WAP application database URL. Requires authorization to use the whaleal database\nappDBUrl=mongodb://root:&lt;password&gt;@127.0.0.1:27017/admin\n</code></pre> <p>Start WAP service</p> <pre><code>cd /opt/WAP\nchmod +x start.sh\n\n./start.sh\n</code></pre>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#12-open-the-wap-home-page-and-reset-password","title":"12. Open the WAP home page and Reset Password.","text":"<pre><code>http://&lt;public IP&gt;\n\nusername: admin\npassword: password\n</code></pre> <p>Reset Password and Login.</p> <p>\u200b    </p>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#deploy-mongodb","title":"Deploy MongoDB","text":""},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#deploy-mongodbs-server","title":"Deploy MongoDB's server","text":"<ol> <li>Install and deploy the agent into the server. Each machine takes turns to do the following operations.</li> </ol> <ol> <li>After successful management, it will be displayed in the following figure.</li> </ol> <ol> <li>Upload MongoDB package.</li> </ol>"},{"location":"WhalealPlatform/01-WhalealOverview/03-QuickStartOnPremise/#build-a-mongodb-three-node-replication-set","title":"Build a MongoDB three-node replication set","text":"<ol> <li>Click to the MongoDB page and click Replica Set under Create Cluster.</li> </ol> <ol> <li>Create replication set node status information.</li> </ol> <ol> <li>Click on the Show to view the real-time creation log.</li> </ol> <ol> <li>Check the log to determine whether the cluster was created successfully.</li> </ol> <ol> <li>View information on each node in MongoDB</li> </ol> <ol> <li>Check the surveillance</li> </ol> <p>#### Existing MongoDB Deployment</p> <p>Reference: Deploy MongoDB's server</p> <ol> <li> <p>Click to the MongoDB page and open \"Existing MongoDB Deployment\".</p> <p></p> </li> <li> <p>Fill in and copy relevant information       a. Enter the cluster name of the replication set (custom)       b. Select the project and host name of the storage management system       c. Enter the port number of the MongoDB cluster       d. Add MongoDB's authenticated username and password       e. Select the version number corresponding to the cluster</p> <p></p> </li> <li> <p>Check the event log to determine whether the management was successful.</p> <p></p> </li> <li> <p>View cluster node information.</p> <p></p> </li> <li> <p>view the monitoring data.</p> <p></p> </li> </ol>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/","title":"Quick Start On Marketplace","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#installation-requirements","title":"Installation Requirements","text":"<p>Before installing Whaleal Platform (WAP), you must ensure that the Service and Agent meet the necessary software, hardware, network, and port requirements.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#whaleal-platform","title":"Whaleal Platform","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#hardware-requirements","title":"Hardware Requirements","text":"<p>Minimum Requirements: 8 cores, 16GB of RAM, 500GB disk space.</p> Node Number CPU Memory Disk 50 8+ 16GB+ 500GB+additional storage for logs 200 16+ 32GB+ 500GB+additional storage for logs 200+ Please contact the Whaleal Team for specific requirements. <p>Operating System Requirements</p> Operating System Version Architecture Amazon Linux 2023x86_64"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#software-requirements","title":"Software Requirements","text":"<p>Java Environment Requirements</p> JAVA Version open-jdk 11.0.22"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#network-requirements","title":"Network Requirements","text":"<p>TCP</p> <p>Ensure that all Whaleal Platform Application services can communicate effectively over TCP/IP.</p> <ul> <li>Whaleal Platform Application Database</li> <li>Whaleal Platform Application Agent Monitor MongoDB</li> </ul> <p>Hosts</p> <p>To ensure plug-and-play functionality, the Whaleal Platform Server requires the external IP to be open.</p> <p>Port</p> <p>The Whaleal Platform Application must meet the following basic requirements:</p> <ul> <li>Users and the Whaleal Platform Application Agent must be able to access via HTTP/HTTPS requests.</li> <li>The Whaleal Platform Application must be able to access the Whaleal Platform Application Database.</li> <li>All Whaleal Platform Applications and Whaleal Platform Application Agents must be able to access the monitored and managed MongoDB services.</li> <li>The Whaleal Platform Application must be able to send information to users via email, DingTalk, Feishu, Webhook.</li> </ul> <p>The Whaleal Platform Application must open the following ports:</p> Service Default Port Transport Direction HTTP 8080 TCP Inbound Whaleal Platform 80 TCP Inbound Boot deployment pagem 9599 TCP Inbound SMTP 587 TCP Outbound DingTalk, Lark, Webhook TCP Outbound <p>If a custom port is needed, please open the custom port.</p> <p>Port at host</p> <p>The Whaleal Platform Application can complete most operations, but some processes require administrator access to the Whaleal Platform Application host. The following ports must be open:</p> Service Default Port Transport Direction ssh 22 TCP Inbound"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#whaleal-platform-database","title":"Whaleal Platform Database","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#hardware-requirements_1","title":"Hardware Requirements","text":"<p>Minimum requirement: 2 cores, 4GB RAM</p> Node Number CPU Memory Disk 50 4+ 8GB+ 200GB 200 8+ 16GB+ 500GB 200+ Please contact the Whaleal Team for specific requirements. <p>For better performance, it is recommended to use:</p> <ul> <li>SSD for the Application Database disk.</li> <li>WiredTiger Storage Engine for the Application Database.</li> </ul> <p>Operating System Requirements</p> Operating System Version Architecture Centos 7.9.2009 x86_64"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#software-requirements_1","title":"Software Requirements","text":"<p>Java Environment Requirements</p> JAVA Version open-jdk 11.0.22"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#network-requirements_1","title":"Network Requirements","text":"<p>Port at host</p> Service Default Port Transport Direction MongoDB 27017 TCP Inbound"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#mongodb-agent","title":"MongoDB - Agent","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#hardware-requirements_2","title":"Hardware Requirements","text":"<p>Minimum: 2 cores, 4GB RAM</p> <p>Operating System</p> Operating System Version Architecture Centos 7.9.2009 x86_64"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#software-requirements_2","title":"Software Requirements","text":"<p>Java Environment Requirements</p> JAVA Version open-jdk 11.0.22"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#network-requirements_2","title":"Network Requirements","text":"<p>Port</p> <p>The Whaleal Platform Application Agent must meet the following basic requirements:\\</p> <ul> <li>Users and the Whaleal Platform Application must be able to access the server and MongoDB.</li> <li>Therefore, the Whaleal Platform Application must open the following ports:</li> </ul> Service Default Port Transport Direction MongoDB 27017 TCP Inbound\u3001Outbound <p>If a custom port is needed, please open the custom port.</p> <p>Port at host</p> <p>The Whaleal Platform Application Agent can complete most operations, but some processes require administrator access to the Whaleal Platform Application host. The following ports must be open:</p> Service Default Port Transport Direction ssh 22 TCP Inbound"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#ddt-mongodb-backup","title":"DDT - MongoDB Backup","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#hardware-requirements_3","title":"Hardware Requirements","text":"<p>Minimum: 4 cores, 16GB RAM</p> <p>Operating System</p> Operating System Version Architecture Centos 7.9.2009 x86_64"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#software-requirements_3","title":"Software Requirements","text":"<p>Java Environment</p> JAVA Version open-jdk 11.0.22"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#network-requirements_3","title":"Network Requirements","text":"<p>Port</p> <p>DDT must meet the following basic requirements:</p> <ul> <li>DDT service configures ports 47019 and 57019 for MongoDB backup process operation.</li> </ul> <p>DDT must open the following ports:</p> Service Default Port Transport Direction MongoDB 47019 TCP Inbound MongoDB 57019 TCP Inbound <p>If a custom port is needed, please open the custom port.</p> <p>Port at host</p> <p>DDT can complete most operations, but some processes require administrator access to the DDT host. The following ports must be open:</p> Service Default Port Transport Direction ssh 22 TCP Inbound"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#installation-deployment","title":"Installation Deployment","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#subscribe-to-whaleal-platform-agent","title":"Subscribe to Whaleal Platform Agent","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#subscription-service","title":"Subscription Service","text":"<p>Search for Whaleal Platform Agent in the AWS Marketplace</p> <p></p> <p>Click \"Continue to Subscribe\" to subscribe to the service.</p> <p></p> <p>Click \"Accept Terms\" to agree to the service terms.</p> <p></p> <p>Click \"Continue to Configuration\" to configure.</p> <p></p> <p>Configure instance, version, region, and pricing, among other related information.</p> <p></p> <p>Click \"Continue to Launch\" to proceed to the next step.</p> <p></p> <p>Select \"Launch through EC2\" and then click \"Launch\" to deploy the instance in EC2.</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#instance-deployment","title":"Instance deployment","text":"<p>Configure instance name</p> <p></p> <p>Configure instance typeMinimum instance type: 2 cores, 4GB RAM</p> <p></p> <p>Configure Key pair</p> <p></p> <p>Configure network and ports</p> <p></p> <p>Add storage volume</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#deploy-appdb-mongodb-service-optional","title":"Deploy Appdb MongoDB service (optional)","text":"<p>The Appdb MongoDB service can be configured manually. If you opt for manual configuration, you can ignore the following steps.</p> <p>Automated deployment</p> <p>Navigate to /opt/ and execute \u201cQuickStart_MongoDB.sh\u201d to quickly start the Appdb MongoDB single-instance service.</p> <p></p> <p>Record the server IP and MongoDB username and password.</p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#subscribe-to-whaleal-platform-server","title":"Subscribe to Whaleal Platform Server","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#subscribe-to-the-service","title":"Subscribe to the service","text":"<p>Search for Whaleal Platform in the AWS Marketplace</p> <p></p> <p>Click \"Continue to Subscribe\" to subscribe to the service.</p> <p></p> <p>Click \"Accept Terms\" to agree to the service terms.</p> <p></p> <p>Click \"Continue to Configuration\" to proceed with the setup.</p> <p></p> <p>Configure instance, version, region, and pricing-related information.</p> <p></p> <p>Click \"Continue to Launch\" to proceed to the next step.</p> <p></p> <p>Select \"Launch through EC2\" and then click \"Launch\" to deploy the instance in EC2.</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#instance-deployment_1","title":"Instance deployment","text":"<p>Configure instance name</p> <p></p> <p>Configure instance type</p> <p>Minimum instance type: 8 cores, 16GB RAM, 500GB</p> <p></p> <p>Configure key pair</p> <p></p> <p>Configure network and ports</p> <p></p> <p>Add storage volume</p> <p>Minimum requirement: 500GB</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#whaleal-platform-server-deployment","title":"Whaleal Platform Server Deployment","text":"<p>Confirm that the boot services are starting on the Whaleal Platform servernginx service</p> <p></p> <p>Java Service</p> <p></p> <p>Enter the Whaleal Platform URL in your browser</p> <p></p> <p>Click \"Next Step\" to proceed to the next step Check whether the server hardware specifications meet the requirements of the Whaleal Platform</p> <p></p> <p>Configure the MongoDB service as outlined in \"Appdb MongoDB service deployment\"</p> <p></p> <p>Configure the connection for accessing the Whaleal Platform, which can be an IP address or domain name.</p> <p></p> <p>Click \"Launch\" to deploy the Whaleal Platform service.</p> <p></p> <p>Once the startup is successful, generate the connection URL and display the initial username and password.</p> <p></p> <p>Initial login</p> <p></p> <p>Reset password on first login</p> <p></p> <p>Display the home page upon successful login</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#deploy-single-instance-replica-set","title":"Deploy single-instance replica set","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#instance-deployment_2","title":"Instance deployment","text":"<p>Create an instance in the subscribed Whaleal Platform Agent</p> <p></p> <p></p> <p>Configure instance name</p> <p></p> <p>Configure instance type</p> <p></p> <p>Configure key pair</p> <p></p> <p>Configure network and ports</p> <p></p> <p>Add storage volume</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#mongodb-service-deployment","title":"MongoDB Service Deployment","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#configure-the-agent-service","title":"Configure the Agent service","text":"<p>Configure \"parameters.properties\" in the /opt/agent directory on the Agent server</p> <p></p> <p>Modify the configuration file URL, placing the Whaleal Platform URL connection after \"foreign_url=\" and adding port \"8080\"</p> <p></p> <p>Check Agent statussystemctl status whaleal_agent</p> <p></p> <p>All Agent services are stored in the public project of the Whaleal Platform after deployment</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#create-a-custom-project","title":"Create a custom project","text":"<p>Move the host from the public project to the custom project</p> <p></p> <p></p> <p>View host information</p> <p></p>"},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#upload-the-mongodb-package","title":"Upload the MongoDB package","text":""},{"location":"WhalealPlatform/01-WhalealOverview/04-QuickStartOnMarketplace/#deploy-mongodb-replica-set","title":"Deploy MongoDB Replica Set","text":"<p>Configure replica set parameters</p> <p></p> <p>Monitor event log progress</p> <p></p> <p></p> <p> Replica Set setup completed</p> <p></p>"},{"location":"WhalealPlatform/02-InstallWhaleal/01-InstallationChecklist/","title":"Installation Checklist","text":"<p>You must make several decisions based on the content of this page before you install Whaleal. During the installation process, you will make choices based on these decisions.</p> <p>To install Whaleal:</p> <ol> <li> <p>Read the Whaleal Overview.</p> </li> <li> <p>Plan your installation according to the questions on this page.</p> </li> <li> <p>Provision servers that meet the Whaleal Platform System Requirements.</p> </li> <li> <p>Install the Application Database and optional Backup Database.</p> </li> <li> <p>Install Whaleal.</p> </li> </ol>"},{"location":"WhalealPlatform/02-InstallWhaleal/01-InstallationChecklist/#will-you-deploy-managed-mongodb-instances-on-servers-that-have-no-internet-access","title":"Will you deploy managed MongoDB instances on servers that have no internet access?","text":"<p>If the servers where you deploy MongoDB don\u2019t have internet access and if you use Automation, then before you create the first managed MongoDB deployment from Whaleal, you must configure local mode and store the binaries. Agents can then download the binaries directly from Whaleal. </p>"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/","title":"Hardware And Software Requirements","text":"<p>This section describes the hardware, software, and networking requirements for the hosts that run the Whaleal components.</p> <p>Before installing Whaleal Platform (WAP), you need to review the following materials: - Server Requirement - Agent Requirement</p>"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#server-requirement","title":"Server Requirement","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#hardware-requirement","title":"Hardware Requirement","text":"<p>All hosts that install the following Whaleal Platform (WAP) components must meet RAM and Disk requirements:</p> <ul> <li>Whaleal Platform Application</li> <li>Whaleal Platform Application Databases</li> </ul> <p>Whaleal Platform Application Hardware Requirement</p> <p>All hosts deploying Whaleal Platform Application must meet the following hardware requirements:</p> Number of Monitored Nodes CPU Memory Disk 50 8+ 8GB+ 200GB + logs storage 200 16+ 16GB+ 500GB + logs storage 200+ Contact Whaleal Team Contact Whaleal Team Contact Whaleal Team <p>Whaleal Platform Application Database Hardware Requirement</p> <p>All hosts deploying Whaleal Platform Application Database must meet the following hardware requirements:</p> Number of Monitored Nodes CPU Memory Disk 50 4+ 8GB+ 200GB 200 8+ 16GB+ 500GB 200+ Contact Whaleal Team Contact Whaleal Team Contact Whaleal Team <p>For better performance, it is recommended to use:</p> <ul> <li>SSD for Application Database storage</li> <li>WiredTiger storage engine for Application Database</li> </ul>"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#software-requirement","title":"Software Requirement","text":"<p>Java Environment Requirement</p> JAVA Version jdk 11+ open-jdk 11+ <p>Operating System Compatibility</p> <p>Whaleal Platform Application must be deployed on a 64-bit operating system.</p> Operating System Version Red Hat Enterprise Linux 6.x, 7.x, 8.x CentOS 6.x, 7.x, 8.x"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#network-security","title":"Network Security","text":"<p>TCP Connection Requirement</p> <p>All Whaleal Platform Application services must be able to communicate properly with the following services:</p> <ul> <li>Whaleal Platform Application Database</li> <li>Whaleal Platform Application Agent Monitor MongoDB</li> </ul> <p>Hosts</p> <p>To facilitate easier usage, it is recommended to configure the hostname of the server where the Whaleal Platform Application is located</p> <p>Port</p> <p>Whaleal Platform Application must meet the following basic requirements:</p> <ul> <li>Users and Whaleal Platform Application Agent must be able to access via HTTP/HTTPS requests</li> <li>Whaleal Platform Application must be able to access Whaleal Platform Application Database</li> <li>All Whaleal Platform Application and Whaleal Platform Application Agent must be able to access the monitored MongoDB services</li> <li>Whaleal Platform Application must be able to send messages to users via email, SMS, and DingTalk</li> </ul> <p>Therefore, Whaleal Platform Application must have the following ports open:</p> Service Default Port Transport Direction Description HTTP 8080 TCP Inbound WAP application service port Boot Page 9599 TCP Inbound WAP login page port Web 80 TCP Inbound WAP Web Port <p>For custom ports, please open the specified ports.</p> <p>Ports on Host</p> <p>Whaleal Platform Application can complete most operations, but some processes require administrator access to the Whaleal Platform Application host to complete. Therefore, the following port must be open:</p> Service Default Port Transport Direction Description ssh 22 TCP Inbound Default port for SSH (Secure Shell) service"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#agent-requirement","title":"Agent Requirement","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#hardware-requirement_1","title":"Hardware Requirement","text":"<p>All hosts that install the following Whaleal Platform (WAP) components must meet RAM and Disk requirements:</p> <ul> <li>Whaleal Platform Application Agent</li> </ul> <p>Whaleal Platform Application Agent Hardware Requirement</p> <p>All hosts deploying Whaleal Platform Application Agent must meet the following hardware requirements:</p> Number of Managed/Monitored Nodes CPU Memory Disk 1 1+ 2GB+ 2GB + logs storage 5 2+ 4GB+ 2GB + logs storage 5+ Contact Whaleal Team Contact Whaleal Team Contact Whaleal Team"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#software-requirement_1","title":"Software Requirement","text":"<p>Java Environment Requirement</p> JAVA Version jdk 11+ open-jdk 11+ <p>Operating System Compatibility</p> <p>Whaleal Platform Application Agent must be deployed on a 64-bit operating system.</p> Operating System Version Red Hat Enterprise Linux 6.x, 7.x, 8.x CentOS 6.x, 7.x, 8.x"},{"location":"WhalealPlatform/02-InstallWhaleal/02-HardwareAndSoftwareRequirements/#network-security_1","title":"Network Security","text":"<p>TCP Connection Requirement</p> <p>All Whaleal Platform Application services must be able to communicate properly with the following services:</p> <ul> <li>Whaleal Platform Application Database</li> <li>Whaleal Platform Application Agent Monitor MongoDB</li> </ul> <p>Ports on Host</p> <p>Whaleal Platform Application Agent can complete most operations, but some processes require administrator access to the Whaleal Platform Application host to complete. Therefore, the following port must be open:</p> Service Default Port Transport Direction Description ssh 22 TCP Inbound"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/","title":"Install Whaleal in AWS MarketPlace","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/#subscription-service","title":"Subscription Service","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/#whalal-platform","title":"Whalal Platform","text":"<ol> <li> <p>Log in to the AWS console.</p> </li> <li> <p>Search Marketplace in Servers.</p> </li> <li> <p>Click Discover products in the left navigation bar of the marketplace.</p> </li> <li> <p>Search for whaleal in MarketPlace.</p> </li> <li> <p>Find Whalal Platform and subscribe.</p> </li> </ol> <p></p> <ol> <li>Click  Continue  To Subscribe</li> </ol> <p></p> <p>Wait for the progress below to load</p> <p></p> <p>Loading completed</p> <p></p> <ol> <li>View subscription results in Manage subscriptions,when you see the WAP in the image below in Manage subscriptions, your subscription is successful.</li> </ol> <p></p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/#whaleal-platform-agent","title":"Whaleal Platform Agent","text":"<ol> <li> <p>Log in to the AWS console.</p> </li> <li> <p>Search Marketplace in Servers.</p> </li> <li> <p>Click Discover products in the left navigation bar of the marketplace.</p> </li> <li> <p>Search for whaleal in MarketPlace.</p> </li> <li> <p>Find Whalal Platform Agent and subscribe.</p> </li> </ol> <p></p> <ol> <li>Click  Continue  To Subscribe</li> </ol> <p></p> <p>Wait for the progress below to load</p> <p></p> <p>Loading completed</p> <p></p> <ol> <li>View subscription results in Manage subscriptions,when you see the WAP in the image below in Manage subscriptions, your subscription is successful.</li> </ol> <p></p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/#install-appdb-for-wap-service","title":"Install appdb for WAP service","text":"<p>Before building the appdb for the WAP service, refer to the Installation Checklist to set the minimum instance parameter configuration.</p> <ol> <li>Start the instance through the subscribed Whaleal Platform Agent in Manage subscriptions and click lunch new instance below the subscription.</li> </ol> <p></p> <ol> <li> <p>Select region.</p> </li> <li> <p>Select Instance type based on actual business pressure.</p> </li> <li> <p>Select Key pair (login).</p> </li> <li> <p>Select or configure a security group and edit Inbound rules and Outbound rules according to business requirements.</p> </li> <li> <p>Configuring storage space size.</p> </li> <li> <p>Click lunch to start the instance.</p> </li> <li> <p>Access the instance and use the script in the instance to start appdb.</p> </li> </ol> <p>There is a QuickStart_MongoDB.sh script in the /opt directory of the instance. You can directly execute the script to start a mongodb, or use the self-built method to start the mongodb service as the WAP appdb. No matter which method is used to start, ensure that the starting user has sufficient read and write permissions.</p> <p>After starting the script, the following output will be displayed. The content in the red box below is saved locally to prevent loss.</p> <p>Record username and password</p> <p></p> <p>After the modification is completed, test the connection locally</p> <p></p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/#install-wap","title":"Install WAP","text":"<p>Before building  WAP service, refer to the Installation Checklist to set the minimum instance parameter configuration.</p> <ol> <li>Under Manage subscriptions, find Instance new Instance under Whaleal Platform</li> </ol> <p></p> <ol> <li> <p>Select region.</p> </li> <li> <p>Select Instance type based on actual business pressure.</p> </li> <li> <p>Select Key pair (login).</p> </li> <li> <p>Select or configure a security group and edit Inbound rules and Outbound rules according to business requirements.</p> </li> <li> <p>Configuring storage space size.</p> </li> <li> <p>Click lunch to start the instance.</p> </li> </ol>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/01-InstallWhalealInAWSMarketPlace/#configuring-wap","title":"Configuring WAP","text":"<ol> <li>Access its public IP directly in the browser,visit the WAP guide page to configure WAP.</li> </ol> <ol> <li>Click the Next step button and then proceed to resource check.</li> </ol> <p>After all the checks are passed, you can proceed to the next step.</p> <p></p> <ol> <li>Configure appdb and modify the three items Database host, User and Password.After the configuration is complete, click Next step.</li> </ol> <p></p> <ol> <li> <p>Configure Web Url and click Next step.</p> </li> <li> <p>At this point, the configuration is successful and click lunch.</p> </li> </ol> <p>\u200b    As shown below, when all components are successfully started, click Next step</p> <p></p> <ol> <li> <p>Click the Finish</p> </li> <li> <p>First login WAP.</p> </li> </ol> <p>a. The first login the default user name is \"admin\" and the default password is \"password\".</p> <p>b. Change default password after login.</p> <ol> <li>Login to WAP service.</li> </ol> <p></p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/02-InstallWhalealinDocker/","title":"Install Whaleal in Docker","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/","title":"OnPremise Install Whaleal","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#prerequisites","title":"Prerequisites","text":"<p>You must have administrative access on the hosts to which you install.</p> <p>Before you install Whaleal, you must:</p> <ol> <li> <p>Plan your configuration. See Installation Checklist.</p> </li> <li> <p>Deploy hosts that meet the Whaleal System Requirements.</p> </li> </ol> <p>IMPORTANT</p> <p>Your Whaleal instance can fail in production if you fail to configure the following:</p> <ul> <li>Whaleal hosts per the Whaleal System Requirements.</li> <li>MongoDB hosts per the Production Notes in the MongoDB manual. MongoDB instances in Whaleal include:</li> <li>The Whaleal Application Database,</li> <li>Each blockstore.</li> </ul> <ol> <li>Install the Whaleal Application Database and optional Backup Database. The databases require dedicated MongoDB instances. Don't use MongoDB installations that store other data. Whaleal requires the Backup Database if you use the Backup feature.</li> </ol> <p>The Whaleal Application must authenticate to the backing databases as a MongoDB user with appropriate access.</p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#install-whaleal","title":"Install Whaleal","text":"<p>To install Whaleal:</p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#contact-jinmu-company-to-get-the-latest-waptargz-compressed-file","title":"Contact Jinmu Company to get the latest WAP.tar.gz compressed file","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#optional-verify-whaleal-package-integrity","title":"Optional: Verify Whaleal package integrity.","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#install-the-whaleal-package-on-each-server-being-used-for-whaleal","title":"Install the Whaleal package on each server being used for Whaleal.","text":"<p>Navigate to the directory to which to install Whaleal. Extract the archive to that directory:</p> <pre><code>tar -zxf WAP.tar.gz\n</code></pre> <p>When complete,W is installed.</p>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#configure-the-whaleal-connection-to-the-whaleal-application-database","title":"Configure the Whaleal connection to the Whaleal Application Database.","text":"<p>On a server that is to run Whaleal, open <code>WAP/start.sh</code> with root privileges and configure the settings described here, as appropriate.</p> <p>Configure the following setting to provide the connection string Whaleal uses to connect to the database:</p> <ul> <li>appDBUrl</li> </ul> <p>Specify the IP address for Whaleal's external access by configuring bind_ip.</p> <ul> <li>bind_ip</li> </ul>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#start-whaleal","title":"Start Whaleal.","text":"<p>Issue the following command:</p> <pre><code>sh WAP/start.sh\n</code></pre>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#open-the-whaleal-home-page-and-register-the-first-user","title":"Open the Whaleal home page and register the first user.","text":"<ol> <li>Enter the following URL in a browser, where <code>&lt;host&gt;</code> is the fully qualified domain name of the server:</li> </ol> <pre><code>http://&lt;bind_ip&gt;:8080\n</code></pre> <ol> <li>Use the default username and password for the first login. The default username is: admin, the default password is: password</li> </ol>"},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#at-this-point-whaleal-has-been-built-and-is-ready-for-use","title":"At this point, Whaleal has been built and is ready for use.","text":""},{"location":"WhalealPlatform/02-InstallWhaleal/03-InstallWhaleal/03-OnPremiseInstallWhaleal/#steps-for-usage","title":"Steps for usage","text":"<ol> <li> <p>Click the Server button in the left navigation bar to jump to the server page.</p> </li> <li> <p>Click the EC2 button in the drop-down box to jump to the Host List page.</p> </li> <li> <p>Click ADD Host to add a server.</p> </li> </ol> <p></p> <p>Now that the server is available, you can use Whaleal to work.</p> <p>For deployment of Standalone, please refer to Deploy a Standalone.</p> <p>For  deployment of Replica Set, please refer to Deploy a Replica Set.</p> <p>For deployment of Sharding Cluster, please refer to Deploy a Sharded Cluster.</p> <p>To use Whaleal to manage an existing cluster, please refer to Deploy a existing Cluster.</p>"},{"location":"WhalealPlatform/03-Projects/01-Projects/","title":"Projects","text":"<p>In WAP, MongoDB deployments are associated with projects.</p> <p>Each project has its own Monitoring, Backup and Automations associated with the project.</p>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#working-with-multiple-environments","title":"Working with Multiple Environments","text":"<p>For a project, the Monitoring must be able to connect to all hosts it monitors. If you have multiple MongoDB deployments in distinct environments and cannot monitor all deployments with a single agent (for instance, if your environments are separated by firewalls), you will need to add new projects.</p> <p>You can also use multiple projects and agents if you want to separately monitor different MongoDB deployments that run in the same environment.</p>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#create-one-project","title":"Create One Project","text":"<p>IMPORTANT</p> <ul> <li>To create a Project, you must proactively add users to the Project.</li> <li>When you create a project, WAP automatically assigns a set of default alert configurations to the project.</li> </ul>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#navigate-to-the-create-a-project-page","title":"Navigate to the Create a Project page.","text":"<ol> <li>Click the Project icon in the upper left corner of the page.</li> <li>Click New Project.</li> </ol>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#provide-a-name-for-your-project","title":"Provide a name for your Project.","text":"Server Intention Project Purpose Production Server Hosts your application to your internal or external end users. If an end user might use an environment, it functions as a Production environment. This applies whether the environment also provides testing, quality assurance, evaluation, or development capabilities. Test/QA Server This type of environment can be used to:Test\uff1aExercises your application to verify that it works as designed and expected. The platform configuration might be a less performant version of Production in compute, network, and storage capability.Assure system quality\uff1aValidates your application against a combination of data, hardware, and software configured to simulate Production. The platform configuration should be a smaller scale of Production in compute, network, and storage capability.Stage\uff1aSimulates the Production environment including performance testing and release candidate approval. The platform configuration should mirror Production in compute, network, and storage capability. Development Server Hosts in progress design, code, debugging or some combination thereof for your application. Used to evaluate if the current state of your application can be promoted to another environment. RAM Pool Provides any combination of servers for any environment purpose."},{"location":"WhalealPlatform/03-Projects/01-Projects/#add-members-to-your-project","title":"Add members to your project.","text":"<p>Select the users who want to join the Project, and finally Confirm.</p>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#delete-one-project","title":"Delete One Project","text":"<p>IMPORTANT</p> <p>After deleting Project, the hosts and MongoDB in this Project will not belong to any Project, and will not be viewable by users in the host list and MongoDB list. If you need to be seen again, you need to grant the user the Write permission in Admin/Account. </p> <p></p> <p></p>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#view-all-of-your-projects","title":"View all of your projects.","text":"<p>\u200b   Click the Project icon in the upper left corner of the page. </p>"},{"location":"WhalealPlatform/03-Projects/01-Projects/#delete-the-project","title":"Delete the project.","text":"<p>\u200b   Click the Project card to display Project details, and click Delete.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/","title":"Deployment Prerequisites","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#system-requirements","title":"System Requirements","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#hardware-and-software","title":"Hardware and Software","text":"<p>Each host must meet the following requirements.</p> <ul> <li>At least 10 GB of free disk space plus whatever space is necessary to hold your MongoDB data.</li> <li>At least 2 GB of RAM.</li> <li>If you use AWS EC2 instances, you should use a minimum of an <code>t3.small</code> instance.</li> <li>The MongoDB Agent must be installed only on 64-bit architectures.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#server-networking-access","title":"Server Networking Access","text":"<p>The hosts that serve the MongoDB deployments must:</p> <ul> <li>Have full networking access to each other through their FQDN. Each host must be able to reach every other host through the FQDN. To find the FQDN for each host, run the following command in the shell:</li> </ul> <pre><code>hostname -f\n</code></pre> <ul> <li>Set the Common Name or Subject Alternative Name value of any SSL certificates to the MongoDB host\u2019s FQDN.</li> </ul> <p>The network configuration must allow each MongoDB Agent to make a direct connection to every MongoDB deployment listed on the Deployment page. Whaleal does not support port forwarding.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#backup-and-monitoring","title":"Backup and Monitoring","text":"<p>Whaleal supports backup and monitoring only for MongoDB version 5.0 and later.</p> <p>For more information about backup, refer to BackupAndRestore</p> <p>For more information about backup, refer to Monitor</p>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#mongodb-backup-support","title":"MongoDB  Backup Support","text":"<ul> <li>Increased disk usage, disk I/O, and network I/O on each MongoDB host with backup enabled while a snapshot is being taken.</li> <li>Increased inbound network load to the Agent host or hosts while a snapshot is being taken.</li> <li>Snapshots and backups use no storage capacity on Whaleal application.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#mongodb-agent-system-user-permissions","title":"MongoDB Agent System User Permissions","text":"<p>If you want the MongoDB Agent to manage your MongoDB deployments, the MongoDB Agent System User must have permission:</p> <ul> <li> <p>To stop the MongoDB processes. The MongoDB Agent System User restarts the processes using the agent's own set of MongoDB binaries.</p> </li> <li> <p>To <code>Read</code> and <code>Write</code> the MongoDB data directories and log directories.</p> </li> <li> <p>Set to the same user ID (UID) and group ID (GID) of the MongoDB process to be automated. If the MongoDB processes to be automated are not running as the same user and group, the Agent cannot manage those processes.</p> </li> </ul> <p>## EXAMPLE</p> <p>If your MongoDB Agent runs as the <code>mongod</code> root user in the <code>mongod</code> root group, the MongoDB process must also run as the <code>mongod</code> root user in the <code>mongod</code> root group.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#installation-options","title":"Installation Options","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#installing-mongodb-enterprise-dependencies","title":"Installing MongoDB Enterprise Dependencies","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#ubuntu","title":"Ubuntu","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#ubuntu-1804","title":"Ubuntu 18.04","text":"<pre><code>sudo apt-get install \\\n     libcurl4 libgssapi-krb5-2 libldap-2.4-2 liblzma5 \\\n     libsasl2-2 libsasl2-modules \\\n     libsasl2-modules-gssapi-mit libwrap0 openssl snmp\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#ubuntu-2004","title":"Ubuntu 20.04","text":"<pre><code>sudo apt-get install \\\n     libcurl4 libgssapi-krb5-2 libldap-2.4-2 liblzma5 \\\n     libsasl2-2 libsasl2-modules \\\n     libsasl2-modules-gssapi-mit libwrap0 openssl snmp\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#ubuntu-2204","title":"Ubuntu 22.04","text":"<pre><code>sudo apt-get install \\\n     libcurl4 libgssapi-krb5-2 libldap-2.4-2 liblzma5 \\\n     libsasl2-2 libsasl2-modules \\\n     libsasl2-modules-gssapi-mit libwrap0 openssl snmp\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#rhelcentos","title":"RHEL/CentOS","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#rhelcentos-6x","title":"RHEL/CentOS 6.x","text":"<pre><code>sudo yum install cyrus-sasl cyrus-sasl-gssapi \\\n     cyrus-sasl-plain krb5-libs libcurl net-snmp \\\n     net-snmp-libs openldap openssl xz-libs\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#rhelcentos-7x","title":"RHEL/CentOS 7.x","text":"<pre><code>sudo yum install cyrus-sasl cyrus-sasl-gssapi \\\n     cyrus-sasl-plain krb5-libs libcurl \\\n     lm_sensors-libs net-snmp net-snmp-agent-libs \\\n     openldap openssl tcp_wrappers-libs xz-libs\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#rhelcentos-8x","title":"RHEL/CentOS 8.x","text":"<pre><code>sudo yum install cyrus-sasl cyrus-sasl-gssapi \\\n     cyrus-sasl-plain krb5-libs libcurl \\\n     lm_sensors-libs net-snmp net-snmp-agent-libs \\\n     openldap openssl xz-libs\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#suse","title":"SUSE","text":""},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#suse-12x","title":"SUSE 12.x","text":"<pre><code>sudo zypper install cyrus-sasl cyrus-sasl-plain \\\n     cyrus-sasl-gssapi krb5 libcurl4 libldap-2_4-2 \\\n     libopenssl1_0_0 libsensors4 libsnmp30 libwrap0 \\\n     liblzma5\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#suse-15x","title":"SUSE 15.x","text":"<pre><code>sudo zypper install cyrus-sasl cyrus-sasl-plain \\\n     cyrus-sasl-gssapi krb5 libcurl4 libldap-2_4-2 \\\n     libopenssl1_1 libsensors4 libsnmp30 libwrap0 \\\n     liblzma5\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#installing-to-a-host-before-installing-mongodb","title":"Installing to a Host Before Installing MongoDB","text":"<p>If you deploy the MongoDB Agent to a host onto which you want to have Automation install MongoDB, ensure the system user that owns the MongoDB Agent has <code>Read</code> and <code>Write</code> permissions on the MongoDB data and log directories you plan to use.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/01-DeploymentPrerequisites/#installing-to-a-host-that-already-runs-mongodb","title":"Installing to a Host that Already Runs MongoDB","text":"<p>If you install the MongoDB Agent to a host on which Automation is managing a MongoDB process, the MongoDB Agent system user must have the following permissions:</p> <ul> <li>To stop the MongoDB process. The MongoDB Agent restarts the process using its own set of MongoDB binaries. If you had installed MongoDB with a package manager, use the same package manager to install the MongoDB Agent. This gives the MongoDB Agent the same owner as MongoDB.</li> <li>To <code>Read</code> and <code>Write</code> to the MongoDB data and log directories.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/03-AddK8SCluster/","title":"Add K8S Cluster","text":"<p>premise\uff1a</p> <p>\u200b   Add k8s conifg in setting, refer to Kubernetes.</p> <ol> <li>Click Server&gt;K8S on the left side of the navigation bar</li> </ol> <p></p> <ol> <li>Click Add Stateful Set</li> </ol> <p></p> <ol> <li>Complete the configuration of the parameters in the figure below. There are no special requirements. NS and Stateful Set meet the production requirements.</li> </ol> <p></p> <ol> <li>Click Confirm.</li> </ol> <p>At this point, the K8S cluster is added.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/","title":"Deploy a Standalone MongoDB Instance","text":"<p>Whaleal provides a wizard for adding your existing MongoDB deployments to monitoring and management. The wizard prompts you to:</p> <ul> <li>Install the Agent if you don't have it installed</li> <li>Identify the sharded cluster, the replica set, or the standalone to add.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/#procedure","title":"Procedure","text":""},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/#navigate-to-the-deployment-page-for-your-project","title":"Navigate to the Deployment page for your project.","text":"<ol> <li>If it is not already displayed, select your desired project from the Projects menu in the navigation bar.</li> <li>If it is not already displayed, click MongoDB in the sidebar.</li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/#create-new-standalone","title":"Create New Standalone.","text":"<ol> <li>Click the Create Cluster dropdown menu.</li> </ol> <ol> <li>Select Standalone.</li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/#configure-the-standalone-mongodb-instance","title":"Configure the standalone MongoDB instance.","text":"<p>In the Standalone section, complete the following fields.</p> Setting Description Project Select the Project name of your Standalone deployment. You cannot change this once set. Hostname Type the resolvable address for the host serving your MongoDB deployment. This can be a hostname or an IPv4 address. Port Type the IANA port number for your MongoDB deployment. Data Directory Type the system path to the database directory for this deployment. The default is /data/data_port. Version Select the MongoDB version for your standalone MongoDB deployment. Log File The log file and data file are in the same directory, and the directory cannot be customized. The default is <code>/data/data_port/mongodb.log</code>. AuthLevel Select authentication method BindIp The <code>BindIp</code> setting in MongoDB specifies the IP addresses that the MongoDB server will listen on for incoming connections."},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/#set-any-advanced-configuration-options-for-the-standalone-mongodb-instance","title":"Set any Advanced Configuration options for the standalone MongoDB instance.","text":"<p>In the Advanced Configuration Options section, add any additional runtime options you want to set for your MongoDB deployment.</p> <p>To add an option:</p> <ol> <li>Click Add Option.</li> </ol> <p></p> <ol> <li> <p>Select a Startup Option.</p> </li> <li> <p>Set an acceptable value for that Startup Option.</p> </li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/04-DeployStandalone/#click-create","title":"Click Create.","text":""},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/","title":"Deploy a Replica Set","text":"<p>Whaleal provides a wizard for adding your existing MongoDB deployments to monitoring and management. The wizard prompts you to:</p> <ul> <li>Install the Agent if you don't have it installed</li> <li>Identify the sharded cluster, the replica set, or the standalone to add. </li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#considerations","title":"Considerations","text":""},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#unique-names-for-replica-set","title":"Unique Names for Replica Set","text":"<p>Use a unique name for the replica set.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#procedure","title":"Procedure","text":""},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#navigate-to-the-deployment-page-for-your-project","title":"Navigate to the Deployment page for your project.","text":"<ol> <li>If it is not already displayed, select your desired project from the Projects menu in the navigation bar.</li> <li>If it is not already displayed, click MongoDB in the sidebar.</li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#open-the-cluster-creation-view","title":"Open the Cluster Creation View.","text":"<p>Click the Create Cluster arrow in the top-right of the MongoDB page. Select Replica Set from the drop-down menu to open the Create New Replica Set view.</p> <p></p>"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#configure-cluster-wide-settings","title":"Configure Cluster-Wide Settings.","text":"<p>The Replica Set Configuration section contains the following cluster-wide configuration settings. Settings marked with an * asterisk in the Whaleal UI are required**.</p> Setting Description Project Select the Project name of your replica set deployment. You cannot change this once set. Cluster Name The name of the replica set. It must be a unique name. BindIp The <code>BindIp</code> setting in MongoDB specifies the IP addresses that the MongoDB server will listen on for incoming connections. Version Select the MongoDB server version of the <code>mongod</code> process. AuthLevel Select authentication method"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#configure-each-replica-set-member","title":"Configure each Replica Set Member.","text":"<p>Whaleal lists each replica set member under the MongoD Settings heading of the Member Configuration section. Each replica set member has the following options:</p> Setting Description Member Select one of the following replica set member roles from the menu:<code>Ordinary member node</code>A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden node</code>A data-bearing member of the replica set that can vote in elections. Corresponds to the hidden replica configuration option.<code>Hidden delay node</code>A data-bearing member of the replica set that can vote in elections. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. For complete documentation on adding servers to Whaleal Automation.This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongod</code>process. This setting corresponds to the <code>net.port</code> configuration file option.The <code>mongod</code> must have exclusive access to the specified port. If deploying multiple <code>mongod</code> processes to a single host, you must select a unique unused port for each process. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary node and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code> replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code>replica set configuration option. Data Directory Specify the directory where the <code>mongod</code> process stores data files. This setting corresponds to the <code>storage.dbPath</code> <code>mongod</code> configuration file option. The Whaleal Automation must have file system permission to read, write, and execute all files and folders in the specified directory.Each <code>mongod</code> process must have its own database directory. If deploying multiple <code>mongod</code> processes on the same host, ensure each process has its own distinct directory. Log File The log file and data file are in the same directory, and the directory cannot be customized. Build Indexes Specify <code>true</code> to direct the <code>mongod</code> to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option."},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#configure-your-replication-settings","title":"Configure your Replication Settings.","text":"<p>The Replication Settings section contains the following configuration options for the replica set:</p> Setting Description Protocol Version Select the replication protocol version used by the replica set. This setting corresponds to the <code>protocolVersion</code> replica set configuration option. Chaining Allowed Specify <code>true</code> to allow secondary members to replicate from other secondary members. This setting corresponds to the <code>chainingAllowed</code> replica set configuration option. Write Concern Majority Journal Default Determines the behavior of <code>{w:\"majority\"}</code> write concern if the write concern does not explicitly specify the journal option <code>j</code>. This setting corresponds to the <code>writeConcernMajorityJournalDefault</code> replica set configuration option. Heartbeat Timeout (secs) Specify the number of seconds that the replica set members wait for a successful heartbeat from each other. This setting corresponds to the <code>heartbeatTimeoutSecs</code> replica set configuration option. Election Timeout (ms) Specify the time limit in milliseconds for detecting when a replica set's primary is unreachable. This setting corresponds to the <code>electionTimeoutMillis</code> replica set configuration option. CatchUp Timeout (ms) Specify the time limit in milliseconds for a newly elected primary to sync, or catch up, with the other replica set members that may have more recent writes. This setting corresponds to the <code>catchUpTimeoutMillis</code> replica set configuration option. CatchUp Takeover Delay (ms) Specify the time in milliseconds a node waits to initiate a catchup takeover after determining it is ahead of the current primary. This setting corresponds to the <code>catchUpTakeoverDelayMillis</code> replica set configuration option."},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#set-the-default-read-and-write-concerns-for-your-mongodb-replica-set","title":"Set the default read and write concerns for your MongoDB replica set.","text":"<p>In the Default Read Concerns/Write Concerns card, you configure the default level of acknowledgement requested from MongoDB for read and write operations for this cluster. Setting the default read and write concern can help with MongoDB 5.0 and later deployments using arbiters.</p> <p>From the Default Read Concerns section, you can set consistency and isolation properties for the data read from the cluster.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#set-any-advanced-configuration-options-for-your-mongodb-replica-set","title":"Set any advanced configuration options for your MongoDB replica set.","text":"<p>The Advanced Configuration Options section allows you to set MongoDB runtime options for each MongoDB process in your deployment.</p> <p>To add an option:</p> <ol> <li>Click Advanced Configuration.</li> </ol> <p></p> <ol> <li> <p>Click Add Option and select the configuration option.</p> </li> <li> <p>Whaleal displays a context-sensitive input for configuring an acceptable value for the selected option.</p> </li> <li> <p>Click Confirm to add the selected option and its corresponding value to every process of the selected process type in the cluster.</p> </li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/05-DeployReplicaSet/#click-create-replica-set","title":"Click Create Replica Set.","text":"<p>Whaleal automatically deploys the replica set as configured. You can monitor the progress of cluster deployment from the Deployment view.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/","title":"Deploy a Sharded Cluster","text":"<p>Whaleal provides a wizard for adding your existing MongoDB deployments to monitoring and management. The wizard prompts you to:</p> <ul> <li>Install the Agent if you don't have it installed</li> <li>Identify the sharded cluster, the replica set, or the standalone to add. You can choose to add the deployment to Monitoring or to both Monitoring and Automation.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#considerations","title":"Considerations","text":""},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#unique-names-for-sharded-clusters","title":"Unique Names for Sharded Clusters","text":"<p>Use unique names for the new cluster and its shards.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#important","title":"IMPORTANT","text":"<p>Replica set, sharded cluster, and shard names within the same project must be unique. Failure to have unique names for the deployments will result in broken backup snapshots.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#procedure","title":"Procedure","text":""},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#navigate-to-the-deployment-page-for-your-project","title":"Navigate to the Deployment page for your project.","text":"<ul> <li>If it is not already displayed, select your desired project from the Projects menu in the navigation bar.</li> <li>If it is not already displayed, click MongoDB in the sidebar.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#open-the-cluster-creation-view","title":"Open the Cluster Creation View.","text":"<p>Click the Create Cluster arrow in the top-right of the MongoDB page. Select Sharding Cluster from the drop-down menu to open the Create Sharding Cluster view.</p> <p></p>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#configure-cluster-wide-settings","title":"Configure Cluster-Wide Settings.","text":"<p>The Cluster Configuration section contains the following cluster-wide configuration settings. Settings marked with an * asterisk in the Whaleal UI are required**.</p> Setting Description Project Select the Project name of your replica set deployment. You cannot change this once set. Cluster Name The name of the replica set. It must be a unique name. BindIp The <code>BindIp</code> setting in MongoDB specifies the IP addresses that the MongoDB server will listen on for incoming connections. Version Select the MongoDB server version of the <code>mongod</code> process. AuthLevel Select authentication method"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#configure-each-shard-in-your-cluster","title":"Configure Each Shard in Your Cluster.","text":"<p>From the Member Configuration section, click Shard Settings to open the shard configuration options. Whaleal lists each shard in the cluster and the <code>mongod</code> processes associated to that shard. Each shard process has the following options:</p> Setting Description Member Select one of the following replica set member roles from the menu:<code>Ordinary member node</code>A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden node</code>A data-bearing member of the replica set that can vote in elections. Corresponds to the hidden replica configuration option.<code>Hidden delay node</code>A data-bearing member of the replica set that can vote in elections. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. For complete documentation on adding servers to Whaleal Automation.This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongod</code>process. This setting corresponds to the <code>net.port</code> configuration file option.The <code>mongod</code> must have exclusive access to the specified port. If deploying multiple <code>mongod</code> processes to a single host, you must select a unique unused port for each process. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary node and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code> replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code>replica set configuration option. Data Directory Specify the directory where the <code>mongod</code> process stores data files. This setting corresponds to the <code>storage.dbPath</code> <code>mongod</code> configuration file option. The Whaleal Automation must have file system permission to read, write, and execute all files and folders in the specified directory.Each <code>mongod</code> process must have its own database directory. If deploying multiple <code>mongod</code> processes on the same host, ensure each process has its own distinct directory. Log File The log file and data file are in the same directory, and the directory cannot be customized. Build Indexes Specify <code>true</code> to direct the <code>mongod</code> to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option. <p>To add additional shards to the cluster:</p> <ol> <li>Click Add a Shard.</li> <li>Under the Cluster Configuration section, set the following parameters for each <code>mongod</code> in the shard:</li> <li>Version</li> <li>Data Directory</li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#configure-each-configuration-server-in-your-cluster","title":"Configure Each Configuration Server in Your Cluster.","text":"Setting Description Member Select one of the following replica set member roles from the menu:<code>Ordinary member node</code>A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden node</code>A data-bearing member of the replica set that can vote in elections. Corresponds to the hidden replica configuration option.<code>Hidden delay node</code>A data-bearing member of the replica set that can vote in elections. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. For complete documentation on adding servers to Whaleal Automation.This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongod</code>process. This setting corresponds to the <code>net.port</code> configuration file option.The <code>mongod</code> must have exclusive access to the specified port. If deploying multiple <code>mongod</code> processes to a single host, you must select a unique unused port for each process. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary node and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code> replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code>replica set configuration option. Data Directory Specify the directory where the <code>mongod</code> process stores data files. This setting corresponds to the <code>storage.dbPath</code> <code>mongod</code> configuration file option. The Whaleal Automation must have file system permission to read, write, and execute all files and folders in the specified directory.Each <code>mongod</code> process must have its own database directory. If deploying multiple <code>mongod</code> processes on the same host, ensure each process has its own distinct directory. Log File The log file and data file are in the same directory, and the directory cannot be customized. Build Indexes Specify <code>true</code> to direct the <code>mongod</code> to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option."},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#configure-each-mongos-in-your-cluster","title":"Configure Each <code>mongos</code> in Your Cluster.","text":"<p>From the Member Configuration section, click Mongos Settings to open the <code>mongos</code> configuration options. Each <code>mongos</code> process has the following options:</p> Setting Description Hostname Select from the menu the host to which Whaleal Automation deploys the <code>mongos</code>. The menu only lists hosts under Whaleal Automation. For complete documentation on adding servers to Whaleal Automation. This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongos</code> process. This setting corresponds to the <code>net.port</code> configuration file option. Defaults to <code>27017</code>.The <code>mongos</code> must have exclusive access to the specified port. If deploying multiple <code>mongos</code> processes to a single host, you must select a unique unused port for each process. Add a Mongos Click to add an additional <code>mongos</code> process."},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#configure-each-replica-set-in-your-cluster","title":"Configure Each Replica Set in your Cluster.","text":"<p>The Replication Settings section contains the following configuration options for each replica set in the cluster:</p> Setting Description Replica Set Id Names of components in the sharded cluster Protocol Version Select the replication protocol version used by the replica set. This setting corresponds to the <code>protocolVersion</code> replica set configuration option.For more information, see Replica Set Protocol Versions. Chaining Allowed Specify <code>true</code> to allow secondary members to replicate from other secondary members. This setting corresponds to the <code>chainingAllowed</code> replica set configuration option. Write Concern Majority Journal Default Determines the behavior of <code>{w:\"majority\"}</code> write concern if the write concern does not explicitly specify the journal option <code>j</code>. This setting corresponds to the <code>writeConcernMajorityJournalDefault</code>replica set configuration option. Heartbeat Timeout (secs) Specify the number of seconds that the replica set members wait for a successful heartbeat from each other. This setting corresponds to the <code>heartbeatTimeoutSecs</code> replica set configuration option. Election Timeout (ms) Specify the time limit in milliseconds for detecting when a replica set's primary is unreachable. This setting corresponds to the <code>electionTimeoutMillis</code> replica set configuration option. CatchUp Timeout (ms) Specify the time limit in milliseconds for a newly elected primary to sync, or catch up, with the other replica set members that may have more recent writes. This setting corresponds to the <code>catchUpTimeoutMillis</code>replica set configuration option. CatchUp Takeover Delay (ms) Specify the time in milliseconds a node waits to initiate a catchup takeover after determining it is ahead of the current primary. This setting corresponds to the <code>catchUpTakeoverDelayMillis</code> replica set configuration option."},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#set-the-default-read-and-write-concerns-for-your-mongodb-replica-set","title":"Set the default read and write concerns for your MongoDB replica set.","text":"<p>In the Default Read Concerns/Write Concerns card, you configure the default level of acknowledgement requested from MongoDB for read and write operations for this cluster. Setting the default read and write concern can help with MongoDB 5.0 and later deployments using arbiters.</p> <p>From the Default Read Concerns section, you can set consistency and isolation properties for the data read from the cluster.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#set-any-advanced-configuration-options-for-your-mongodb-replica-set","title":"Set any advanced configuration options for your MongoDB replica set.","text":"<p>The Advanced Configuration Options section allows you to set MongoDB runtime options for each MongoDB process in your deployment.</p> <p>To add an option:</p> <ol> <li>Click Advanced Configuration.</li> </ol> <p></p> <ol> <li> <p>Click Add Option and select the configuration option.</p> </li> <li> <p>Whaleal displays a context-sensitive input for configuring an acceptable value for the selected option.</p> </li> <li> <p>Click Confirm to add the selected option and its corresponding value to every process of the selected process type in the cluster.</p> </li> </ol>"},{"location":"WhalealPlatform/04-CreateDeployment/06-DeployShardedCluster/#click-create-cluster","title":"Click Create Cluster.","text":"<p>Whaleal redirects you to the MongoDB List view, where you must review the cluster configuration before Whaleal begins deployment.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/","title":"Add Existing MongoDB Processes to Whaleal","text":""},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#considerations","title":"Considerations","text":""},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#unique-names","title":"Unique Names","text":"<p>Deployments must have unique names within the projects.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#important","title":"IMPORTANT","text":"<p>Replica set, sharded cluster, and shard names within the same project must be unique. Failure to have unique names for the deployments will result in broken backup snapshots.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#preferred-hostnames","title":"Preferred Hostnames","text":"<p>Set up a preferred hostname if you:</p> <ul> <li>Require a specific hostname or IPv4 address to access the MongoDB process, or</li> <li>Must specify the hostname to use for hosts with multiple aliases.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#authentication-credentials-on-source-and-destination-clusters","title":"Authentication Credentials on Source and Destination Clusters","text":"<p>If the Whaleal project has MongoDB authentication settings enabled for its deployments, the MongoDB deployment you import must support the project's authentication mechanism.</p> <p>We recommend that you import to a new destination project that has no running processes and doesn't have authentication enabled.</p> <p>If the source cluster uses authentication, and the destination Whaleal project doesn't have any existing managed processes, Whaleal enables authentication in the destination project.</p> <p>If the source cluster and the destination Whaleal project both use authentication, and the project has processes, Whaleal attempts to use existing authentication settings in the destination project during the import process. For the import process to succeed, authentication credentials on the source cluster and the Whaleal destination project must be the same.</p> <p>To ensure that import is successful, before you start the import process, add the Whaleal destination project's credentials on the source cluster. </p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#authentication-use-cases","title":"Authentication Use Cases","text":"<p>If your MongoDB deployment requires authentication, when you add the deployment to Whaleal for monitoring, you must provide the necessary credentials.</p> <ul> <li> <p>If the deployment doesn't use Automation, but did use Backup, Monitoring, or both, you can find those credentials where the credentials were before updating to the MongoDB Agent.</p> </li> <li> <p>If the deployment doesn't use Automation, but will use Backup, Monitoring, or both:</p> </li> <li>Create the credentials for the MongoDB Deployment. </li> <li> <p>Add the credentials that you granted to those functions to Whaleal after you add the MongoDB processes. </p> </li> <li> <p>If the deployment uses Automation,  Whaleal uses the credentials from the Agent. You can delete the credentials from the legacy Backup, and Monitoring Agents. The Agent uses those credentials for its Automation, Backup, and Monitoring functions.</p> </li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#automation-and-updated-security-settings-upon-import","title":"Automation and Updated Security Settings Upon Import","text":"<p>Adding a MongoDB deployment to automation may affect the security settings of the Whaleal project and the MongoDB deployment.</p> <ul> <li>Automation enables the Project Security Setting. If the MongoDB deployment requires authentication but the Whaleal project doesn't have authentication settings enabled, when you add the MongoDB deployment to automation, Whaleal updates the project's security settings to the security settings of the newly imported deployment.</li> </ul> <p>The import process only updates the Whaleal project's security setting if the project's security setting is currently disabled. The import process doesn't disable the project's security setting or change its enabled authentication mechanism.</p> <ul> <li>Automation Imports MongoDB Users and Roles. The following statements apply to situations where a MongoDB deployment requires authentication or the Whaleal project has authentication settings enabled.</li> </ul> <p>If the MongoDB deployment contains users or user-defined roles, you can choose to import these users and roles for Whaleal to manage. The imported users and roles are Synced to all managed deployments in the Whaleal project.</p> <ul> <li>Automation Applies to All Deployments in the Project. The project's updated security settings, including all users and roles managed by the Whaleal project, apply to all deployments in the project, including the imported MongoDB deployment.</li> </ul> <p>Whaleal restarts all deployments in the project with the new setting, including the imported MongoDB deployment. </p> <ul> <li>When using Whalea to manage MongoDB, Whaleal will create a wapAdmin user on the managed MongoDB. Whaleal manages the managed MongoDB through the wapAdmin user, which has administrator user privileges.</li> </ul>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>If mongod is enabled as a service on the deployment, a race condition might result where <code>systemd</code> starts <code>mongod</code> on reboot, rather than the Automation. To prevent this issue, ensure the <code>mongod</code> service is disabled before you add your deployment to Automation:</p> </li> <li> <p>Verify whether the <code>mongod</code> service is enabled:</p> </li> </ul> <pre><code>sudo systemctl is-enabled mongod.service\n</code></pre> <ul> <li>If the service is enabled, disable it:</li> </ul> <pre><code>sudo systemctl disable mongod.service\n</code></pre>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#important_1","title":"IMPORTANT","text":"<p>If you are adding a sharded cluster, you must create this user through the mongos and on every shard. That is, create the user both as a cluster wide user through mongos as well as a shard local user on each shard.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#procedures","title":"Procedures","text":""},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#add-mongodb-processes","title":"Add MongoDB Processes","text":"<p>To add existing MongoDB processes to Whaleal:</p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#1-navigate-to-the-mongodb-page-for-your-project","title":"1.  Navigate to the MongoDB page for your project.","text":"<p>\u200b   a. If it is not already displayed, select your desired project from the Projects menu in the navigation bar.</p> <p>\u200b   b.If it is not already displayed, click Deployment in the sidebar.</p>"},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#2-click-add-and-select-existing-mongodb-deployment","title":"2. Click Add and select Existing MongoDB Deployment.","text":""},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#3-follow-the-prompts-to-add-the-deployment","title":"3. Follow the prompts to add the deployment","text":"Cluster name Cluster name is the cluster name displayed on Whaleal Project In the drop-down box, select the cluster to which you want to manage MongoDB. Host Name Select the node where the MongoDB to be managed is located. Port Enter the port number of the MongoDB node to be managed. User Name The user of the Mongodb that needs to be managed. Password The password of the Mongodb that needs to be managed. Version Select the version of MongoDB that needs to be managed. If there is no suitable version, please upload the relevant version of MongoDB package in Setting&gt;&gt;MongoDB Packge."},{"location":"WhalealPlatform/04-CreateDeployment/07-DeployExistingCluster/#4after-the-configuration-is-complete-click-submit","title":"4.After the configuration is complete, click Submit","text":""},{"location":"WhalealPlatform/04-CreateDeployment/02-AddEC2/01-ResourceQuota/","title":"Resoucrce Quota","text":"<p>When adding an ec2 instance using a manually built WAP, the default resource quota is five ec2 instances.</p> <p>When adding more than five ec2 instances, further addition will fail. You can contact us according to the information in the yellow prompt bar.</p> <p></p>"},{"location":"WhalealPlatform/04-CreateDeployment/02-AddEC2/02-SubscribeAgent/","title":"Subscribe Agent","text":"<ol> <li> <p>Subscribe to Whaleal Platform Agent, refer to Install Whaleal in AWS MarketPlace</p> </li> <li> <p>Connecting to EC2 Instance</p> </li> </ol> <pre><code>sudo -i \n</code></pre> <ol> <li>Enter the /opt directory</li> </ol> <pre><code>cd /opt/agent\n</code></pre> <ol> <li>Modify the /opt/agent/parameters.properties file</li> </ol> <pre><code>vi parameters.properties\n\n#Modify the first line\n#In the configuration item \"foreign_url=\", replace Whaleal_Public_IP with Whaleal's public IP as follows\nforeign_url=http://Whaleal_Public_IP:8080\n</code></pre> <ol> <li>Restart the agent.</li> </ol> <pre><code>ps -ef | grep agent\nkill -9 Agent_PID\n</code></pre> <p>Wait two minutes and check to confirm that the agent has automatically restarted</p> <ol> <li>Go to Whaleal to check the EC2 management progress.</li> </ol> <p></p> <p></p>"},{"location":"WhalealPlatform/04-CreateDeployment/02-AddEC2/03-ManuallyAddAgent/","title":"Manually add Agent","text":"<ol> <li> <p>Start the EC2 instance and connect to it</p> </li> <li> <p>Visit Whaleal and click Server&gt;EC2&gt;Add Host&gt;Mode One on the left side of the navigation bar</p> </li> </ol> <p></p> <ol> <li>Select Project, then click Generate AGENT_ID</li> </ol> <p></p> <ol> <li>Install the agent</li> </ol> <p>Follow the prompts to execute all commands</p> <p></p> <ol> <li>View the agent process</li> </ol> <pre><code>ps -ef | grep agent\n</code></pre> <ol> <li>Go to Whaleal to check the EC2 management progress.</li> </ol> <p></p>"},{"location":"WhalealPlatform/05-ManageDeployments/01-ViewAllClusters/","title":"View All Clusters","text":""},{"location":"WhalealPlatform/05-ManageDeployments/01-ViewAllClusters/#note","title":"NOTE","text":"<p>For an Whaleal administrator, the view displays all deployments to which the administrator has access, not just those to which the administrator belongs.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/01-ViewAllClusters/#access-all-clusters-view","title":"Access All Clusters View","text":"<p>First, click MongoDB in the left navigation bar of Whaleal. Upon navigating to the MongoDB List page, you will have the option to filter clusters by various criteria. Administrator users can search and view all clusters without applying any filters. Additionally, clusters can be precisely filtered based on criteria such as Project, Type, Cluster Name, Node Name, or Operating System. Non-administrator users will only be able to view clusters within public projects or projects to which they have been granted access permissions.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/01-ViewAllClusters/#_1","title":"View All Clusters","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/","title":"Edit a Deployment's Configuration","text":"<p>You can modify a deployment's configuration and topology, including its MongoDB versions, and numbers of hosts or shards. You can make modifications at all levels of a deployment's topology from a top-level sharded cluster or replica set to lower levels, such as a replica set within a sharded cluster, or an individual process within a replica set. You can also modify standalone processes.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#considerations","title":"Considerations","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#mongodb-version","title":"MongoDB Version","text":"<p>Whaleal is applicable to MongoDB5.0 and later versions\uff0cyou can also manage versions before 5.0, but some functions may not be available and occasional problems may occur.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#fixed-properties","title":"Fixed Properties","text":"<p>You cannot modify the following settings after a deployment has been created:</p> <ul> <li><code>database path</code></li> <li>The hostname, <code>bind_ip</code> or <code>port</code> to which a MongoDB process is assigned</li> </ul> <p>You can modify the following deployment settings:</p> <ul> <li>advanced options</li> </ul>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#deployment-topology","title":"Deployment Topology","text":"<p>You can make modifications at all levels of a deployment's topology, including child processes.</p> <p>To modify the topology or processes, use this tutorial or one of the more specific tutorials:</p> <ul> <li>Convert a Standalone to a Replica Set</li> <li>Convert a Replica Set to a Shard Cluster</li> </ul>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#removing-a-shard","title":"Removing a Shard","text":"<p>For Sharded Clusters Only</p> <p>When you remove a shard, any unsharded databases in that shard are moved to a remaining shard using the movePrimary command.</p> <p>All sharded collections remain online and available during the shard removal process. However, read and write operations sent to unsharded collections during the <code>movePrimary</code> operation can result in unexpected behavior, including failure of the migration or loss of data.</p> <p>We recommend moving the primary shard for any databases containing unsharded collections before removing the shard.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#removing-multiple-replica-set-members","title":"Removing Multiple Replica Set Members","text":"<p>You can remove or migrate multiple replica set members at once, but a majority of the voting members must remain. If you need to remove more voting members, remove them one at a time.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#procedure","title":"Procedure","text":"<p>Select the type of deployment you want to edit:</p>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#standalone","title":"Standalone","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#in-the-operation-drop-down-list-next-to-the-deployed-cluster-click-cluster-modify","title":"In the Operation drop-down list next to the deployed cluster, click Cluster Modify.","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#modify-advanced-configuration-options","title":"Modify Advanced Configuration Options.","text":"<p>The Advanced Configuration Options section allows you to set MongoDB runtime options for each MongoDB process in your deployment.</p> <p>To add an option:</p> <ol> <li>Click Add Option.</li> </ol> <p></p> <ol> <li>Click Select and select the configuration option.</li> </ol> <p></p> <ol> <li> <p>Whalel displays a context-sensitive input for configuring an acceptable value for the selected option.</p> </li> <li> <p>Click Comfirm to add the selected option and its corresponding value to the process.</p> </li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#click-update","title":"Click Update.","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#replica-set","title":"Replica Set","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#in-the-operation-drop-down-list-next-to-the-deployed-cluster-click-cluster-modify_1","title":"In the Operation drop-down list next to the deployed cluster, click Cluster Modify.","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#modify-cluster-wide-settings","title":"Modify Cluster-Wide Settings.","text":"<p>The Replica Set Configuration section contains the following cluster-wide configuration settings.\\</p> <p></p>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#configure-each-replica-set-member","title":"Configure Each Replica Set Member.","text":"<p>Whaleal lists each replica set member under the Update Replica Set heading of the Member Configuration section. Each replica set member has the following configurable options:</p> <p></p> Setting Description Member Select one of the following replica set member roles from the menu:<code>Default</code>: A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden</code>: A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>hidden</code> replica configuration option.<code>Delayed Hidden</code>: A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>secondaryDelaySecs</code> and <code>hidden</code> replica configuration options. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongod</code> process. This setting corresponds to the <code>net.port</code> configuration file option. The <code>mongod</code> must have exclusive access to the specified port. If deploying multiple <code>mongod</code> processes to a single host, you must select a unique unused port for each process. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code>] replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code> replica set configuration option. Build Indexes Specify <code>true</code> to direct the <code>mongod</code> to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option. Add a Mongod Adds an additional <code>mongod</code> process as a replica set member.Adding a new <code>mongod</code> process also updates the list of processes in the Member Configuration section. You must configure the Version, Data Directory of the new process."},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#configure-your-replication-settings","title":"Configure your Replication Settings.","text":"<p>The Cluster Configuration section contains the following configuration options for the replica set:</p> <p></p> Setting Description Protocol Version Select the replication protocol version used by the replica set. This setting corresponds to the <code>protocolVersion</code> replica set configuration option. Chaining Allowed Specify <code>true</code> to allow secondary members to replicate from other secondary members. This setting corresponds to the <code>chainingAllowed</code> replica set configuration option. Write Concern Majority Journal Default Determines the behavior of <code>{w:\"majority\"}</code> write concern if the write concern does not explicitly specify the journal option <code>j</code>. This setting corresponds to the <code>writeConcernMajorityJournalDefault</code> replica set configuration option. Heartbeat Timeout (secs) Specify the number of seconds that the replica set members wait for a successful heartbeat from each other. This setting corresponds to the <code>heartbeatTimeoutSecs</code> replica set configuration option. Election Timeout (ms) Specify the time limit in milliseconds for detecting when a replica set's primary is unreachable. This setting corresponds to the <code>electionTimeoutMillis</code> replica set configuration option. CatchUp Timeout (ms) Specify the time limit in milliseconds for a newly elected primary to sync, or catch up, with the other replica set members that may have more recent writes. This setting corresponds to the <code>catchUpTimeoutMillis</code> replica set configuration option. CatchUp Takeover Delay (ms) Specify the time in milliseconds a node waits to initiate a catchup takeover after determining it is ahead of the current primary. This setting corresponds to the <code>catchUpTakeoverDelayMillis</code> replica set configuration option."},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#modify-advanced-configuration-options_1","title":"Modify Advanced Configuration Options.","text":"<p>The **Advanced Configuration ** section allows you to set MongoDB <code>runtime options</code> for each MongoDB process in your deployment.</p> <p>To add an option:</p> <ol> <li>Click Add Options.</li> </ol> <p></p> <ol> <li>Click Select and select the configuration option.</li> </ol> <p></p> <ol> <li> <p>Whaleal displays a context-sensitive input for configuring an acceptable value for the selected option.</p> </li> <li> <p>Click Confirm to add the selected option and its corresponding value to every process of the selected process type in the cluster.</p> </li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#click-update_1","title":"Click Update.","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#sharded-cluster","title":"Sharded Cluster","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#in-the-operation-drop-down-list-next-to-the-deployed-cluster-click-cluster-modify_2","title":"In the Operation drop-down list next to the deployed cluster, click Cluster Modify.","text":""},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#modify-cluster-wide-settings_1","title":"Modify Cluster-Wide Settings.","text":"<p>From the Member Configuration section, click Shard Settings to open the shard configuration options. Whaleal lists each shard in the cluster and the <code>mongod</code> processes associated to that shard. Each shard process has the following options. You cannot modify options that are greyed out:</p> <p></p> Setting Description Member Select one of the following replica set member roles from the menu:<code>Default</code>: A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden</code>: A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>hidden</code> replica configuration option.<code>Delayed Hidden</code>: A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>secondaryDelaySecs</code> and <code>hidden</code> replica configuration options. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. This hostname can be a hostname or an IPv4 address. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code>] replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code> replica set configuration option. Build Indexes Specify <code>true</code> to direct the <code>mongod</code> to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option. Add a Mongod Adds an additional <code>mongod</code> process as a replica set member.Adding a new <code>mongod</code> process also updates the list of processes in the Member Configuration section. You must configure the Version, Data Directory of the new process. <p>To add additional shards to the cluster:</p> <ol> <li>Click Add a Shard.</li> </ol> <p></p> <ol> <li>Under the Cluster Configuration section, set the following parameters for each <code>mongod</code> in the shard:</li> <li>Version</li> <li>Data Directory</li> <li>Log File</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#configure-each-configuration-server-in-your-cluster","title":"Configure Each Configuration Server in Your Cluster.","text":"<p>From the Member Configuration section, click Config Server Replica Set Settings to open the CSRS configuration options. Each config server replica set member has the following options:</p> <p></p> Setting Description Member Select one of the following replica set member roles from the menu:<code>Default</code>: A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden</code>: A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>hidden</code> replica configuration option.<code>Delayed Hidden</code>: A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>secondaryDelaySecs</code> and <code>hidden</code> replica configuration options. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongod</code> process. This setting corresponds to the <code>net.port</code> configuration file option. Defaults to <code>27017</code>.The <code>mongod</code> must have exclusive access to the specified port. If deploying multiple <code>mongod</code> processes to a single host, you must select a unique unused port for each process. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code> replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code> replica set configuration option. Build Indexes Specify <code>true</code> to direct the <code>mongod</code>] to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option. This setting corresponds to the <code>tags</code> <code>mongod</code> replica set configuration option. Add a Mongod Adds an additional <code>mongod</code> process as a replica set member.Adding a new <code>mongod</code> process also updates the list of processes in the Cluster Configuration section. You must configure the Version  and Data Directory of the new process."},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#configure-each-mongos-in-your-cluster","title":"Configure Each <code>mongos</code> in Your Cluster.","text":"<p>From the Member Configuration section, click Mongos Settings to open the <code>mongos</code> configuration options. Each <code>mongos</code> process has the following options:</p> <p></p> Setting Description Hostname Select from the menu the host to which Whaleal Automation deploys the <code>mongos</code>. The menu only lists hosts under Whaleal Automation. For complete documentation on adding servers to Whaleal Automation. This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongos</code> process. This setting corresponds to the <code>net.port</code> configuration file option. Defaults to <code>27017</code>.The <code>mongos</code> must have exclusive access to the specified port. If deploying multiple <code>mongos</code> processes to a single host, you must select a unique unused port for each process. Add a Mongos Click to add an additional <code>mongos</code> process."},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#configure-each-replica-set-in-your-cluster","title":"Configure Each Replica Set in your Cluster.","text":"<p>The Replication Settings section contains the following configuration options for each replica set in the cluster:</p> <p></p> Setting Description Protocol Version Select the replication protocol version used by the replica set. This setting corresponds to the <code>protocolVersion</code> replica set configuration option.For more information, see Replica Set Protocol Versions. Chaining Allowed Specify <code>true</code> to allow secondary members to replicate from other secondary members. This setting corresponds to the <code>chainingAllowed</code> replica set configuration option. Write Concern Majority Journal Default Determines the behavior of <code>{w:\"majority\"}</code> write concern if the write concern does not explicitly specify the journal option <code>j</code>. This setting corresponds to the <code>writeConcernMajorityJournalDefault</code>replica set configuration option. Heartbeat Timeout (secs) Specify the number of seconds that the replica set members wait for a successful heartbeat from each other. This setting corresponds to the <code>heartbeatTimeoutSecs</code> replica set configuration option. Election Timeout (ms) Specify the time limit in milliseconds for detecting when a replica set's primary is unreachable. This setting corresponds to the <code>electionTimeoutMillis</code> replica set configuration option. CatchUp Timeout (ms) Specify the time limit in milliseconds for a newly elected primary to sync, or catch up, with the other replica set members that may have more recent writes. This setting corresponds to the <code>catchUpTimeoutMillis</code>replica set configuration option. CatchUp Takeover Delay (ms) Specify the time in milliseconds a node waits to initiate a catchup takeover after determining it is ahead of the current primary. This setting corresponds to the <code>catchUpTakeoverDelayMillis</code> replica set configuration option."},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#set-any-advanced-configuration-options-for-your-mongodb-replica-set","title":"Set any advanced configuration options for your MongoDB replica set.","text":"<p>The Advanced Configuration Options section allows you to set MongoDB runtime options for each MongoDB process in your deployment.</p> <p>To add an option:</p> <ol> <li>Click Advanced Configuration.</li> </ol> <p></p> <ol> <li>Click Add Option and select the configuration option.</li> </ol> <p></p> <ol> <li> <p>Whaleal displays a context-sensitive input for configuring an acceptable value for the selected option.</p> </li> <li> <p>Click Confirm to add the selected option and its corresponding value to every process of the selected process type in the cluster.</p> </li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/02-EditDeploymentConfiguration/#click-update_2","title":"Click Update","text":""},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/","title":"Edit a Replica Sets","text":""},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/#overview","title":"Overview","text":"<p>You can add, remove, and reconfigure members in a replica setdirectly in the Whaleal console.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/#procedures","title":"Procedures","text":""},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/#add-a-replica-set-member","title":"Add a Replica Set Member","text":"<p>You must have an existing server to which to deploy the new replica set member. To add a member to an existing replica set, increasing the size of the set:</p> <ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li> <p>On the card with the replica set, click Cluster Modify.</p> </li> <li> <p>In Member Configuration, click Add+.</p> </li> </ol> <p></p> <ol> <li>In Hostname, select the host that you want to add as a new member of the replica set.</li> </ol> <p>Use the following procedure to add the host if it doesn't appear in the Hostname list:</p> <p>\u200b        a. In Hostname, select New Server.</p> <p>\u200b            If no hosts have yet been added to the project, the Hostname list does not appear. Click Server instead.</p> <p>\u200b        b. In the Server dialog, select your operating system and click Add Host.</p> <p>\u200b        c. Follow the instructions to install an Agent on the new host.</p> <ol> <li>Click Update.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/#edit-a-replica-set-member","title":"Edit a Replica Set Member","text":"<ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li> <p>On the card with the replica set, click Cluster Modify.</p> </li> <li> <p>In Member Configuration, modify the settings for the replica set member that you want to edit.</p> </li> </ol> Votes Specify whether the replica set member votes in elections. A value of <code>1</code> indicates the member votes, while a value of <code>0</code> indicates that the member does not vote. Priority Specify the priority of the replica set member during elections. Non-voting members must have a priority of <code>0</code>. Build Indexes Specify whether the replica set member builds indexes. <p></p> <ol> <li>Click Update.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/#remove-a-replica-set-member","title":"Remove a Replica Set Member","text":"<ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li> <p>On the card with the replica set, click Cluster Modify.</p> </li> <li> <p>In Member Configuration, to find the target mongod process, click the red delete button on the right.</p> </li> </ol> <p></p> <ol> <li>Click Update.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/03-EditsReplicaSets/#edit-a-cluster-configuration","title":"Edit a Cluster Configuration","text":"<ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li> <p>On the card with the replica set, click Cluster Modify.</p> </li> <li> <p>Configure the replica set in Cluster Configuration.</p> </li> </ol> <p></p> <ol> <li>Click Update.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/04-ShardedClusterOperations/","title":"Sharded Cluster Operations","text":""},{"location":"WhalealPlatform/05-ManageDeployments/04-ShardedClusterOperations/#add-a-shard-to-a-mongodb-cluster","title":"Add a Shard to a MongoDB Cluster","text":"<ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b    a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b    b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b    Click the Clusters view.</p> <ol> <li> <p>On the card with the replica set, click Cluster Modify.</p> </li> <li> <p>In the Member Configuration section, add a shard.</p> </li> </ol> <p></p> <p>\u200b        a. Expand shard settings.</p> <p>\u200b        b. Click Add a Shard to add <code>mongod</code> processes to the shard.</p> <p>## Review and update settings for the new shard as needed</p> Setting Description Member <code>Ordinary member node</code>:  A data-bearing member of the replica set that can become the primary and vote in elections.<code>Hidden node</code>:  A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>hidden</code> replica configuration option.<code>Hidden Delayed node</code> :  A data-bearing member of the replica set that can vote in elections. Corresponds to the <code>secondaryDelaySecs</code> and <code>hidden</code> replica configuration options. Hostname Select from the menu the host to which Whaleal Automation deploys the replica set member. The menu only lists hosts under Whaleal Automation. This hostname can be a hostname or an IPv4 address. Port Specify the IANA port number for the <code>mongod</code> process. This setting corresponds to the <code>net.port</code> configuration file option. Defaults to <code>27017</code>.The <code>mongod</code> must have exclusive access to the specified port. If deploying multiple <code>mongod</code> processes to a single host, you must select a unique unused port for each process. Votes Specify the number of votes that the replica set member has during elections. This setting corresponds to the <code>votes</code> <code>mongod</code> replica set configuration option. Priority Specify the priority of the member during elections. Replica set members with a priority of <code>0</code> cannot become the primary and cannot trigger elections. This setting corresponds to the <code>priority</code> <code>mongod</code> replica set configuration option. Delay Specify the number of seconds \"behind\" the primary member this member should \"lag\". This setting corresponds to the <code>secondaryDelaySecs</code> <code>mongod</code> replica set configuration option. Build Indexes Specify <code>true</code> to direct the <code>mongod</code>] to build indexes. This setting corresponds to the <code>buildIndexes</code> <code>mongod</code> replica set configuration option. This setting corresponds to the <code>tags</code> <code>mongod</code> replica set configuration option. <ol> <li>Click the Update to add the new shard to the cluster.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/04-ShardedClusterOperations/#remove-a-shard-to-a-mongodb-cluster","title":"Remove a Shard to a MongoDB Cluster","text":"<ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li> <p>On the card with the replica set, click Cluster Modify.</p> </li> <li> <p>In the Member Configuration section, remove a shard.</p> </li> </ol> <p></p> <p>This operation needs to be performed with caution</p> <ol> <li>Click the Update to remove a  shard from the cluster.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/05-StopManagingandorMonitoringOneDeployment/","title":"Stop Managing and/or Monitoring One Deployment","text":""},{"location":"WhalealPlatform/05-ManageDeployments/05-StopManagingandorMonitoringOneDeployment/#stop-management","title":"Stop management","text":"<p>If you do not want to use Whaleal to manage the cluster, you can remove the cluster from management.</p> <ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li>On the card with the cluster, click Remove from WAP.</li> </ol> <p></p> <ol> <li>Click the Confirm button in the pop-up window to confirm the removal</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/05-StopManagingandorMonitoringOneDeployment/#stop-monitoring","title":"Stop Monitoring","text":"<ol> <li>Navigate to the Clusters view for your deployment.</li> </ol> <p>\u200b        a. If it is not already displayed, select your desired project from the MongoDB menu in the navigation bar.</p> <p>\u200b        b. If it is not already displayed, select your desired project from the Projects menu in the drop-down box options.</p> <p>\u200b        Click the Clusters view.</p> <ol> <li>On the card with the cluster, click Turn off Monitoring.</li> </ol> <p></p> <ol> <li>Click the Confirm button in the pop-up window to confirm the removal</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/","title":"MongoDB Operation","text":"<p>By managing MongoDB clusters with Whaleal, we can start, shut down, restart, and other operations on the managed clusters. By clicking on the UI interface, we can easily implement these operations. The following is a list of operations that can be performed on the cluster using Wahaleal.</p> <p></p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#connect-to-this-instance","title":"Connect to this instance","text":"<ol> <li>check the Connect to this instance button</li> <li> <p>Select the connection method and click the corresponding button. The currently provided connection methods are shell,  java , and python.</p> </li> <li> <p>Modify the username and password in the MongoDB connection string to use it</p> </li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#update-cluster-info","title":"Update Cluster Info","text":"<ol> <li>check the Update Cluster Info button</li> <li>Whaleal updates cluster information every 10 seconds or longer by default. If we want to obtain the cluster information of the current cluster, we can use the Update Cluster Info button to obtain the current cluster information.</li> </ol>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#startup","title":"Startup","text":"<p>When the cluster is in the close state, we can start the cluster through Startup button.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#shutdown","title":"Shutdown","text":"<p>When the cluster is in the Health state, we can shut down the cluster through Shutdown button.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#restart","title":"Restart","text":"<p>When the cluster is in the Health state, we can restart the cluster through Shutdown button.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#rename","title":"Rename","text":"<p>If you want to change the cluster name displayed in WAP, click rename to change the cluster name, but only change the cluster name displayed in Whaleal.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#version-modify","title":"Version Modify","text":"<p>Whaleal can upgrade and downgrade the managed clusters, but it cannot upgrade or downgrade across versions and needs to be operated step by step.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#note","title":"note:","text":"<p>Upload the relevant versions of the MongoDB service packages needed during the upgrade and downgrade process to the WAP in advance through Settings&gt;MongoDB Packge in the navigation bar.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#upgrade","title":"Upgrade:","text":"<p>Before upgrading, you need to upload the target MongoDB version and all versions involved in the upgrade process to WAP. The upgrade process is a step-by-step upgrade and cross-version upgrade is not allowed.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#downgrade","title":"Downgrade:","text":"<p>Before downgrading, you need to upload the target MongoDB version and all versions involved in the upgrade process to WAP. The upgrade process is a step-by-step downgrade, and cross-version downgrade is not allowed.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#logrotaate-startegy","title":"LogRotaate Startegy","text":"<p>The log is split once a day. You can configure the split time according to the options. The time used is the punctual time (UTC time)</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#convert-to-replste","title":"Convert to ReplSte","text":"<p>Slandalone architecture-specific operation options.</p>"},{"location":"WhalealPlatform/05-ManageDeployments/06-MongoDBOperation/#convert-to-sharded-cluster","title":"Convert to Sharded Cluster","text":"<p>Operation options specific to the Replica Set architecture.</p>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/","title":"Monitoring Instructions","text":"<p>Whaleal can monitor more than 30 aspects of MongoDB, including host-level monitoring and MongoDB-level monitoring. Monitoring is enabled by default, and we can also turn off monitoring. If you need to turn off monitoring, first click MongoDB, enter the MongoDB List page, then select the project we need to operate, and then click the magnifying glass icon to find the target cluster. After finding the target cluster, find Turn off Monitoring in the drop-down box on the right side of the cluster, click it, and then click Confirm to turn off the monitoring of the cluster.</p>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#why-use-monitoring-mongodb","title":"Why use monitoring MongoDB?","text":""},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Improved Query Performance: By tracking metrics like Opcounters, Latency, and ScanAndOrder, you can identify and optimize slow queries, ensuring faster response times.</li> <li>Resource Utilization: Monitoring CPU, Memory, and Disk IOPS helps in identifying resource bottlenecks and optimizing the allocation of system resources to maintain smooth operations.</li> </ul>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#reliability-and-availability","title":"Reliability and Availability","text":"<ul> <li>Early Issue Detection: Metrics such as Page Faults, Connections, and Asserts allow for the early detection of potential issues, preventing downtime and ensuring high availability.</li> <li>Replication Health: Monitoring Oplog Window and OplogSize is crucial for maintaining replication health and ensuring data redundancy, which is vital for disaster recovery.</li> </ul>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#scalability","title":"Scalability","text":"<ul> <li>Capacity Planning: By observing trends in metrics like System Memory, LogicalSize, and IndexSize, you can effectively plan for scaling your MongoDB deployment, whether vertically (adding more resources) or horizontally (adding more nodes).</li> <li>Load Balancing: System Network and Network metrics help in understanding network traffic patterns, allowing for better load distribution across the database cluster.</li> </ul>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#security","title":"Security","text":"<ul> <li>Unauthorized Access Detection: By monitoring Connections and Network activity, you can detect unusual patterns that might indicate security breaches or unauthorized access attempts.</li> <li>Data Integrity: Ensuring that backup and replication processes are functioning correctly through Oplog Window and Logical DataSize metrics helps maintain data integrity.</li> </ul>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#operational-efficiency","title":"Operational Efficiency","text":"<ul> <li>Automated Alerts and Troubleshooting: Setting up alerts based on key metrics (e.g., high CPU usage, excessive Page Faults) reduces the manual effort required to monitor the system and allows for quick troubleshooting.</li> <li>Efficient Resource Management: Continuous monitoring of resource usage (CPU, Memory, Disk IOPS) ensures that resources are used efficiently, preventing over-provisioning and under-utilization.</li> </ul>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#compliance-and-reporting","title":"Compliance and Reporting","text":"<ul> <li>Regulatory Compliance: Detailed monitoring provides necessary logs and audit trails for compliance with regulatory requirements.</li> <li>Internal Audits: Regular reporting on metrics such as Asserts, LockCondition, and Transactions helps in conducting internal audits to ensure adherence to operational standards.</li> </ul>"},{"location":"WhalealPlatform/06-Monitor/01-MonitoringInstructions/#user-experience","title":"User Experience","text":"<ul> <li>Enhanced User Experience: By ensuring low latency and high availability, monitoring directly contributes to a better user experience for applications relying on MongoDB.</li> <li>Proactive Issue Resolution: Early detection of issues through metrics like Page Faults, LockCondition, and Tickets allows for proactive resolution, minimizing the impact on end-users.</li> </ul> <p>For more information about specific monitoring indicators, please refer to Monitoring indicator details</p>"},{"location":"WhalealPlatform/06-Monitor/02-UsageMonitoring/","title":"Usage Monitoring","text":"<p>When using monitoring, configure the following three options according to your needs.</p>"},{"location":"WhalealPlatform/06-Monitor/02-UsageMonitoring/#monitoring-time-period","title":"Monitoring time period","text":"<p>When using monitoring, we can choose the monitoring time period according to our needs. There are three default options, namely Real Time, Last 1 Day, and Last 7 Day. Of course, if we want to configure other time periods to view monitoring, we can also directly configure Start Time and End Time.</p> <p></p>"},{"location":"WhalealPlatform/06-Monitor/02-UsageMonitoring/#monitoring-granularity","title":"Monitoring granularity","text":"<p>In order to better observe the changes in certain indicators, we can configure different granularities.</p> <p></p>"},{"location":"WhalealPlatform/06-Monitor/02-UsageMonitoring/#monitoring-metrics","title":"Monitoring Metrics","text":"<p>If we focus on which indicators, we can select different indicators as needed, so that the entire monitoring page looks simpler and clearer.The selected indicator will appear in the box above the drop-down box. It is also very simple to delete the monitoring indicator. Just click the cross after the indicator in the box to delete the displayed indicator.</p> <p></p>"},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/","title":"Monitoring Indicator Details","text":""},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/#system-resource-metrics","title":"System Resource Metrics","text":"<ol> <li>CPU: Monitors the CPU usage to identify if the system is overloaded.</li> </ol> <ol> <li>Memory Swap: Tracks swap space usage. Excessive swapping can degrade performance.</li> </ol> <ol> <li>System Memory: Observes overall memory usage to ensure there\u2019s enough available for MongoDB operations.</li> </ol> <ol> <li>System Network: Monitors network throughput and latency to identify potential network bottlenecks.</li> </ol> <ol> <li>Disk IOPS: Measures input/output operations per second on the disk, indicating how quickly data is read from or written to the disk.</li> </ol> <ol> <li>DiskInfo: Provides detailed information about disk usage and health.</li> </ol>"},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/#mongodb-specific-metrics","title":"MongoDB-specific Metrics","text":"<ol> <li>Opcounters: Tracks the number of operations (insert, query, update, delete, etc.) performed.</li> </ol> <ol> <li>Connections: Monitors the number of active client connections to ensure the system can handle the load.</li> </ol> <ol> <li>Page Faults: Measures the rate of page faults, indicating how often MongoDB needs to read data from disk into memory.</li> </ol> <ol> <li>Memory: Tracks MongoDB\u2019s internal memory usage, including how much memory is used by different components.</li> </ol> <ol> <li>Network: Monitors MongoDB network traffic to ensure data is being transmitted efficiently.</li> </ol> <ol> <li>Asserts: Tracks internal database assertions, which can indicate potential issues or bugs.</li> </ol>"},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/#cache-metrics","title":"Cache Metrics","text":"<ol> <li>Cache Flow: Measures the flow of data into and out of the cache, indicating cache efficiency.</li> </ol> <ol> <li>Cache Usage: Monitors how effectively the cache is being utilized.</li> </ol>"},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/#performance-metrics","title":"Performance Metrics","text":"<ol> <li>Latency: Measures the response time for queries, helping to identify performance bottlenecks.</li> </ol> <ol> <li>Tickets: Tracks the availability of tickets for read and write operations, indicating resource contention.</li> </ol> <ol> <li>Target Query: Monitors the performance of specific targeted queries.</li> </ol> <ol> <li>ScanAndOrder: Tracks operations where MongoDB must scan documents and order them in memory, which can be resource-intensive.</li> </ol> <ol> <li>CollectionSCAN: Measures the frequency of collection scans, which are less efficient than indexed queries.</li> </ol>"},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/#document-and-data-metrics","title":"Document and Data Metrics","text":"<ol> <li>Document Info: Provides details about the number and size of documents.</li> </ol> <ol> <li>Deleted Document: Tracks the rate at which documents are deleted.</li> </ol> <ol> <li>Oplog Window: Monitors the size of the oplog window, crucial for replication lag and recovery.</li> </ol> <ol> <li>LogicalSize: Measures the logical size of the database, providing insight into data growth.</li> </ol> <ol> <li>OpenCursor: Tracks the number of open cursors, indicating active database operations.</li> </ol> <ol> <li>Logical DataSize: Measures the logical size of data stored in MongoDB.</li> </ol> <ol> <li>IndexSize: Tracks the size of indexes, impacting query performance.</li> </ol> <ol> <li>OplogSize: Monitors the size of the oplog, essential for replication health.</li> </ol>"},{"location":"WhalealPlatform/06-Monitor/03-MonitoringIndicatorDetails/#lock-and-transaction-metrics","title":"Lock and Transaction Metrics","text":"<ol> <li>LockCondition: Tracks lock contention within MongoDB, which can affect performance.</li> </ol> <ol> <li>DatabaseLock: Measures the time the database is locked for various operations.</li> </ol> <ol> <li>CollectionLock: Monitors lock contention at the collection level.</li> </ol> <ol> <li>Transaction Condition: Tracks transaction performance and conflicts.</li> </ol>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/","title":"Restore","text":"<p>Backup data restore,  You can restore snapshot backup data to the current cluster or a specified cluster. If DDT is used for backup, you can restore it to any point in time during the backup period.</p> <p>To restore a deployment from a backup, select a snapshot or point in time from which you want to restore your database. Whaleal provides you with the files from which you can restore your database.</p> <p>You can restore a replica set, or all shards in a sharded cluster.</p> <p>You can restore a deployment from an existing snapshot or a specific point in time. For the point in time, you can specify a date and time.</p> <p>To restore your backup, use one of these options:</p> <ul> <li>Restore the files to another cluster using automation</li> <li>Restore the files to current cluster using automation</li> </ul> <p></p>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#restore_1","title":"Restore","text":"<p>To restore:</p> <ol> <li> <p>Navigate to the Backup &gt; Restore History tab.</p> </li> <li> <p>Click Restore.</p> </li> </ol>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#snapshot","title":"snapshot","text":"<p>If you choose to have Whaleal automation restore your backup, the Automation removes all existing data from the target hosts and replaces that data with new backup data from your snapshot.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#point-in-time","title":"point in time","text":"<p>If you select point in time to restore to the specified point in time, you can restore to any point in time between the start of backup and the current point in time. However, the target of recovery cannot be the current cluster, You can only restore to a new cluster.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#limitations","title":"Limitations","text":"<p>If you are restoring a sharded cluster, you must restore all shards. And the recovery target must be consistent with the source cluster architecture (number of fragments) and version. The restore process fails if you try to restore a single shard in a sharded cluster.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#prerequisites","title":"Prerequisites","text":"<p>To perform automated restores:</p> <p>Install an MongoDB Agent installed on the source and all target hosts, and check that an MongoDB Agent on the target deployment can connect to all hosts in the target deployment.</p> <p>Potential Causes for Automated Restore Failure An automated restore can fail when certain storage settings of the backup's database and target database do not match:</p> <ul> <li>storage.engine</li> <li>storage.directoryPerDB</li> <li>storage.mmapv1.nsSize</li> <li>storage.mmapv1.smallFiles</li> <li>storage.wiredTiger.collectionConfig.blockCompressor</li> <li>storage.wiredTiger.engineConfig.directoryForIndexes</li> </ul> <p>An automated restore fails when you attempt to restore a single shard in a sharded cluster. If you are restoring a sharded cluster, you must restore all shards.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#manual-restore","title":"Manual Restore","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#prerequisites_1","title":"Prerequisites","text":"<p>To perform manual restores, you must have the Backup Admin role in Whaleal.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/02-Restore/#restore-file-format","title":"Restore File Format","text":"<p>Whaleal provides each snapshot as an uncompressed (.tar) or compressed (.tar.gz) archive containing a complete copy of the data directory.</p> <p>Choosing compressed snapshots results in faster delivery, but requires sufficient space on the target host for both the compressed snapshot and its extracted database files.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/","title":"Create Repository","text":"<p>The bacckup function of the WAP platform is implemented based on two methods: dump and DDT. mongodump is a toolkit provided by MongoDB, and DDT is a full-volume, full-volume + incremental, full-volume + real-time backup tool implemented by MongoDB Oplog. Provide users with all-round backup functions.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#backup-architecture-diagram","title":"Backup architecture diagram","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#dump","title":"dump","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#ddt","title":"DDT","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#start-a-backup","title":"Start A Backup","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#navigate-to-the-create-repository-page","title":"Navigate to the Create Repository page.","text":"<ol> <li>Find the Backup option in the menu bar, click Backup in the drop-down menu to enter the Backup page. </li> <li>Click Create Repository to start cluster backup.</li> </ol>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#configure-backup-parameters","title":"Configure backup parameters","text":"Parameters Description Name Name of the backup policy. Type Backup type, optional values:ddt: Backup through backup programdump: Backup through the MongoDB tool mongodump. MongoDB Cluster MongoDB cluster to be backed up. DDT Host The host for deploy DDT, which must be in the DDT Project. MongoDB Host The host deploy MongoDB for used to store backup data. Storage Location Method of uploading backup S3 files (supports AWS S3 and Linode Object Storage). Task Snapshots Every Frequency of backing up data (every 1 day or every 7 days). Keep S3 File Days Number of days to keep the snapshot files in S3. Recover Data From Days Number of days to retain oplog incremental data (used for data recovery to a specific point in time), this number should be less than the snapshot file retention days. Cache Size Of 47019 Cache size setting for full MongoDB service. Cache Size Of 57019 Cache size setting for incremental MongoDB service. DDT Of Oplog JVM memory setting for incremental DDT backup Java service. DDT Of Full JVM memory setting for full DDT backup Java service. DDT Of Replay Oplog JVM memory setting for data recovery DDT Java service. dump_restore_work_num Number of collections dump &amp; restore should export in parallel restore_drop_collection Before restoring the collections from the dumped backup, drops the collections from the target database, optional values: 0, 1."},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/01-CreateRepository/#view-backup-tasks","title":"View Backup Tasks","text":"Parameters Description Event Log View all log records throughout the life cycle of a backup task. Full MongoDB Cluster MongoDB for full backup data storage. Oplog MongoDB Cluster MongoDB for incremental Oplog backup data storage. DDT Host Name Server on which DDT is deployed. DDT MongoDB Name Server where full backup data and incremental Oplog backup data are deployed. Advance Configuration Configuration of maximum usage limit of backup resources. Task Log View the logs of each backup program in the backup task."},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/","title":"Operations","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#backup-records","title":"Backup Records","text":""},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#backup","title":"BackUp","text":"<p>Displays a list of all snapshots, including snapshot files, creation time, expiration time, backup progress and other information of all nodes in the cluster. You can also view the running log of the entire backup cycle through Event Log.</p> <p></p> Parameters Description Sub Name Task Name. BackUp File Name The name and S3 download address of the cluster backup data file. DDT Task Name DDT backup task log details. Elapsed Time to generate backup snapshots. Items Total number of documents backed up by snapshots. Progress Progress percentage. Create Time Snapshot file creation time. Transfered Backup file size."},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#restore","title":"Restore","text":"<p>A list of backup data recovery tasks displays all backup and recovery operation records, and contains detailed information about specific tasks, including task execution time, task execution log, etc.</p> <p></p> Parameters Description Sub Name Task Name. BackUp File Name None DDT Task Name DDT restore task log details. Elapsed Time to generate restore snapshots. Items Total number of documents restore up by snapshots. Progress progress percentage. Create Time Snapshot file creation time. Transfered None"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#update","title":"update","text":"<p>Update task status. Get the latest backup and restore tasks and task status.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#take-a-snapshot","title":"Take a Snapshot","text":"<p>Restart the new snapshot task and generate a new snapshot. Specific details can be viewed in Backup Records.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#stop","title":"Stop","text":"<p>Stop the backup task.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#delete","title":"Delete","text":"<p>Delete backup policies and clarify all backup data files.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#rebuild","title":"Rebuild","text":"<p>Rebuild backup tasks and recreate backup snapshots.</p>"},{"location":"WhalealPlatform/07-BackupAndRestore/01-Backup/02-Operations/#edit","title":"Edit","text":"<p>Modify the backup policy.</p>"},{"location":"WhalealPlatform/08-Security/01-ConfigureFirewalltoAccessWhaleal/","title":"Firewall Configuration","text":"<p>In order to ensure that WAP services and their components can run smoothly and interact effectively, appropriate ports must be opened for communication and data exchange. WAP services involve multiple key components, including WAP applications and WAP agents, which connect and transmit data through network ports.</p> <p>For firewall configuration, please refer to:</p> <ul> <li>HardwareAndSoftwareRequirements</li> </ul>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/01-MongoDBAccessControl/","title":"Configure MongoDB Authentication and Authorization","text":"<p>Your  MongoDB deployment can use the access control mechanisms described on this page. You can specify authentication settings when you add a deployment. After you add a deployment, you can edit the security settings.</p> <p>If your deployment uses access control, the WAP Agent must authenticate to the deployment as a MongoDB user with appropriate access permissions. Enable and configure authentication through the WAP application.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/01-MongoDBAccessControl/#precautions","title":"Precautions","text":"<p>After enabling access control, you must create a MongoDB user so that clients can access your database.</p> <p>By default, WAP automatically creates a user for WAP Agent. WAP Agent can manage other users. Therefore, the first user you create can have any role.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/01-MongoDBAccessControl/#access-control-mechanism","title":"Access control mechanism","text":""},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/01-MongoDBAccessControl/#scram-sha-1-and-scram-sha-256","title":"SCRAM-SHA-1 and SCRAM-SHA-256","text":"<p>In the following table, the default authentication mechanism for the release series is marked with \"\u2713\"</p> <p>and acceptable authentication mechanisms are marked with \"*\"</p> MongoDB Release Series SCRAM-SHA-1 SCRAM-SHA-256 5.x.x * \u2713 4.4.x * \u2713 4.2.x * \u2713 4.0.x * \u2713 <p>To enable SCRAM-SHA-1 or SCRAM-SHA-256 for your WAP project, complete the following tasks:</p> <ul> <li>Enable Username and Password Authentication for your WAP Project.</li> </ul>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/01-MongoDBAccessControl/#x509","title":"X.509","text":"<p>MongoDB supports X.509 certificate authentication for use with a secure TLS connection. The X.509 client authentication allows clients to authenticate to servers with certificates rather than with a username and password.</p> <p>To enable X.509 authentication for your WAP project, complete the following tasks:</p> <ul> <li>Enable x.509 Authentication for your WAP Project.</li> </ul> <p>You can also use X.509 certificates for membership authentication for the processes that WAP monitors.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/02-EnableUsernamePasswordAuthentication/","title":"Enable Username and Password Authentication for your WAP Project","text":""},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/02-EnableUsernamePasswordAuthentication/#overview","title":"Overview","text":"<p>WAP enables you to configure the Authentication Mechanisms that all clients, including the WAP Agents, use to connect to your MongoDB deployments. </p> <p>MongoDB users can use usernames and passwords to authenticate themselves against a MongoDB database.</p> MongoDB Version Default authentication mechanism MongoDB 4.0 and later Salted Challenge Response Authentication Mechanism (SCRAM) using the SHA-1 and SHA-256 hashing algorithms (<code>SCRAM-SHA-1</code> and <code>SCRAM-SHA-256</code>)."},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/02-EnableUsernamePasswordAuthentication/#scram-sha-1-and-scram-sha-256","title":"SCRAM-SHA-1 and SCRAM-SHA-256","text":"<p>SCRAM-SHA-1 and SCRAM-SHA-256are IETF standards that define best practice methods for implementation of challenge-response mechanisms for authenticating users with passwords.</p> <p><code>SCRAM-SHA-1</code> and <code>SCRAM-SHA-256</code> verify supplied user credentials using the user's name, password and authentication database. The authentication database is the database where the user was created.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/02-EnableUsernamePasswordAuthentication/#considerations","title":"Considerations","text":"<p>This tutorial describes how to enable Username and Password authentication for your WAP MongoDB deployment.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/02-EnableUsernamePasswordAuthentication/#procedure","title":"Procedure","text":"<p>This procedure describes how to configure and enable username and password authentication when using Automation.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/02-EnableUsernamePasswordAuthentication/#enable-password-authentication","title":"Enable Password Authentication","text":"<p>1.Click MongoDB in the left navigation bar</p> <p>2.Select the Cluster Name you want to configure.</p> <p></p> <p>3.Click Safety Management</p> <p>4.Click Auth</p> <p></p> <p>5.Click Authentication management,</p> <p>6.Select Account and password and CA certificate for authLevel</p> <p>7.Finally click Confirm</p> <p></p> <p>Enable password authentication. If there is no user, you need to create a user Please refer to:ManageMongoDBUsersandRoles</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/03-EnableX509Authentication/","title":"Enable CA Certificate Authentication for your WAP Project","text":"<p>WAP enables you to configure the Authentication Mechanisms that all clients, including the WAP Agents, use to connect to your MongoDB deployments. </p> <p>MongoDB supports x.509 client and member certificate authentication for use with a secure TLS/SSL connection. </p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/03-EnableX509Authentication/#prerequisites","title":"Prerequisites","text":"<p>A full description of Transport Layer Security, public key infrastructure, X.509 certificates, and Certificate Authorities exceeds the scope of this tutorial. This tutorial assumes prior knowledge of TLS and access to valid X.509 certificates.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/03-EnableX509Authentication/#procedures","title":"Procedures","text":"<p>These procedures describe how to configure and enable CA Certificate authentication when using Automation. </p> <p>Enable CA client certificate authentication for your WAP project</p> <p>1.Click MongoDB in the left navigation bar</p> <p>2.Select the Cluster Name you want to configure.</p> <p></p> <p>3.Click Safety Management</p> <p>4.Click Auth</p> <p></p> <p>5.Click Authentication management,</p> <p>6.Select Account and password and CA certificate for authLevel</p> <p>7.Finally click Confirm</p> <p></p> <p>If there is no user after enabling CA authentication, you need to create a mongodb user. Please refer to:ManageMongoDBUsersandRoles</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/04-ManageMongoDBUsersandRoles/","title":"Manage MongoDB Users and Roles","text":"<p>With access control enabled, clients must authenticate to the MongoDB process as MongoDB users. Once authenticated, these users only have privileges granted by their assigned roles. You can assign MongoDB's built-in roles to a user as well as custom roles.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/04-ManageMongoDBUsersandRoles/#enter-the-user-management-page","title":"Enter the user management page","text":"<ol> <li>Click MongoDB in the left navigation bar</li> <li>Select the cluster name to configure</li> <li>Click Safety Management</li> <li>Click User</li> </ol> <p>WAP currently does not support deleting mongodb users or modifying mongodb user information</p> <p>wapAdamin user is the agent management user and will be created by default</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/04-ManageMongoDBUsersandRoles/#add-a-mongodb-user","title":"Add a MongoDB User","text":"<p>1.Click on mongodb</p> <p>2.Select the Cluster Name you want to configure.</p> <p></p> <p>3.Click Safety Management</p> <p>4.Click User</p> <p>5.Click Add User</p> <p></p> <p>6.Configure username and password</p> <p>7.You can also click generation to quickly generate a secure password. Note: Remember to copy and save the password after generating it.</p> <p></p> <p>8.Configure authentication repository and roles</p> <ul> <li>db: Fill in the mongodb authentication library</li> <li>role: Select the user's role. Different roles have different permissions.</li> </ul> <p></p> <p>9.Select an Verification Mechanism</p> <ul> <li>Selectable SCRAM-SHA-1 or SCRAM-SHA-256</li> </ul> <p></p> <p>10.Configuring Authentication Restriction</p> <ul> <li> <p>clientSource: restricts which addresses this user can authenticate and use the given roles.</p> </li> <li> <p>serverAddress: restricts the addresses this user can authenticate and has the given roles.</p> </li> </ul> <p></p> <p>11.After the configuration is complete, click confirm</p> <p></p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/05-ConfigureandDeployAuditing/","title":"Configure and Deploy Auditing","text":"<p>The WAP platform supports the MongoDB community version to enable the Deploy Auditing function to record key information in detail, including user operations, request methods, cluster operations, user logins and other important content. These records provide administrators with a comprehensive data view to promptly identify any potential security risks or abnormal behaviors.</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/05-ConfigureandDeployAuditing/#go-to-the-audit-start-page","title":"Go to the audit start page","text":"<p>1.Click MongoDB in the left navigation bar</p> <p>2.Select the Cluster Name for which auditing needs to be enabled</p> <p>3.Click Safety Management</p> <p>4.Click Audit</p> <p></p> <p>Notice</p> <p>1.Only MongoDB community versions are supported</p> <p>2.Enabling this function generates a large number of MongoDB logs</p>"},{"location":"WhalealPlatform/08-Security/03-SecureMongoDBDeploymentswithAuthentication/05-ConfigureandDeployAuditing/#enable-audit-function-log","title":"Enable audit function log","text":"<p>1.Click on mongodb</p> <p>2.Select the Cluster Name you want to configure.</p> <p></p> <p>3.Click Safety Management</p> <p>4.Click Audit</p> <p></p> <p>5.Click Audit Enable and select yes</p> <p></p> <p>After opening the audit log, you can view the specific content on the audit page. Please see audit</p>"},{"location":"WhalealPlatform/09-Alert/01-HostAlert/","title":"Host Alert","text":"<p>When Whaleal is used to manage a host for the first time, Whaleal detects that the host is a new host and initializes it. The alart mode directly inherits the alart indicators in the current Project. If you want to configure different alart indicators in the project, you can select the host of the server in the Host drop-down box in Host Alert and configure it separately.</p>"},{"location":"WhalealPlatform/09-Alert/01-HostAlert/#select-project","title":"Select Project","text":"<ol> <li>Click Alert in the navigation bar.</li> <li>Click Host Alert on the Alert Message page.</li> <li>In the host drop-down box, select the server for which you want to configure an alart.</li> </ol>"},{"location":"WhalealPlatform/09-Alert/01-HostAlert/#indicator-configuration","title":"Indicator Configuration","text":"<p>After selecting the target hsot, the configuration options shown in the following picture may appear.</p> <p></p> <p>Configuration items\uff1a</p> Parameters Description Alert Strategy Type Time interval: To count indicators over a period of time, you need to configure the start time and end time in Statistics Granularity/S. Continuous Time: Configure the indicator statistics within a continuous time, which counts the indicator value at the current time. If Item Configure specific Alert indicators here Statistics Granularity/S Configure the granularity of statistics. If the granularity is too large, you may ignore the fact that the Alert indicator is too high at a certain point in time. Trigger Condition Configure indicator values according to plan\"&gt;\",\"&lt;\",\"=\",\"&gt;=\" ,or \"&lt;=\". Trigger Value Alert trigger value. When the Alert indicator value configured in the If Item reaches this value, an alart will be triggered. Trigger Count The number of times the alart is triggered within the time configured in then Alert Frequency/M then Alert Frequency/M Control alart frequency"},{"location":"WhalealPlatform/09-Alert/01-HostAlert/#send-alerts","title":"Send alerts","text":"<p>When the alart value is triggered, we can see the current alart in open Alert, and we can search in MSG or configure the time interval to view the alart within a period of time.</p> <p></p> <p>Alert will also send the alert to a specific platform through the information configured in the alert platform configured in Groups in the Project. For the configuration process, refer to Project Alert.</p>"},{"location":"WhalealPlatform/09-Alert/02-MongoDBAlert/","title":"MongoDB Alert","text":"<p>When you use Whaleal to manage a host for the first time, Whaleal will detect that the host is a new host and initialize it. The alart method directly inherits the alart indicators in the current project. If you want to configure different alart indicators in the project, you can select the host where the server is located in the MongoDB drop-down box in MongoDB Alert and configure it separately.</p>"},{"location":"WhalealPlatform/09-Alert/02-MongoDBAlert/#select-project","title":"Select Project","text":"<ol> <li>Click Alert in the navigation bar.</li> <li>Click MongoDB Alert on the Alert Message page.</li> <li>In the MongoDB drop-down box, select the server for which you want to configure an alart.</li> </ol>"},{"location":"WhalealPlatform/09-Alert/02-MongoDBAlert/#indicator-configuration","title":"Indicator Configuration","text":"<p>After selecting the target hsot, the configuration options shown in the following picture may appear.</p> <p></p> <p>Configuration items\uff1a</p> Alert Strategy Type Time interval: To count indicators over a period of time, you need to configure the start time and end time in Statistics Granularity/S. Continuous Time: Configure the indicator statistics within a continuous time, which counts the indicator value at the current time. If Item Configure specific Alert indicators here Statistics Granularity/S Configure the granularity of statistics. If the granularity is too large, you may ignore the fact that the Alert indicator is too high at a certain point in time. Trigger Condition Configure indicator values according to plan\"&gt;\",\"&lt;\",\"=\",\"&gt;=\" ,or \"&lt;=\". Trigger Value Alert trigger value. When the Alert indicator value configured in the If Item reaches this value, an alart will be triggered. Trigger Count The number of times the alart is triggered within the time configured in then Alert Frequency/M then Alert Frequency/M Control alart frequency"},{"location":"WhalealPlatform/09-Alert/02-MongoDBAlert/#send-alerts","title":"Send alerts","text":"<p>When the alart value is triggered, we can see the current alart in open Alert, and we can search in MSG or configure the time interval to view the alart within a period of time.</p> <p></p> <p>Alert will also send the alert to a specific platform through the information configured in the alert platform configured in Groups in the Project. For the configuration process, refer to Project Alert.</p>"},{"location":"WhalealPlatform/09-Alert/03-ProjectAlert/","title":"Project Alert","text":"<p>When using Whaleal to manage a MongoDB cluster, you can configure cluster alerts based on specific metrics. Alerts can be sent to DingTalk, Lark, or to a custom alert platform via Webhook.</p>"},{"location":"WhalealPlatform/09-Alert/03-ProjectAlert/#configuration-steps","title":"Configuration steps","text":"<ol> <li>Click Project in the left navigation bar of the Whaleal platform</li> <li>Click on the target item</li> <li>There are three types of police alert icons in Group. DingTalk and Lark configurations require the use of built-in tokens and salts\uff0cand Webhook.</li> </ol>"},{"location":"WhalealPlatform/09-Alert/03-ProjectAlert/#lark","title":"Lark","text":"<ol> <li> <p>Enter a Lark group.</p> </li> <li> <p>Click the three dots in the upper right corner of the group.</p> </li> </ol> <p></p> <ol> <li> <p>Add a bot</p> </li> <li> <p>Click Bots</p> <p></p> </li> <li> <p>Click Add Bot</p> <p></p> </li> <li> <p>Click Custom Bot</p> <p></p> </li> <li> <p>Edit Bot Name and Description</p> <p></p> </li> <li> <p>Configure the key to use \"_\" to connect</p> <p></p> </li> <li> <p>Configure the key spliced in step 5 in the Project.</p> <p></p> </li> </ol> <p>After the configuration is complete, click Alert Setting in the left navigation bar to configure the alart trigger values and trigger methods of different indicators according to Host Alert, MongoDB Alert or Project.</p> <p></p>"},{"location":"WhalealPlatform/09-Alert/03-ProjectAlert/#dingtalk","title":"DingTalk","text":"<ol> <li> <p>Enter a DingTalk group.</p> </li> <li> <p>Click the three dots in the upper right corner of the group.</p> </li> </ol> <p></p> <ol> <li> <p>Add a bot</p> </li> <li> <p>Click Bots</p> <p></p> </li> <li> <p>Click Add Bot</p> <p></p> </li> <li> <p>Select Custom Bot</p> <p></p> </li> <li> <p>Edit Bot Name and Security Setting.</p> <p></p> </li> <li> <p>Check the Bot you just created, then copy the access_token after the Webhook link and concatenate it with the value of Additional Signature in Security Setting using \"_\".</p> <p></p> </li> <li> <p>Configure the key spliced in step 5 in the Project.</p> <p></p> </li> </ol> <p>After the configuration is complete, click Alert Setting in the left navigation bar to configure the alart trigger values and trigger methods of different indicators according to Host Alert, MongoDB Alert or Project.</p> <p></p>"},{"location":"WhalealPlatform/09-Alert/03-ProjectAlert/#webhook","title":"WebHook","text":"<p>Webhook configuration configures an alart Post Url, Webhook sends the alart to this Url</p>"},{"location":"WhalealPlatform/10-Diagnose/01-ClusterInfo/","title":"Cluster Info","text":""},{"location":"WhalealPlatform/10-Diagnose/01-ClusterInfo/#select-cluster","title":"Select Cluster","text":"<p>Select info from Diagnose in the left navigation bar, and select the cluster name you want to view from the Cluster drop-down box on this page.</p> <p>We can view the cluster information here, including cluster status, MongoDB version information, and node health status</p> <p>Cluster Info:</p> Cluster Name Current cluster name Status The current state of the cluster Project Projects to which the cluster belongs Enable Monitoring Whether to enable monitoring Nodes Number of cluster nodes Authentication Mechanism The auth type of the current cluster Version MongoDB version information for the cluster FCV Feature Compatibility Version TLS/SSL TLS/SSL status Cluster Member Configuration Cluster Member Configuration is hostname or IP <p>Node Info:</p> <p>The left side of the node is the node information, and the right side is the monitoring.</p> <p>In the Operation drop-down box, you can operate the process of the node, including Update Node Information, Startup, ShutDown, Restart. These operations are only effective for the current node, not for the entire cluster.</p> <p>Clicking Monitor will jump to the monitoring page of the node, where you can see detailed monitoring indicators.</p> <p>Click Perforance to jump to the Perforance page of the node. For details, refer to Performance</p>"},{"location":"WhalealPlatform/10-Diagnose/01-ClusterInfo/#replicasetshard","title":"ReplicaSet/shard","text":"<p>In the ReplicaSet/shard cluster, there are two drop-down boxes: ReplicaSets Info and Node State. ReplicaSets Info contains the configuration information of Shards and Config Server in Replica Set or Shard, and Node State contains the information of each node in the cluster.</p>"},{"location":"WhalealPlatform/10-Diagnose/02-ClusterHealth/","title":"Cluster Health","text":"<p>Quick diagnosis</p> <p>Quick diagnosis includes the latency of both the WAP platform and agent hosts (WhalealLag), basic information of the hosts (HostInfo), more detailed real-time host resource utilization (RealHostInfo), basic information of MongoDB instances (MongoInfo), and more detailed real-time MongoDB instance information (RealMongoInfo). These pieces of information can assist in evaluating the performance, availability, and health status of MongoDB, thereby enabling appropriate optimization and adjustment measures.</p> <p>Start diagnosis</p> <p>After selecting the Cluster Name and Node Name, click Start Diagnose Session to start diagnosing the node.</p> <p></p> <p>After clicking Start Diagnose Session, the diagnosis node may take some time, please be patient.</p> <p>After the diagnosis is completed, a pop-up window will pop up saying End of Diagnosis!</p> <p></p> <p>Diagnose result</p> <p></p> <p></p> <p>The indicators in the Diagnose result are problematic indicators and need to be checked in detail.</p>"},{"location":"WhalealPlatform/10-Diagnose/03-Performance/","title":"Performance","text":"<p>Performance real-time monitoring can track and record the performance indicators of the MongoDB database system in real time. Through real-time monitoring, administrators can discover potential performance problems in a timely manner and take corresponding measures for optimization to ensure that the database system can continue to run efficiently.</p> <ol> <li>Select your cluster and cluster nodes</li> <li>Click Real-time Diagnosis</li> </ol> <p></p> <p>Monitoring comparison</p> <p>You can view the comparison of monitoring indicators of different nodes in a cluster.</p> <p></p> <ol> <li>Click Monitor Comparison</li> <li>You can choose the time range, node and indicator type for monitoring</li> </ol> <p></p> <p></p>"},{"location":"WhalealPlatform/10-Diagnose/04-LogVis/","title":"LogVis","text":"<p>Before using LogVis, you need to configure S3 storage in the settings in advance</p> <p>LogVis can view the slow query statistics in the logs within a certain period of time. To view the statistics, follow the steps below:</p> <ol> <li>Select Cluster Name and Node Name, then click the Analyze button.</li> </ol> <p></p> <ol> <li>Wait for a while and click the magnifying glass icon to view the analysis results</li> </ol> <p></p>"},{"location":"WhalealPlatform/10-Diagnose/04-LogVis/#connectionlist","title":"ConnectionList","text":"<p>In ConnectionList, you can see which nodes the cluster is connected to and count the number of connections.</p> <p></p>"},{"location":"WhalealPlatform/10-Diagnose/04-LogVis/#statistical-information","title":"Statistical information","text":"<p>In Statistical information, view the slow query statistics of each collection in the collection, including the number of slow queries, the average time of slow queries, and the longest/shortest time statistics of slow queries.</p> <p></p>"},{"location":"WhalealPlatform/10-Diagnose/04-LogVis/#slow-query-information","title":"Slow query information","text":"<p>In Slow query information, the collection name is displayed above. Click the colored dot in front of the collection name to control whether to display the slow query of the table. Then click the colored dot in the figure. The color dot with the same color as the collection name is a slow query of the collection. After clicking, the slow query will appear below. Click Click To View to view the analysis information of the slow query.</p> <p></p> <p></p>"},{"location":"WhalealPlatform/10-Diagnose/05-ExploreData/","title":"ExploreData","text":"<p>Explain Plan (execution plan) is used to explain the execution method and optimization strategy of query statements. By analyzing the execution plan, administrators can understand the execution of the query, discover potential performance bottlenecks, and optimize it. You can optimize query statements, create appropriate indexes, or adjust the storage structure of the collection based on the execution plan to improve query efficiency and overall performance.</p> <ol> <li>Select Cluster Name</li> </ol> <p></p> <ol> <li>Select a database and click on it to enter the database.</li> </ol> <p></p> <ol> <li>Select a collection and click on it to enter the collection.</li> </ol> <p></p> <ol> <li>Fill in the statement to be executed in the FILTER, and then click the explain button</li> </ol> <p></p>"},{"location":"WhalealPlatform/10-Diagnose/05-ExploreData/#explain-result","title":"Explain Result","text":"<p>Visual Tree:Formatted explain result</p> <p></p> <p>Raw Json:Complete explain result</p> <p></p>"},{"location":"WhalealPlatform/11-Audit/01-Audit/","title":"Audit List","text":"<p>The WAP platform supports the MongoDB community version to enable the Deploy Auditing function to record key information in detail, including user operations, request methods, cluster operations, user logins and other important content. These records provide administrators with a comprehensive data view to promptly identify any potential security risks or abnormal behaviors.</p> <p>To enable Audit for your mongodb cluster, please refer to:ConfigureandDeployAuditing</p>"},{"location":"WhalealPlatform/11-Audit/01-Audit/#contents-introduction","title":"Contents Introduction","text":""},{"location":"WhalealPlatform/11-Audit/01-Audit/#steps-to-access-the-page","title":"Steps to access the page","text":"<p>Click Audit on the right menu bar</p> <p></p>"},{"location":"WhalealPlatform/11-Audit/01-Audit/#selection-feature-introduction","title":"Selection feature introduction","text":""},{"location":"WhalealPlatform/11-Audit/01-Audit/#_1","title":"Audit","text":"Parameters Description MSG Search for the group you want to search Time Range Select time range progress selection search content Member User selects the platform user wants to view the accounting journal level Selection of accounting journal levels, from 0 to 4"},{"location":"WhalealPlatform/11-Audit/01-Audit/#dashboard-page","title":"Dashboard page","text":"Parameters Description User operation Records user account operations, deletions, modifications, etc. Request Mode Record platform request operations, including web and API MongoDB Cluster Operation Records include cluster update, delete and other operations Login Record user login information"},{"location":"WhalealPlatform/11-Audit/01-Audit/#log-information","title":"Log information","text":"Parameters Description High-risk Operation High-risk platform operations, including service restart, cluster modification, Agent downtime, etc. Normal Operation Contains all normal operation information, which can be exported to a csv file locally"},{"location":"WhalealPlatform/12-Account/01-usercenter/","title":"user Center","text":"<p>The user center contains the user's information</p> <p>You can modify your personal information including email, phone number, etc.</p> <p>View current personal information</p> <ol> <li> <p>Click on the user name on the right</p> </li> <li> <p>Click Account</p> </li> </ol> <p></p> Parameters Description Name The name of the currently logged in user Email Email bound to the current user,After configuring the alert in Whaleal, the alert notification will be sent to your personal mailbox simultaneously. Phone The mobile phone number bound to the current user,After configuring the alert in Whaleal, the alert notification will be sent to your personal mobile phone synchronously in the form of SMS. Create Time Current user creation time Update Time The time when the current user's information was last modified DingTalk\u3001Lark\u3001Webhook Configure DingTalk, Lark, and Webhook to obtain alert information <p>Click the Edit option button to modify your personal information.</p> <p></p> Parameters Can it be modified Email \u221a Phone \u221a DingTalk \u221a Lark \u221a Webhook \u221a"},{"location":"WhalealPlatform/12-Account/02-UserManagement/","title":"User Management","text":"<p>User management, WAP user management can configure account permissions, modify passwords, delete users, etc.</p>"},{"location":"WhalealPlatform/12-Account/02-UserManagement/#enter-the-user-management-page","title":"Enter the user management page","text":"<ol> <li>Click on the user name on the right</li> <li>Click Account</li> <li>Click User Management</li> </ol>"},{"location":"WhalealPlatform/12-Account/02-UserManagement/#manage-user-operations","title":"Manage User Operations","text":"<p>Click on the right side of the operation</p> <p></p> <p>Cancel Admin</p> <ul> <li>Configure administrator permissions for users so that administrators can delete users.</li> </ul> <p>Delete User</p> <ul> <li>Delete the current user</li> </ul> <p>Reset Password</p> <ul> <li>Reset password for user</li> </ul>"},{"location":"WhalealPlatform/12-Account/02-UserManagement/#configuring-user-permissions","title":"Configuring User Permissions","text":"<p>Click on the user name</p> <p></p> <p>Authority Management</p> <ul> <li>Create Server Permissions</li> </ul> <p>Configure permissions for users to create servers</p> <ul> <li>Create MongoDB Permissions</li> </ul> <p>Configure permissions for users to create mongodb</p> <p>Server</p> <ul> <li>You can view the server permissions managed by the current user</li> </ul> <p></p> <p>Mongo</p> <ul> <li>You can view the mongo permissions managed by the current user</li> </ul> <p></p>"},{"location":"WhalealPlatform/12-Account/03-AccountConfiguration/","title":"Account Configuration","text":"<p>Account configuration: users can configure whether the WAP account receives system alart notifications. In addition, users can also set the time zone</p>"},{"location":"WhalealPlatform/12-Account/03-AccountConfiguration/#enter-the-user-configuration-page","title":"Enter the user configuration page","text":"<ol> <li>Click on the user name on the right</li> <li>Click Account</li> <li>Click Account Configuration</li> </ol> <p>Receive Alart Notifications</p> <ul> <li>Choose whether to receive alert notifications</li> </ul> <p>Time Zone</p> <ul> <li>Users can configure the time zone and the time display of user monitoring data.</li> </ul>"},{"location":"WhalealPlatform/13-Setting/01-MongoDBPackge/","title":"MongoDB Package","text":"<p>Mongodb installation package management. To build Mongodb using the WAP platform, you need to manually upload the Mongodb media package on this page. Only when the corresponding version is uploaded can it be deployed.</p> <p></p>"},{"location":"WhalealPlatform/13-Setting/01-MongoDBPackge/#upload-installation-package-steps","title":"Upload installation package steps","text":"<ol> <li>Click Settings in the left navigation bar</li> <li>Click MongoDB Package</li> <li>Drag the file here or click Upload</li> </ol>"},{"location":"WhalealPlatform/13-Setting/01-MongoDBPackge/#deleting-the-installation-package","title":"Deleting the installation package","text":"<ol> <li>Click Settings in the left navigation bar</li> <li>Click MongoDB Package</li> <li>Select the installation package and click Delete</li> </ol>"},{"location":"WhalealPlatform/13-Setting/02-SMTP/","title":"Configure SMTP","text":"<p>Configure SMTP to send emails, which is used to send warning information of the WAP platform. Only after the server is configured can the warning emails be sent to users. The following describes how to configure SMTP in the environment</p>"},{"location":"WhalealPlatform/13-Setting/02-SMTP/#view-smtp-configuration","title":"View SMTP Configuration","text":"<ol> <li>Click on the left side of the setting</li> <li>Click SMTP</li> </ol> Parameters Description SMTP Server Address SMTP mail server address User Name username Password email Password Port The port number Email From Sender's Email Email Title mail title SSL Use SSL (encryption) Encode: Character encoding settings"},{"location":"WhalealPlatform/13-Setting/02-SMTP/#example-modify-smtp-steps","title":"Example Modify SMTP steps","text":"<p>1.Click Edit to edit the configuration</p> <p></p> <p>2.Configuring SMTP Parameters</p> Parameters Description SMTP Server Address <code>smtp.example.com</code> -Replace with your SMTP server address. User Name <code>wap</code> - Replace with your username. Password <code>password</code> - Replace with your email password. Port <code>465</code> - Replace with your SMTP port number. Email From <code>email@example.com</code> - Replace with your sender's email address. Email Title <code>alert</code> - Replace with the title of your message. SSL <code>Enable</code> - Use SSL, the default is Enable. Encode <code>UTF-8</code>- Character encoding type, the default is UTF-8. <p>3.Click Seve</p>"},{"location":"WhalealPlatform/13-Setting/03-CollectionGranularity/","title":"Collection Granularity","text":"<p>The collection granularity configuration can set the frequency of data collection in monitoring, modify the collection granularity configuration, and modify the granularity configuration of the host and MongoDB, as well as the retention time of MongoDB node logs.</p>"},{"location":"WhalealPlatform/13-Setting/03-CollectionGranularity/#view-collection-granularity-configuration","title":"View  Collection Granularity Configuration","text":"<ol> <li>Click Settings in the left navigation bar</li> <li>Click Collection Granularity</li> </ol>"},{"location":"WhalealPlatform/13-Setting/03-CollectionGranularity/#parameter-introduction","title":"Parameter Introduction","text":"Parameters Description Host Monitor Collection Granularity The frequency and level of detail with which metrics are collected and stored from monitored hosts. It determines how often metrics such as CPU usage, memory usage, disk I/O, and network traffic are sampled and recorded. MONGODB Monitor Collection Granularity The frequency at which monitoring metrics are collected from the monitored MongoDB cluster. MONGODB Node Analysis Log Retention Time Select the retention time of mongodb analysis log will be deleted after expiration MONGODB Node Raw Log Retention Time MONGODB Node Raw Log Retention Time will be deleted after it expires"},{"location":"WhalealPlatform/13-Setting/04-Kubernetes/","title":"Configure Kubernetes","text":"<p>Configure Kubernetes for the WAP platform. Add Kubernetes to create hosts and mongodb using Kubernetes.</p>"},{"location":"WhalealPlatform/13-Setting/04-Kubernetes/#view-kubernetes-configuration","title":"View Kubernetes Configuration","text":"<p>1.Click on the left side of the setting</p> <p>2.Click Kubernetes</p> <p></p>"},{"location":"WhalealPlatform/13-Setting/04-Kubernetes/#add-kubernetes-configuration-steps","title":"Add Kubernetes configuration steps","text":"<p>1.Click ADD K8S</p> <p></p> <p>Name: Configure k8s name</p> <p>Type: Support for Linode Kubernetes and Amazon EKS</p> <p>Configuration: k8s Configuration configuration file is used to connect to EKS</p> <p>2.Click Confirm</p>"},{"location":"WhalealPlatform/13-Setting/04-Kubernetes/#example-configuring-kubernetes","title":"Example: Configuring Kubernetes","text":"<p>1.You need to prepare the Kubernetes confing file in advance. The following is an example of Kubernetes confing</p> <pre><code>apiVersion: v1\nkind: Config\npreferences: {}\n\nclusters:\n- cluster:\n    certificate-authority-data: &lt;certificate-authority-data&gt;\n    server: https://&lt;server&gt;:443\n  name: lke196921\n\nusers:\n- name: lke196921-admin\n  user:\n    as-user-extra: {}\n    token: &lt;token&gt;\n\ncontexts:\n- context:\n    cluster: lke196921\n    namespace: default\n    user: lke196921-admin\n  name: lke196921-ctx\n\ncurrent-context: lke196921-ctx\n</code></pre> <p>2.Configure kubernetes fill in</p> <ul> <li> <p>name: Enter the kubernetes cluster name</p> </li> <li> <p>Type: Choose Kubernetes</p> </li> <li>Configuration: Copy the Kubeconfig file here</li> </ul> <p></p> <p>3.Click confirm Configuration Complete</p> <p></p>"},{"location":"WhalealPlatform/13-Setting/05-S3/","title":"Configure S3","text":"<p>Configure s3 storage for WAP. Some functions in WAP require s3 configuration to use, such as Support and Diagnose-LogVis. Here is how to configure s3 in the environment</p>"},{"location":"WhalealPlatform/13-Setting/05-S3/#view-s3-configuration","title":"View s3 Configuration","text":"<ol> <li>Click on the left side of the setting</li> <li>Click S3</li> </ol>"},{"location":"WhalealPlatform/13-Setting/05-S3/#example-modify-s3-steps","title":"Example Modify S3 steps","text":"<p>1.Click Edit to edit the configuration</p> <p></p> <p>2.Configuring S3 Parameters</p> Parameters Description Cloud Bucket <code>wap-test</code>Bucket Name Path Prefix Path name, default is <code>wap</code> Credential ID <code>Access Key ID</code>, used to identify you Credential Key The <code>Secret Access Key</code> that is paired with the Access Key ID Endpoint The <code>endpoint URL</code> of the object storage <p>3.Click Seve</p>"},{"location":"WhalealPlatform/14-Support/01-ClusterInspection/","title":"Cluster inspection","text":"<p>In addition to the basic problem troubleshooting tools built into the platform, Whaleal also provides services from professional technicians. It can collect MongoDB node and cluster information through inspection scripts, and provide the collected data to our technicians for professional problem analysis, problem troubleshooting, and provide professional rectification suggestions and prevention plans.</p>"},{"location":"WhalealPlatform/14-Support/01-ClusterInspection/#diagnostic-information-collection","title":"Diagnostic information collection","text":"<ol> <li>Select menu Support</li> <li>Select the cluster to inspect from the drop-down menu</li> <li>Click Mdiag to start collecting information</li> </ol> <p>After the information collection is completed, the collection record will be displayed on the current page. Users can download the collected information locally by clicking the Download button. You can directly send the downloaded package to our technicians for problem analysis and problem diagnosis. Or you can seek help from our technical staff in the form of submitting a work order by clicking Submit Case.</p>"},{"location":"WhalealPlatform/15-AdministerWhaleal/01-StartAndStopWhalealApplication/","title":"Start and Stop Whaleal Application","text":"<p>Whaleal Application is split into separate services to run, and all services are independent of each other.</p>"},{"location":"WhalealPlatform/15-AdministerWhaleal/01-StartAndStopWhalealApplication/#start-whaleal","title":"Start Whaleal","text":"<pre><code>cd /opt/WAP/\nsh start.sh\n</code></pre>"},{"location":"WhalealPlatform/15-AdministerWhaleal/01-StartAndStopWhalealApplication/#stop-whaleal","title":"Stop Whaleal","text":"<pre><code>cd /opt/WAP/\nsh stop.sh\n</code></pre>"},{"location":"WhalealPlatform/15-AdministratorWhaleal/01-StartAndStopWhalealApplication/","title":"Start and Stop Whaleal Application","text":"<p>Whaleal Application is split into separate services to run, and all services are independent of each other.</p>"},{"location":"WhalealPlatform/15-AdministratorWhaleal/01-StartAndStopWhalealApplication/#start-whaleal","title":"Start Whaleal","text":"<pre><code>cd /opt/WAP/\nsh start.sh\n</code></pre>"},{"location":"WhalealPlatform/15-AdministratorWhaleal/01-StartAndStopWhalealApplication/#stop-whaleal","title":"Stop Whaleal","text":"<pre><code>cd /opt/WAP/\nsh stop.sh\n</code></pre>"},{"location":"WhalealPlatform/15-AdministratorWhaleal/02-IntegrationwithPrometheus/","title":"Integration with Prometheus","text":"<p>WAP also supports seamless integration of monitoring indicators into Prometheus. Through WAP, users can easily collect, store and analyze key performance data and use this data to optimize system stability and efficiency.</p>"},{"location":"WhalealPlatform/15-AdministratorWhaleal/02-IntegrationwithPrometheus/#configuration-examples","title":"Configuration Examples","text":""},{"location":"WhalealPlatform/15-AdministratorWhaleal/02-IntegrationwithPrometheus/#prometheus-configuration","title":"prometheus configuration","text":"<p>1.Modify the prometheus configuration file prometheus.yml</p> <pre><code>  - job_name: wap-monitor\n    scrape_interval: 10s\n    metrics_path: '/api/server/mongo/getMongoDBForPrometheus'\n    params:\n      id: [\"public\"]\n      type: [\"project\"]\n    basic_auth:\n      username: 'admin'\n      password: xxxxx\n    static_configs:\n      - targets: ['172.xx.xx.xx:8080']\n        labels:\n          instance: wap\n</code></pre> <p>Request parameters:</p> key value type description id The ID of the project or the ID of the mongodb cluster or the ID of the mongodb node String id value type \"project\" or \"mongodbCluster\" or \"mongodbNode\" String Query monitoring data range mongodbParam anAssert, cacheFlow, cacheUsage, collectionLock, collectionScan, conn, databaseLock, deletedDocument, documentOp, indexSize, latency, lockCondition, logicalDataSize, logicalDatabaseDataSize, logicalSize, memory, net, openCursor, oplogSize, oplogWindow, pageFaults, qps, scanAndOrder, storageSize, targetQ, tickets, transactionCondition String Query the monitoring indicators in the specified range. If the parameter value is empty, query all indicators. Otherwise, query according to the parameter value list <p>2.Restart prometheus</p>"},{"location":"WhalealPlatform/15-AdministratorWhaleal/02-IntegrationwithPrometheus/#grafana-configuration","title":"Grafana configuration","text":"<p>1.Access grafana</p> <p>2.Import grafana json file</p> <p></p> <p>3.Select grafana json file to import</p> <p></p> <p>4.Click import</p> <p></p> <p>5.Configuration Complete</p> <p></p>"},{"location":"WhalealPlatform/16-Troubleshooting/01-EC2andK8S/","title":"EC2andK8S","text":"<p>Problems that occur when adding ec2 or k8s. The following tasks are used to check for common and easy-to-fix problems:</p>"},{"location":"WhalealPlatform/16-Troubleshooting/01-EC2andK8S/#check-the-agent-log","title":"Check the agent log","text":"<p>If you encounter problems when adding ec2 or k8s hosts, please check the Agent output log for errors.</p> <p>The log file is stored in the server \"/logs/whaleal_agent-collection_log\" file</p>"},{"location":"WhalealPlatform/16-Troubleshooting/01-EC2andK8S/#check-whether-the-agent-is-started-normally","title":"Check whether the agent is started normally","text":"<p>Make sure the agent process is running</p> <p>Run the following command to view the agent status:</p> <pre><code>&gt; systemctl status whaleal_agent\n\n\u25cf whaleal_agent.service - Start Whaleal Platform Agent Service\n   Loaded: loaded (/etc/systemd/system/whaleal_agent.service; enabled; vendor preset: disabled)\n   Active: active (running) since \u4e00 2024-07-01 05:46:14 UTC; 1h 12min ago\n Main PID: 7879 (java)\n   CGroup: /system.slice/whaleal_agent.service\n           \u251c\u2500 7879 java -jar /opt/agent/agent-collection-1.0.0.jar --foreign.url=http://xx.xx.xx.xx:8080 --agentId=system --podType=\n</code></pre>"},{"location":"WhalealPlatform/16-Troubleshooting/01-EC2andK8S/#check-whether-the-agent-and-server-are-connected","title":"Check whether the agent and server are connected","text":"<p>Please check whether the WAP service is running normally and confirm that the server connection is normal. Verify whether the Agent can connect to the WAP server through TCP port 9619.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/02-MongoDBMonitoring/","title":"MongoDBMonitoring","text":""},{"location":"WhalealPlatform/16-Troubleshooting/02-MongoDBMonitoring/#monitoring-issues","title":"Monitoring issues","text":""},{"location":"WhalealPlatform/16-Troubleshooting/02-MongoDBMonitoring/#check-whether-the-agent-is-started-normally","title":"Check whether the agent is started normally","text":"<p>Make sure the agent process is running</p> <p>Run the following command to view the agent status:</p> <pre><code>&gt; systemctl status whaleal_agent\n\n\u25cf whaleal_agent.service - Start Whaleal Platform Agent Service\n   Loaded: loaded (/etc/systemd/system/whaleal_agent.service; enabled; vendor preset: disabled)\n   Active: active (running) since \u4e00 2024-07-01 05:46:14 UTC; 1h 12min ago\n Main PID: 7879 (java)\n   CGroup: /system.slice/whaleal_agent.service\n           \u251c\u2500 7879 java -jar /opt/agent/agent-collection-1.0.0.jar --foreign.url=http://xx.xx.xx.xx:8080 --agentId=system --podType=\n</code></pre>"},{"location":"WhalealPlatform/16-Troubleshooting/02-MongoDBMonitoring/#connection-issues","title":"Connection Issues","text":"<p>Verify that MongoDB is running and accessible.</p> <p>Use the telnet command to check whether the necessary port 9619 is open.</p> <p>Make sure the necessary ports are open.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/02-MongoDBMonitoring/#system-resource","title":"system resource","text":"<p>Ensure that the system running MongoDB and Agent has sufficient resources.</p> <p>Monitor system resource usage (CPU, memory, disk I/O) to see if it has reached full capacity</p>"},{"location":"WhalealPlatform/16-Troubleshooting/02-MongoDBMonitoring/#check-the-agent-log","title":"Check the agent log","text":"<p>If you encounter problems when adding ec2 or k8s hosts, please check the Agent output log for errors.</p> <p>The log file is stored in the server \"/logs/whaleal_agent-collection_log\" file</p>"},{"location":"WhalealPlatform/16-Troubleshooting/03-MongoDBUpgradeDowngrade/","title":"MongoDBUpgradeDowngrade","text":""},{"location":"WhalealPlatform/16-Troubleshooting/03-MongoDBUpgradeDowngrade/#check-version-compatibility","title":"Check version compatibility","text":"<p>When upgrading, make sure the target version is higher than the current version. Similarly, when downgrading, make sure the target version is lower than the current version.</p> <p>Version upgrades and downgrades cannot be performed across versions, and can only be performed between adjacent versions. (For example, you cannot upgrade version 4.2 to 5.0 directly, but you can upgrade 4.2 to 4.4 and then 4.4 to 5.0. Similarly, you cannot downgrade 5.0 to 4.2 directly, but you can downgrade 5.0 to 4.4 and then 4.4 to 4.2.)</p>"},{"location":"WhalealPlatform/16-Troubleshooting/03-MongoDBUpgradeDowngrade/#check-the-logs","title":"Check the logs","text":"<p>Check the MongoDB log (mongod.log) for any errors.</p> <p>View WAP event group log error information</p>"},{"location":"WhalealPlatform/16-Troubleshooting/03-MongoDBUpgradeDowngrade/#backing-up-your-data","title":"Backing up your data","text":"<p>Choose to back up data before upgrading or downgrading. If the upgrade or downgrading fails, you can choose to restore the mongodb data by backing up the snapshot.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/03-MongoDBUpgradeDowngrade/#notify-the-whaleal-team","title":"Notify the Whaleal Team","text":"<p>Provide the whale team with information about the problems encountered during the upgrade and downgrade process.</p> <p>When upgrading, make sure the target version is higher than the current version. Similarly, when downgrading, make sure the target version is lower than the current version.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/","title":"BackupandRestore","text":""},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#backup","title":"Backup","text":""},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#unable-to-start-backup","title":"Unable to start backup","text":"<p>Check that the s3 link is configured correctly and has the appropriate permissions</p> <p>View WAP event group log error information</p> <p>Check the MongoDB log (mongod.log) for any errors related to the backup process.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#storage-issues","title":"Storage issues","text":"<p>If the backup file is too large, check whether there is free storage space.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#backup-performance","title":"Backup performance","text":"<p>A slow backup process can be caused by disk I/O problems or high server load. Check server performance indicators during the backup process.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#restore","title":"Restore","text":""},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#version-compatibility","title":"Version compatibility","text":"<p>Make sure that the target MongoDB server to be restored and the backup server have the same version. Backup files between different versions may be incompatible, resulting in recovery failure or incomplete data.</p>"},{"location":"WhalealPlatform/16-Troubleshooting/04-BackupandRestore/#storage-issues_1","title":"Storage issues","text":"<p>If the backup file is too large, check whether there is free storage space.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/","title":"WAP","text":"<p>This page contains answers to frequently asked questions about WAP.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#1-use-the-latest-version-of-prometheus-to-collect-datagram-errors-whether-it-is-related-to-the-version-relationship-ts2024-04-08t035134306z-callerrefreshgo90-levelerror-component-discovery-manager-scrape-discoveryhttp-configwap-monitor-msg-unable-to-refresh-target-groups-err-invalid-character-wlooking-for-beginning-of-value","title":"1. Use the latest version of prometheus to collect Datagram errors. Whether it is related to the version relationship ts=2024-04-08T03:51:34.306Z caller=refresh.go:90 level=error component= \"\" discovery manager scrape \"\" discovery=http config=wap-monitor msg= \"\" Unable to refresh target groups \"\" err= \"\" invalid character 'W'looking for beginning of value \"\"","text":"<p>The prometheus configuration file tries this approach.</p> <pre><code>job_name: wap-monitor\nscrape_interval: 10s\nmetrics_path: '/api/server/mongo/getMongoDBForPrometheus'\nparams:\n  id: [\"public\"]\n  type: [\"project\"]\nbasic_auth:\n  username: 'admin'\n  password: xxxxx\nstatic_configs:\n\n  - targets: ['172.xx.xx.xx:8080']\n    labels:\n      instance: wap\n</code></pre>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#2-the-whaleal-mongodb-log-file-is-so-large-that-the-disk-is-full-and-the-mongo-service-cannot-be-started-wont-he-clean-it-up-himself-do-you-have-to-clean-it-manually-every-time","title":"2. The whaleal-mongodb-log file is so large that the disk is full and the mongo service cannot be started. Won't he clean it up himself? Do you have to clean it manually every time?","text":"<p>What is saved in whaleal-mongodb-log can be cleared from the logs of mongoDB nodes. By default, save for one month. Configure the saving time of mongodb logs in the setting page.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#3-prometheus-configures-multiple-project-gathering-to-report-an-error","title":"3. Prometheus configures multiple project gathering to report an error.","text":"<p>Only one project can be configured at a time.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#4-after-using-the-cluster-rename-only-the-cluster-display-has-changed-and-the-name-of-the-replica-set-of-the-cluster-will-not-change-will-it","title":"4. After using the cluster rename, only the cluster display has changed, and the name of the replica set of the cluster will not change, will it?","text":"<p>The cluster name will not change.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#5-when-converting-from-a-replica-architecture-to-a-fragmented-architecture-all-of-them-are-on-the-same-group-of-machines-in-the-form-of-multiple-instances-when-converting-to-a-fragmented-architecture-will-it-be-different-when-allocating-memory-if-not-will-it-simply-oom-when-allocating-memory-he-wont-know-whether-it-is-multiple-instances-or-50-of-physical-memory","title":"5. When converting from a replica architecture to a fragmented architecture, all of them are on the same group of machines (in the form of multiple instances). When converting to a fragmented architecture, will it be different when allocating memory? If not, will it simply oom? When allocating memory, he won't know whether it is multiple instances or 50% of physical memory?","text":"<p>When the amount of data is large, it will oom. If not set by default in platform, MongoDB defaults to 50% of the physical memory.</p> <p>After the backup strategy is created, when is its trigger time? this can be seen there.</p> <p>After the first creation, you can go to the source MongoDB event group to check the progress.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#6-use-wap-marketplace-to-start-platform-services-through-mirroring-but-the-service-process-did-not-start-successfully-do-i-still-need-to-deploy-it-manually","title":"6. Use WAP marketplace to start platform services through mirroring, but the service process did not start successfully? Do I still need to deploy it manually?","text":"<p>The EC2 server cannot connect to the external network, causing the script not to run</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#7-how-did-the-machines-in-server-be-added-to-project-no-machines-can-be-added-to-the-project-now-after-clicking-on-the-project-on-the-platform-they-are-all-empty","title":"7. How did the machines in server be added to project? no machines can be added to the project now. After clicking on the project on the platform, they are all empty.","text":"<p>All the newly added hosts are on public.</p> <ol> <li>Configuration file \"parameters.properties\" in / opt/agent after the agent instance is started    Write foreign_url= parameters in the format foreign_url= http://54.175.147.38:8080</li> <li>Execute the command after configuration to check whether the process starts \"systemctl status whaleal_agent\"    Wait about 30 seconds after startup</li> <li>All launched agent hosts will be in public project by default.    You can create a new Project, remove the hosts from the public and put them in the new public.</li> <li>You can create a MongoDB cluster based on Project</li> </ol>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#8-do-you-want-to-write-all-the-sourcedsurl-addresses-configured-by-ddt-or-just-write-the-main-node","title":"8. Do you want to write all the sourceDsUrl addresses configured by DDT, or just write the main node?","text":"<p>Both are fine. Master node, slave node, and cluster URI are all available, or only slave nodes can be configured to relieve the pressure on the master node</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#9-after-mongodb-was-separated-from-the-platform-the-mongo-process-on-the-host-also-stopped-do-you-need-other-pre-work-to-deploy-mongodb-again-with-this-machine","title":"9. After mongoDB was separated from the platform, the mongo process on the host also stopped. Do you need other pre-work to deploy MongoDB again with this machine?","text":"<p>Start the MongoDB service, and the data directory is different from the previous data directory.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#10-can-i-reset-my-password","title":"10. Can I reset my password?","text":"<p>The password can be reset, but only users with admin privileges can perform this operation</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#11-can-the-host-under-a-project-be-moved-to-another-project","title":"11. Can the host under a project be moved to another project?","text":"<p>Yes, you need to move it out of the old project before moving it to another project.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#12-what-types-of-deployment-can-i-create-in-wap","title":"12. What types of deployment can I create in WAP?","text":"<p>Using WAP, you can configure all MongoDB deployment types: sharded clusters, replica sets, and standalones.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#13-after-configuring-the-alert-rules-how-can-i-receive-the-alert-information","title":"13. After configuring the alert rules, how can I receive the alert information?","text":"<p>When the alert condition is configured and the alert is triggered, the alert information can be notified via email, DingTalk, SMS, etc.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#14-what-mongodb-versions-does-wap-support","title":"14. What MongoDB versions does WAP support?","text":"<p>WAP supports 98% of MongoDB on the market, and supports versions 5.0 to 7.0.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#15-does-wap-support-changes-to-the-mongodb-cluster-architecture","title":"15. Does WAP support changes to the MongoDB cluster architecture?","text":"<p>Currently supported mongodb architecture changes include single-machine conversion to replica set, replica set conversion to sharding</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#16-what-mongodb-authentication-methods-are-supported","title":"16. What MongoDB authentication methods are supported?","text":"<p>Currently supported authentication methods include account and password, account and password and CA certificate</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#17-is-the-node-shut-down-when-it-leaves-the-management","title":"17. Is the node shut down when it leaves the management?","text":"<p>When a cluster is removed from management, it is not managed or displayed on the platform, but is not shut down on the host. Deleting a node means shutting down the node.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#18-how-to-receive-alerts-after-configuring-them","title":"18. How to receive alerts after configuring them?","text":"<p>When the alert is triggered after the alert conditions are configured, the alert information will be notified via email, DingTalk, SMS, etc.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#19-does-mongo-support-synchronization","title":"19. Does mongo support synchronization?","text":"<p>Support, you can use the backup and restore function to synchronize data</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#20-what-is-the-principle-of-horizontal-expansion-of-wap-platform","title":"20. What is the principle of horizontal expansion of WAP platform?","text":"<p>Horizontal expansion is to build multiple wap services. The agents managed by the same appdb can be hashed and assigned to different wap services to reduce the pressure on a single wap. When a wap service fails, other wap services are not affected. The affected agents will be re-hashed and assigned to healthy wap services.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#21-how-long-will-the-oplog-be-stored","title":"21. How long will the oplog be stored?","text":"<p>Depends on the number of recovery days configured by the user, with a maximum retention period of half a year and a minimum retention period of one day</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/01-WAP/#22-can-the-home-page-be-searched-and-displayed-based-on-the-cluster-name","title":"22. Can the Home page be searched and displayed based on the cluster name?","text":"<p>The home page does not allow you to select a cluster for display. You can only view monitoring information for a specific cluster on the MongoDB page.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/02-Monitor/","title":"Monitor","text":"<p>This page contains answers to frequently asked questions about Monitor.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/02-Monitor/#1-monitoring-indicator-cpuinfo_id-this-corresponds-to-user-cpu","title":"1. Monitoring indicator = 'cpuInfo_id' this corresponds to: user cpu?","text":"<p>No, Id stands for cpu idle rate.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/02-Monitor/#2-more-than-60-in-60-seconds-will-the-alert-be-triggered-10-times-but-this-value-is-not-more-than-40-at-present-but-it-has-been-reported-all-the-time","title":"2. More than 60% in 60 seconds, will the alert be triggered 10 times, but this value is not more than 40% at present, but it has been reported all the time.","text":"<p>Within 60s, if the cpu utilization rate is greater than 60% and occurs ten times, the alert will be triggered. Once the alert message is sent every 10 minutes, the alert message will be sent with a granularity of 1 minute. In this case, the average cpu utilization rate within one minute is 40%. Click real-time to see the cpu information at the seconds level.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/02-Monitor/#3-at-present-after-the-monitoring-is-turned-on-is-the-frequency-of-monitoring-once-per-second-can-you-define-the-time-frequency-by-yourself","title":"3. At present, after the monitoring is turned on, is the frequency of monitoring once per second? can you define the time frequency by yourself?","text":"<p>You can adjust it yourself and monitor the granularity in setting.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/02-Monitor/#4-the-monitoring-information-cannot-be-viewed-the-mongo-log-has-just-been-cut-by-the-hour-does-this-matter","title":"4. The monitoring information cannot be viewed. The mongo log has just been cut by the hour. Does this matter?","text":"<p>The MongoDB log has nothing to do with this. This general situation is caused by the network. Delete all the host alert policies configured on this host and see if there is any monitoring data.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/02-Monitor/#5-is-the-monitoring-frequency-once-per-second-can-i-define-the-time-frequency-myself","title":"5. Is the monitoring frequency once per second? Can I define the time frequency myself?","text":"<p>You can adjust it yourself, in the settings, monitor the granularity.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/","title":"Backup","text":"<p>This page contains answers to frequently asked questions about Backup.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#1-when-backing-up-the-ddt-host-randomly-selects-which-node-to-back-up-from-is-it-possible-for-him-to-choose-the-hidden-node-if-he-selects-the-slave-node-will-the-cpu-be-very-high","title":"1. When backing up, the DDT host randomly selects which node to back up from. Is it possible for him to choose the hidden node? If he selects the slave node, will the cpu be very high?","text":"<p>DDT is a server used to perform backup tasks. It is completed by executing the JAVA backup process. Try not to place this on the server where MongoDB is located. Try to add an extra server to do backup. The backup operation does not consume much CPU on the source side, which is equivalent to performing a query operation. There will be a little stress during the first full backup.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#2-there-is-a-problem-with-backup-configuration-s3","title":"2. There is a problem with backup configuration S3","text":"<p>If the bucket name is filled in incorrectly, create a backup policy and refresh the page according to the new configuration. After this key is triggered once, the backend will re-encrypt the key, so there is a problem with the connection, so you need to re-enter key accesskey.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#3-backup-issuin-configuration","title":"3. Backup issu\uff0cIn configuration:","text":"<ol> <li>Full volume and real-time</li> <li>Full volume and increment    Do these two mean the same?    I want to synchronize all the data now. After the synchronization of all the data is completed, I need to continue to synchronize incremental data. Which configuration should I use?    Full and real-time: full oplog (full start time to positive infinite time)    Full and incremental: full oplog (full start time to full end time)</li> </ol>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#4-what-configuration-is-recommended-for-ddt-hosts","title":"4. What configuration is recommended for DDT hosts?","text":"<p>DDT recommends high CPU, 8C+ 16GB+</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#5-what-is-the-ddt-backup-logic-like","title":"5. What is the DDT backup logic like?","text":"<p>This is how DDT works in real time: https://docs.whaleal.com/guide/en/documentDataTransfer/Introduction/Architecture.html.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#6-will-the-process-above-ddt-be-retained-all-the-time-so-that-if-there-are-more-instances-there-will-be-many-such-process-on-ddt-machines","title":"6. Will the process above DDT be retained all the time, so that if there are more instances, there will be many such process on DDT machines?","text":"<p>There are two processes during a DDT backup. After the full backup is completed, the full DDT process exits, leaving a DDT process that synchronizes the oplog synchronized in real time.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#7-if-there-is-a-ddt-host-to-configure-backup-tasks-is-there-a-place-to-configure-the-time-to-avoid-time-conflicts","title":"7. If there is a DDT host to configure backup tasks, is there a place to configure the time to avoid time conflicts.","text":"<p>Currently, custom times are not supported, but if you want to achieve the effect of avoiding time conflicts, different MongoDB clusters can also be created at different times when the backup policy is first configured.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#8-there-is-a-problem-with-ddt-backup-cannot-allocate-memory-errno12","title":"8. There is a problem with DDT backup  \"Cannot allocate memory (errno=12)\"","text":"<p>All DDT processes died, DDT died due to insufficient memory.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#9-ddt-has-an-error-i-configured-ddt-yesterday-ran-for-a-while-then-stopped-ran-again-today-and-started-in-the-following-order-start-ddtsh-start-moitorsh","title":"9. DDT has an error. I configured ddt yesterday, ran for a while, then stopped, ran again today, and started in the following order: start-DDT.sh start-moitor.sh","text":"<p>If you see the log error report, it should be started repeatedly [tool for monitoring DDT synchronization] DDT has two processes:</p> <ol> <li>DDT synchronization MongoDB data tool</li> <li>tools for monitoring DDT synchronization (this tool uses web and spring JAR)</li> </ol> <p>If you execute start-all.sh, you will start both processes. If you execute start-DDT.sh, only start the DDT synchronization data tool</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#10-data-check-ddt-synchronization-data-destination-is-missing","title":"10. Data check. DDT synchronization data destination is missing.","text":"<p>If the table is a dynamic table (operating in real time) There will be data inconsistencies, and dynamic tables can be checked many times to determine data consistency. Db.ns.count is a fuzzy calculation, sometimes because of cache and other problems, the amount of data may not be correct. Can be used on the target side: use the exact count to view the number of library table documents db.ns.countDocuments ({})</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#11-deploy-another-cluster-and-copy-a-ddt-directory-you-can-run-both-of-them-for-example-project-a-is-synchronized-now-project-b-needs-to-be-migrated-and-start-two-ddt-at-the-same-time","title":"11. Deploy another cluster and copy a ddt directory. You can run both of them. For example, project a is synchronized. Now project b needs to be migrated, and start two ddt at the same time.","text":"<p>DDT startup script needs to be modified. It is not supported by default. The second DDT must be in a new directory Then you can start run: </p> <pre><code>nohup java-Xmx$max_heap_size-jar ../execute-1.0-SNAPSHOT.jar ../config/DDT.properties &gt; /dev/null 2 &gt; &amp;1 &amp; \n</code></pre>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#12-help-me-confirm-that-ddt-is-synchronizing-data-in-real-time-if-we-want-to-switch-the-connection-to-a-new-cluster-can-we-replace-it-directly-or-do-we-have-to-disconnect-ddt-synchronization-first-stop-business-stop-ddt-and-finally-replace-the-connection-url","title":"12. Help me confirm that DDT is synchronizing data in real time. If we want to switch the connection to a new cluster, can we replace it directly, or do we have to disconnect DDT synchronization first, stop business, stop DDT, and finally replace the connection URL?","text":"<p>Stop the business first, then stop the DDT service, and then replace the connection URL. This is the recommended action step and needs to be operated within the shutdown maintenance window.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/03-Backup/#13-if-both-the-source-and-target-sides-of-ddt-synchronization-have-write-operations-will-ddt-synchronization-have-an-impact","title":"13. If both the source and target sides of DDT synchronization have write operations, will DDT synchronization have an impact?","text":"<p>In this way, the data on the source side and the destination side will be inconsistent.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/04-Service/","title":"Service","text":"<p>This page contains answers to frequently asked questions about Service.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/04-Service/#1-what-data-is-stored-in-nacos-will-the-loss-of-the-data-catalog-affect-the-service","title":"1. What data is stored in Nacos? Will the loss of the data catalog affect the service?","text":"<p>Store the routing information of the java service. Nacos does not save data and can be rebuilt.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/","title":"Agent","text":"<p>This page contains answers to frequently asked questions about Agent.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/#1-the-agentgz-package-has-a-problem-and-cannot-be-downloaded","title":"1. The agent.gz package has a problem and cannot be downloaded.","text":"<p>Server-web did not start properly.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/#2-the-new-version-of-the-configuration-file-is-named-after-the-port-and-the-previous-one-is-in-the-form-of-ipport-do-you-need-to-manually-modify-the-configuration-file-name-of-the-old-cluster","title":"2. The new version of the configuration file is named after the port, and the previous one is in the form of ip+port. Do you need to manually modify the configuration file name of the old cluster?","text":"<p>The old cluster does not need to be modified and will not be affected.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/#3-after-the-agent-server-is-restarted-you-need-to-start-the-agent-process-manually","title":"3. After the agent server is restarted, you need to start the agent process manually","text":"<p>Use the agent script to configure agent to serve the system and set up boot self-boot.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/#4-the-ddt-machine-used-for-synchronization-does-not-have-agent-this-does-not-affect-data-synchronization-can-i-just-configure-mong-on-it","title":"4. The DDT machine used for synchronization does not have agent. This does not affect data synchronization, can I just configure mong on it?","text":"<p>If you don't use backup features on the platform, there will be no impact.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/#5-the-ddt-server-used-for-data-synchronization-does-not-have-an-agent-installed-will-it-affect-data-synchronization-can-i-directly-deploy-and-configure-mongodb-if-i-need-to-use-the-backup-function-later-how-should-i-restore-it-to-the-original-ddt","title":"5. The DDT server used for data synchronization does not have an Agent installed. Will it affect data synchronization? Can I directly deploy and configure MongoDB? If I need to use the backup function later, how should I restore it to the original DDT?","text":"<p>Does not affect data synchronization. If the DDT server is subscribed by marketplace's agent DDT machine clears data, services Start the agent of the DDT machine and put it in the Project called DDT Just start the backup normally. If the DDT server is not created by subscription, you cannot use the backup function in wap.</p>"},{"location":"WhalealPlatform/17-FrequentlyAskedQuestions/05-Agent/#6-after-the-agent-server-is-restarted-do-you-need-to-manually-start-the-agent-process","title":"6. After the agent server is restarted, do you need to manually start the agent process?","text":"<p>The agent startup script will configure the agent as a system service and set it to start automatically at boot</p>"},{"location":"WhalealPlatform/18-ReleaseNotes/01-WhalealChangelog/","title":"Whaleal Changelog","text":""},{"location":"WhalealPlatform/18-ReleaseNotes/01-WhalealChangelog/#whaleal-300","title":"Whaleal 3.0.0","text":"<ul> <li>Add backup function to support sharding cluster backup</li> <li>Support online upgrades</li> <li>Support host quotas</li> <li>Add data query functions</li> <li>Optimization of mongodb log collection</li> <li>Optimize alarm module</li> <li>Add multiple alarm channels</li> </ul>"},{"location":"WhalealPlatform/18-ReleaseNotes/01-WhalealChangelog/#whaleal-200","title":"Whaleal 2.0.0","text":"<ul> <li>Remove redundant files, and optimize agent execution.</li> <li>Clustering: Standardize cluster display and creation, check whether ports are occupied before creation, add creation index function, add cluster operation lock events, add project concepts, and divide host cluster members. Add read-write preferences, add explanation and aggregation.</li> <li>Monitoring: Supplementary monitoring indicators, quantify and optimize the display on the front page, and increase the comparison of various indicators.</li> <li>Log: Event operations exit abnormally, add event status and waiting information, add operation event group logs, add alarm information to archive</li> <li>Diagnosis: Add a new diagnosis function to diagnose a cluster or a node, and the diagnosis content is displayed in batches by date. Inspection can be carried out for a certain batch and the inspection results can be compared with constant values. It also supports downloading diagnostic logs and executing inspection functions regularly.</li> <li>Settings: A new setting module has been added, including MongoDB compressed package management, email settings that can accept alarm information from the host or cluster, and collection granularity configuration that can set the log retention time, the host and mongo collect granularity, and the interval between regular inspections.</li> <li>Account: Add administrator role rights management, which can increase or decrease user rights. User rights determine whether certain content of the user is visible and operable. Administrators can delete the user or directly reset the user password.</li> <li>Notification: Move the notification to the sidebar to filter and observe the message information.</li> </ul>"},{"location":"WhalealPlatform/18-ReleaseNotes/01-WhalealChangelog/#whaleal-100","title":"Whaleal 1.0.0","text":"<ul> <li>Support account/email/mobile number login.</li> <li>The password can be changed using the Captcha.</li> <li>Display host and MongoDB statistics.</li> <li>Host list Host statistics Visual display of host status.</li> <li>Add a host and manage a new host according to the operating instructions.</li> <li>Check the host situation: basic information, monitoring, logs, commands, alarms.</li> <li>MONGO list MONGO cluster information View the MONGODB cluster status: node information, events, cluster logs, and operations.</li> <li>MONGO cluster operation new creation, management, upgrading, master-slave switching, single instance conversion to replication set, turning on/off authentication, monitoring information, node log</li> <li>Reset account information and password.</li> </ul>"},{"location":"whalealData/","title":"Whaleal-data Introduction","text":"<p>Whaleal-data is an archiving platform designed for data archiving. It supports three types of archiving: cold, warm, and S3. For warm data archiving, it supports synchronizing data from MYSQL, Oracle, DB2, and MongoDB to MongoDB. It also supports synchronizing data from MYSQL to MYSQL. Cold data archiving allows archiving MongoDB data to disk files. S3 archiving supports uploading MongoDB Gridfs data to target S3 storage. The platform's homepage displays task execution statistics, archive capacity statistics, table job statistics, business connections, total archive capacity, and user operations. The platform enables independent configuration of data sources and target sources. Users can choose a source to sync data from and a target to sync data to within a table job. After configuring table jobs, multiple table jobs can be configured within a single task configuration. Once tasks are created, they can be managed in the task scheduling section by enabling, disabling, immediately executing, or taking tasks offline. After immediate execution, the corresponding task execution details can be viewed in the task monitoring section. Administrator users have access to various operational details.</p>"},{"location":"whalealData/#platform-architecture-diagram","title":"Platform Architecture Diagram","text":""},{"location":"whalealData/#software-structure-diagram","title":"Software Structure Diagram","text":""},{"location":"whalealData/InstallationDeployment/InstallationRequirements/","title":"InstallationRequirements","text":""},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#installation-requirements","title":"Installation Requirements","text":""},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#hardware-requirements","title":"Hardware Requirements","text":"<ul> <li>Operating System: Windows 10 or later, Linux distributions (such as Ubuntu, CentOS), MacOS.</li> <li>Processor: Intel Core i5 or higher.</li> <li>Memory: At least 8GB RAM.</li> <li>Storage Space: At least 100GB of available disk space.</li> <li>Network Adapter: Supports wired or wireless network connections.</li> </ul>"},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#network-requirements","title":"Network Requirements","text":""},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#network-access-requirements","title":"Network Access Requirements","text":"<p>Configure according to your specific needs.</p>"},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#port-requirements","title":"Port Requirements","text":"<p>Specific ports need to be open (e.g., port 80 for HTTP communication, port used for program startup).</p>"},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#software-requirements","title":"Software Requirements","text":""},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#operating-system-requirements","title":"Operating System Requirements","text":"<ul> <li>Supports Windows Server 2016 or later.</li> <li>Supports CentOS 7 or higher for Linux.</li> </ul>"},{"location":"whalealData/InstallationDeployment/InstallationRequirements/#browser-support","title":"Browser Support","text":"<ul> <li>Google Chrome version 80 or higher.</li> <li>Mozilla Firefox version 75 or higher.</li> </ul>"},{"location":"whalealData/InstallationDeployment/JDKInstallationDeployment/","title":"JDKInstallationDeployment","text":""},{"location":"whalealData/InstallationDeployment/JDKInstallationDeployment/#jdk-installation-and-deployment","title":"JDK Installation and Deployment","text":"<p>It is recommended to install JDK 11.</p>"},{"location":"whalealData/InstallationDeployment/JDKInstallationDeployment/#1-dependency-environment","title":"1. Dependency Environment","text":"<p>For open-source JDK, font library support is required. If it is already present on the Linux system, there's no need to install it. <pre><code>yum install fontconfig\nfc-cache --force\nfc-cache -f\n</code></pre></p>"},{"location":"whalealData/InstallationDeployment/JDKInstallationDeployment/#2-extract-jdk-installation-package","title":"2. Extract JDK Installation Package","text":"<pre><code>tar -zxvf jdk-11.0.9_linux-x64_bin.tar.gz -C /usr/local/\n</code></pre>"},{"location":"whalealData/InstallationDeployment/JDKInstallationDeployment/#3-configure-environment-variables","title":"3. Configure Environment Variables","text":"<p>Open the profile configuration file: <pre><code>vi /etc/profile\n</code></pre> Add the following configurations at the end of the file: <pre><code>export JAVA_HOME=/usr/local/jdk-11.0.9\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre> Refresh the configuration to make it effective: <pre><code>source /etc/profile\n</code></pre></p>"},{"location":"whalealData/InstallationDeployment/JDKInstallationDeployment/#4-verification","title":"4. Verification","text":"<p>Check the installed Java version: <pre><code>java -version\n</code></pre></p> <p>Please note that when copying and pasting these commands, ensure that the formatting remains consistent, and adjust paths and filenames as needed for your system.</p>"},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/","title":"MYSQLInstallationDeployment","text":""},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/#mysql-installation-and-deployment","title":"MySQL Installation and Deployment","text":"<p>It is recommended to use MySQL version 8.0.</p>"},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/#opening-specified-ports-or-disabling-firewall","title":"Opening Specified Ports or Disabling Firewall","text":"<ol> <li> <p>View the ports that are already open:    <pre><code>firewall-cmd --list-ports\n</code></pre></p> </li> <li> <p>Open a specified port (e.g., port 3306 for MySQL):    <pre><code>firewall-cmd --zone=public --add-port=3306/tcp --permanent\n</code></pre></p> </li> <li> <p>Reload the firewall configuration:    <pre><code>firewall-cmd --reload\n</code></pre></p> </li> <li> <p>Confirm the opened ports:    <pre><code>firewall-cmd --list-ports\n</code></pre></p> </li> <li> <p>If needed, you can stop the firewall:    <pre><code>systemctl stop firewalld\n</code></pre></p> </li> <li> <p>Check the firewall status:    <pre><code>systemctl status firewalld\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/#basic-environment-preparation","title":"Basic Environment Preparation","text":"<ol> <li> <p>Create a user and group for MySQL:    <pre><code>groupadd mysql\nuseradd -r -g mysql -s /sbin/nologin mysql\n</code></pre></p> </li> <li> <p>Install dependencies for MySQL:    <pre><code>yum install -y libncurses* libaio* lrzsz*\n</code></pre></p> </li> <li> <p>Extract the MySQL installation package:    <pre><code>tar -xvf mysql-8.0.28-linux-glibc2.12-x86_64.tar -C /usr/local/\n</code></pre></p> </li> <li> <p>Rename the extracted directory:    <pre><code>mv mysql-8.0.28-linux-glibc2.12-x86_64/ mysql\n</code></pre></p> </li> <li> <p>Create required directories:    <pre><code>cd /usr/local/mysql/\nmkdir data\n</code></pre></p> </li> <li> <p>Change directory ownership:    <pre><code>chown -R mysql:mysql /usr/local/mysql/\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/#deploy-mysql-service","title":"Deploy MySQL Service","text":"<ol> <li> <p>Initialize the database:    <pre><code>/usr/local/mysql/bin/mysqld --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ --initialize\n</code></pre></p> </li> <li> <p>Edit <code>my.cnf</code> configuration:    Create/Edit the configuration file <code>/etc/my.cnf</code> and add the following content:    <pre><code>[mysqld]\nbasedir=/usr/local/mysql\ndatadir=/usr/local/mysql/data\nsocket=/usr/local/mysql/data/mysql.sock\nbind-address = 0.0.0.0\nuser=root\nport=3306\nlog-bin=mysql-bin\nserver-id=1\nmax_connections=2048\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\n\n[client]\nsocket=/usr/local/mysql/data/mysql.sock\n</code></pre></p> </li> <li> <p>Configure environment variables:    <pre><code>echo \"export PATH=$PATH:/usr/local/mysql/bin\" &gt;&gt; /etc/profile\nsource /etc/profile\n</code></pre></p> </li> <li> <p>Configure startup script:    <pre><code>cp /usr/local/mysql/support-files/mysql.server /etc/rc.d/init.d/mysqld\nchmod +x /etc/rc.d/init.d/mysqld\n\ncat &gt; /lib/systemd/system/mysqld.service &lt;&lt;EOF\n[Unit]\nDescription=mysqld\nAfter=network.target\n\n[Service]\nType=forking\nExecStart=/etc/rc.d/init.d/mysqld start\nExecReload=/etc/rc.d/init.d/mysqld restart\nExecStop=/etc/rc.d/init.d/mysqld stop\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\nEOF\n</code></pre></p> </li> <li> <p>Reload systemd configuration:    <pre><code>systemctl daemon-reload\n</code></pre></p> </li> <li> <p>Set MySQL to start on boot:    <pre><code>systemctl enable mysqld\n</code></pre></p> </li> <li> <p>Start MySQL:    <pre><code>systemctl start mysqld\n</code></pre></p> </li> <li> <p>Check if MySQL port is active:    <pre><code>netstat -tunlp | grep 3306\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/#configure-password-for-remote-connection","title":"Configure Password for Remote Connection","text":"<ol> <li> <p>Enter the printed password to log in to MySQL:    <pre><code>mysql -u root -p\n</code></pre></p> </li> <li> <p>After logging in, change the root password:    <pre><code>ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';\n</code></pre></p> </li> <li> <p>Check user information:    <pre><code>select user, host, ssl_type from mysql.user;\nuse mysql;\n</code></pre></p> </li> <li> <p>Update the host field to <code>%</code> to allow remote connections:    <pre><code>update user set host = '%' where user = 'root';\n</code></pre></p> </li> <li> <p>Refresh privileges:    <pre><code>flush privileges;\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/MYSQLInstallationDeployment/#adding-archive-platform-fields","title":"Adding Archive Platform Fields","text":"<ol> <li> <p>Log in to MySQL:    <pre><code>mysql -u root -p\n</code></pre></p> </li> <li> <p>Create a database:    <pre><code>create database filing;\n</code></pre></p> </li> <li> <p>Add data from the provided SQL file:    <pre><code>use filing;\nsource /usr/local/filing.sql;\n</code></pre></p> </li> <li> <p>Check the added tables:    <pre><code>use filing;\nshow tables;\n</code></pre></p> </li> </ol> <p>As always, ensure that you adapt paths, filenames, and other specifics to match your system's configuration.</p>"},{"location":"whalealData/InstallationDeployment/NginxInstallationDeployment/","title":"NginxInstallationDeployment","text":""},{"location":"whalealData/InstallationDeployment/NginxInstallationDeployment/#nginx-installation-and-deployment","title":"Nginx Installation and Deployment","text":""},{"location":"whalealData/InstallationDeployment/NginxInstallationDeployment/#opening-specified-ports-or-disabling-firewall","title":"Opening Specified Ports or Disabling Firewall","text":"<ol> <li> <p>View the ports that are already open:    <pre><code>firewall-cmd --list-ports\n</code></pre></p> </li> <li> <p>Open a specified port (e.g., port 80 for Nginx):    <pre><code>firewall-cmd --zone=public --add-port=80/tcp --permanent\n</code></pre></p> </li> <li> <p>Reload the firewall configuration:    <pre><code>firewall-cmd --reload\n</code></pre></p> </li> <li> <p>Confirm the opened ports:    <pre><code>firewall-cmd --list-ports\n</code></pre></p> </li> <li> <p>If needed, you can stop the firewall:    <pre><code>systemctl stop firewalld\n</code></pre></p> </li> <li> <p>Check the firewall status:    <pre><code>systemctl status firewalld\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/NginxInstallationDeployment/#installation-and-deployment","title":"Installation and Deployment","text":"<ol> <li> <p>Extract the Nginx installation package:    <pre><code>tar -zxvf nginx-1.16.1.tar.gz -C /usr/local/\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>yum install -y pcre pcre-devel\nyum install -y zlib zlib-devel\n</code></pre></p> </li> <li> <p>Configure the installation path:    <pre><code>cd /usr/local/nginx-1.16.1\n./configure --prefix=/usr/local/nginx\n</code></pre></p> </li> <li> <p>Compile Nginx:    <pre><code>make &amp;&amp; make install\n</code></pre></p> </li> <li> <p>Configure local hostname resolution:    Edit <code>/etc/hosts</code> and add an entry for your local domain:    <pre><code>ip cloud.whalealmg.com\n</code></pre></p> </li> <li> <p>Edit the Nginx configuration file:    <pre><code>server {\n    listen 80;\n    server_name cloud.whalealmg.com;\n\n    location / {\n        root /usr/local/nginx/html/dist/;\n        index index.html index.htm;\n        try_files $uri $uri/ /index.html;\n    }\n\n    location /filingAdmin/ {\n        proxy_pass http://127.0.0.1:8000/;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-Port $server_port;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n\n    location ~ .*\\.(js|css|jpg|jpeg|gif|png|ico|pdf|txt)$ {\n        root /usr/local/nginx/html/dist/;\n        index index.html index.htm;\n    }\n\n    error_page 500 502 503 504 /50x.html;\n    location = /50x.html {\n        root html;\n    }\n}\n</code></pre></p> </li> <li> <p>Start the Nginx service:    <pre><code>/usr/local/nginx/sbin/nginx\n</code></pre></p> </li> </ol> <p>Make sure to adjust paths, domain names, and other configurations as needed for your specific environment.</p>"},{"location":"whalealData/InstallationDeployment/RedisInstallationDeployment/","title":"RedisInstallationDeployment","text":""},{"location":"whalealData/InstallationDeployment/RedisInstallationDeployment/#redis-installation-and-deployment","title":"Redis Installation and Deployment","text":""},{"location":"whalealData/InstallationDeployment/RedisInstallationDeployment/#opening-specified-ports-or-disabling-firewall","title":"Opening Specified Ports or Disabling Firewall","text":"<ol> <li> <p>View the ports that are already open:    <pre><code>firewall-cmd --list-ports\n</code></pre></p> </li> <li> <p>Open a specified port (e.g., port 6379 for Redis):    <pre><code>firewall-cmd --zone=public --add-port=6379/tcp --permanent\n</code></pre></p> </li> <li> <p>Reload the firewall configuration:    <pre><code>firewall-cmd --reload\n</code></pre></p> </li> <li> <p>Confirm the opened ports:    <pre><code>firewall-cmd --list-ports\n</code></pre></p> </li> <li> <p>If needed, you can stop the firewall:    <pre><code>systemctl stop firewalld\n</code></pre></p> </li> <li> <p>Check the firewall status:    <pre><code>systemctl status firewalld\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/RedisInstallationDeployment/#installation-and-deployment","title":"Installation and Deployment","text":"<ol> <li> <p>Extract the Redis installation package:    <pre><code>tar -zxvf redis-4.0.9.tar.gz -C /usr/local/\n</code></pre></p> </li> <li> <p>Rename the extracted folder:    <pre><code>mv redis-4.0.9 redis\n</code></pre></p> </li> <li> <p>Install the required dependencies (e.g., GCC):    <pre><code>yum install gcc -y\n</code></pre></p> </li> <li> <p>Compile the Redis files:    <pre><code>cd /usr/local/redis\nmake &amp;&amp; make install\n</code></pre></p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/RedisInstallationDeployment/#edit-configuration-file","title":"Edit Configuration File","text":"<ol> <li> <p>Edit the Redis configuration file:    <pre><code>vi redis.conf\n</code></pre></p> </li> <li> <p>Set a password (e.g., \"123456\"):    <pre><code># Before\n# requirepass foobared\n\n# After\nrequirepass 123456\n</code></pre></p> </li> <li> <p>Enable background daemon mode:    <pre><code># Before\n# daemonize no\n\n# After\ndaemonize yes\n</code></pre></p> </li> <li> <p>Allow remote access:    <pre><code># Before\n# bind 127.0.0.1\n\n# After\nbind 0.0.0.0\n</code></pre></p> </li> <li> <p>Save the configuration file and exit the editor.</p> </li> </ol>"},{"location":"whalealData/InstallationDeployment/RedisInstallationDeployment/#start-redis","title":"Start Redis","text":"<ol> <li> <p>Start Redis using the modified configuration file:    <pre><code>redis-server /usr/local/redis/redis.conf\n</code></pre></p> </li> <li> <p>Validate the Redis server is running:    <pre><code>redis-cli\n</code></pre></p> </li> </ol> <p>Make sure to adjust paths, passwords, and other configurations as needed for your specific environment.</p>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/","title":"Whaleal-dataInstallationDeployment","text":""},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#installation-and-deployment-of-whaleal-data","title":"Installation and Deployment of Whaleal-data","text":""},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#high-availability-deployment","title":"High Availability Deployment","text":"<p>To achieve high availability, deploy the service on multiple machines and distribute traffic through a load balancer to balance and share the requests. Common load balancing algorithms include round-robin, least connections, and hash algorithms. Use multiple servers with the same configuration to maintain system continuity by having other servers take over in case of a failure. Common redundancy backup modes include master-slave mode, active-active mode, and N+1 mode.</p>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#package-deployment","title":"Package Deployment","text":""},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#frontend-service-startup","title":"Frontend Service Startup","text":"<ol> <li>After compiling the source code, generate the \"dist\" distribution package.</li> <li>Send the \"dist\" package to the server.</li> <li>Path: The installation path configured in the Nginx configuration.</li> </ol>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#restart-nginx","title":"Restart Nginx","text":"<pre><code>/usr/local/nginx/sbin/nginx -s reload -t\n</code></pre>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#backend-service-startup","title":"Backend Service Startup","text":"<ol> <li>After compiling the source code, generate the \"filing-system-0.0.1-SNAPSHOT.jar\" distribution package.</li> <li>Upload the distribution package to the server.</li> <li>Edit the configuration file \"application.yml\".</li> </ol>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#configuration-file-content","title":"Configuration File Content","text":"<pre><code># Application server port\nserver:\n  port: 8000\n\n# Database and other configurations...\n</code></pre>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#start-the-service","title":"Start the Service","text":"<pre><code>nohup java -jar -Xms2048M -Xmx20000M -XX:PermSize=768M -XX:MaxPermSize=1536M -server -jar filing-system-0.0.1-SNAPSHOT.jar --spring.config.location=application.yml --jasypt.encryptor.password=SfXlqZmK4P257 &amp;\n</code></pre>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#check-logs-for-successful-startup","title":"Check Logs for Successful Startup","text":"<pre><code>tail -f nohup.out\n</code></pre>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#docker-container-deployment","title":"Docker Container Deployment","text":"<ol> <li>Navigate to the directory containing the <code>docker-compose.yml</code> file.</li> <li>Start the service using the command: <code>docker-compose up -d</code>.</li> </ol> <p>After the Docker service starts successfully, you can view the logs using the command: <code>docker logs -f root_whaleal-data_1</code>.</p> <p>For local access, bind the server's IP with the domain name in the hosts file using: <code>sudo sh -c 'echo \"docker_server_ip whaleal-data.com\" &gt;&gt; /etc/hosts'</code>.</p> <p>Access the Whaleal-data service:</p> <ul> <li>Web URL: <code>http://docker_server_ip</code> or <code>http://whaleal-data.com</code></li> <li>Initial login:<ul> <li>User: \"admin\"</li> <li>Password: \"123456\"</li> <li>The system will force you to change the password upon first login.</li> </ul> </li> </ul> <p>Tips: Cold Data Archiving: The default path for cold data archiving is <code>/whalealdb</code>. For Docker, the service is mapped to an external path <code>/opt/whalealdb</code>.</p>"},{"location":"whalealData/InstallationDeployment/Whaleal-dataInstallationDeployment/#quick-access","title":"Quick Access","text":"<p>Start the Whaleal-data service using Docker containers. This service depends on <code>mysql</code>, <code>mongodb</code>, <code>redis</code>, and <code>zookeeper</code> services. It runs in a local browser through the <code>nginx</code> service proxy.</p>"},{"location":"whalealData/InstallationDeployment/ZookeeperInstallationDeployment/","title":"ZookeeperInstallationDeployment","text":""},{"location":"whalealData/InstallationDeployment/ZookeeperInstallationDeployment/#zookeeper-installation-and-deployment","title":"Zookeeper Installation and Deployment","text":""},{"location":"whalealData/InstallationDeployment/ZookeeperInstallationDeployment/#opening-specific-ports-or-disabling-firewall","title":"Opening Specific Ports or Disabling Firewall","text":"<ol> <li>Check already opened ports: <code>firewall-cmd --list-ports</code></li> <li>Open a specific port: <code>firewall-cmd --zone=public --add-port=2181/tcp --permanent</code></li> <li>Reload firewall configuration: <code>firewall-cmd --reload</code></li> <li>Confirm opened ports: <code>firewall-cmd --list-ports</code></li> <li>Stop the firewall: <code>systemctl stop firewalld</code></li> <li>Check firewall status: <code>systemctl status firewalld</code></li> </ol>"},{"location":"whalealData/InstallationDeployment/ZookeeperInstallationDeployment/#installation-and-deployment","title":"Installation and Deployment","text":"<ol> <li>Unpack the installation package: <code>tar -zxvf apache-zookeeper-3.6.1-bin.tar.gz -C /usr/local/</code></li> <li>Rename the extracted folder: <code>mv apache-zookeeper-3.6.1-bin/ zookeeper</code></li> <li>Start Zookeeper: <code>/usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo_sample.cfg</code></li> <li>Verify Zookeeper status: <code>/usr/local/zookeeper/bin/zkServer.sh status /usr/local/zookeeper/conf/zoo_sample.cfg</code></li> </ol> <p>This installation guide provides steps for deploying Zookeeper, opening the required ports, and starting the service. Make sure to follow each step carefully to ensure a successful deployment.</p>"},{"location":"whalealData/UserManual/ArchiveManagement/ColdTaskLogQuery/","title":"ColdTaskLogQuery","text":""},{"location":"whalealData/UserManual/ArchiveManagement/ColdTaskLogQuery/#log-query-cold","title":"Log Query (Cold)","text":"<p>Click on \"Log Query (Cold)\" under the \"Archive Management\" menu to query all file archiving log information. This page includes a search button, search condition fields, and a \"Rewrite\" button for each task.</p> <p></p>"},{"location":"whalealData/UserManual/ArchiveManagement/ColdTaskLogQuery/#searching","title":"Searching","text":"<p>The green button at the top is the search button. The left-hand side condition fields are used for specifying search criteria. After filling in the conditions, click the search button to filter the desired tasks.</p>"},{"location":"whalealData/UserManual/ArchiveManagement/ColdTaskLogQuery/#file-rewriting","title":"File Rewriting","text":"<p>Click on the yellow \"File Rewrite\" button behind a task to initiate a file rewriting operation. This opens a page where you can click \"Create Rewrite Task\" to create the rewrite task.</p> <p></p> <p>Creating a Rewrite Task</p> <p>Clicking the \"Create Rewrite Task\" button opens the following form. Fill in the required information and click \"Confirm.\"</p> <p></p> <p>Delete Temporary Table</p> <p>After creating the rewrite task, you can start the rewriting process. Once it's completed, you can click the \"Delete Temporary Table\" button. A confirmation prompt will appear. If you want to proceed with deletion, click \"Execute.\" If not, click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/ArchiveManagement/FileFullTextSearch/","title":"FileFullTextSearch","text":""},{"location":"whalealData/UserManual/ArchiveManagement/FileFullTextSearch/#file-full-text-search","title":"File Full-Text Search","text":"<p>Click on \"File Full-Text Search\" under the \"Archive Management\" menu to query all file full-text search log information. Click the \"Create Search Task\" button to create a file full-text search task. The system will perform a comprehensive search for files based on the search criteria, and for the found records, you can perform file rewriting operations.</p> <p></p>"},{"location":"whalealData/UserManual/ArchiveManagement/FileFullTextSearch/#searching","title":"Searching","text":"<p>The green button at the top is the search button. The left-hand side condition fields are optional. After filling in the conditions, click the search button to filter the desired search content.</p>"},{"location":"whalealData/UserManual/ArchiveManagement/FileFullTextSearch/#creating-a-search-task","title":"Creating a Search Task","text":"<p>Click the blue \"Create Search Task\" button to open the following form. Fill in the required information and click \"Confirm.\"</p> <p></p>"},{"location":"whalealData/UserManual/ArchiveManagement/FileInspectionManagement/","title":"FileInspectionManagement","text":""},{"location":"whalealData/UserManual/ArchiveManagement/FileInspectionManagement/#file-inspection-management","title":"File Inspection Management","text":"<p>Click on \"File Inspection Management\" under the \"Archive Management\" menu to query all file inspection log information. Click the \"Create Inspection Task\" button to create a file inspection task. The system will perform the necessary file checking and verification logic. For files with exceptions, you can manually update the file path or perform a re-archive operation.</p> <p></p>"},{"location":"whalealData/UserManual/ArchiveManagement/FileInspectionManagement/#searching","title":"Searching","text":"<p>The green button at the top is the search button. The left-hand side has condition fields that you can optionally fill in. After filling in the conditions, click the search button to filter the desired inspection.</p>"},{"location":"whalealData/UserManual/ArchiveManagement/FileInspectionManagement/#creating-an-inspection-task","title":"Creating an Inspection Task","text":"<p>Click the blue \"Create Inspection Task\" button to open the following form. Fill in the required information and click \"Confirm\" to generate inspection data for the corresponding target source of warm data. After completing the task, click \"View Details\" to see the inspection content as shown in the second image.</p> <p></p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DataSourceManagement/","title":"DataSourceManagement","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/DataSourceManagement/#data-source-management","title":"Data Source Management","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/DataSourceManagement/#adding-a-data-source","title":"Adding a Data Source","text":"<p>To add a new data source, navigate to \"Data Source Management\" under the \"Configuration Management\" menu. Here, you can view all the information about existing data sources. Click on the \"New\" button in the first image to bring up the form shown in the second image, where you can input the details of the new data source. Data sources can include MongoDB, MYSQL, Oracle, and DB2. Provide the required username and password for connecting to the database. The \"Options\" field contains optional settings for configuring specific connection options for the database. Click the \"Test\" button to verify if the provided user information can connect to the database. Finally, click \"Confirm\" to save the data source.</p> <p></p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DataSourceManagement/#modifying-a-data-source","title":"Modifying a Data Source","text":"<p>Click the blue button in the right-hand side action column to edit a data source. The form for editing a data source is similar to the form for adding a data source. After making the necessary modifications, click \"Test.\" If the test is successful, click \"Confirm\" to save the changes.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DataSourceManagement/#deleting-a-data-source","title":"Deleting a Data Source","text":"<p>Click the red button in the right-hand side action column to delete a data source. A confirmation prompt will appear. If you intend to delete the data source, click \"Confirm.\" If you clicked by mistake, you can click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DataSourceManagement/#binding-data-source-to-users","title":"Binding Data Source to Users","text":"<p>Navigate to \"User Management\" under \"System Management\" to display all user information. Click on the user you want to operate on, and then check the data sources you want to bind to this user on the right side. Afterward, click \"Save\" to bind the selected data sources to the user.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DestinationSourceManagement/","title":"DestinationSourceManagement","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/DestinationSourceManagement/#target-source-management","title":"Target Source Management","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/DestinationSourceManagement/#adding-warmcolds3-data-target-sources","title":"Adding Warm/Cold/S3 Data Target Sources","text":"<p>To add a new target source, navigate to \"Target Source Management\" under the \"Configuration Management\" menu. If you want to add a warm data target source, click on \"Warm Data Target Source.\" For cold data target sources, click on \"Cold Data File Source.\" Similarly, for S3 target sources, click on \"S3.\" Then, click the \"New\" button to bring up the form for adding a new target source. The process for cold data and S3 is similar to adding a data source. After completing the necessary details, click \"Confirm\" to save the target source. For cold data file sources, click \"Confirm\" after filling in the required information.</p> <p></p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DestinationSourceManagement/#modifying-warmcolds3-data-target-sources","title":"Modifying Warm/Cold/S3 Data Target Sources","text":"<p>Click the blue button to edit a target source. The process for modifying warm data target sources and S3 is similar to modifying a data source. For cold data file sources, modify the path and click \"Confirm\" to save the changes.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DestinationSourceManagement/#deleting-warmcolds3-data-target-sources","title":"Deleting Warm/Cold/S3 Data Target Sources","text":"<p>Click the red button to delete a target source. A confirmation prompt will appear. If you intend to delete the target source, click \"Confirm.\" If not, click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/DestinationSourceManagement/#binding-warmcolds3-data-target-sources-to-users","title":"Binding Warm/Cold/S3 Data Target Sources to Users","text":"<p>The process of binding target sources is similar to binding data sources. If you want to bind a target source, click on the target source, and then check the relevant sources. The process is the same for file sources and S3. After that, click \"Save\" to grant the user access to the selected sources.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/","title":"TableJobConfiguration","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/#table-job-configuration","title":"Table Job Configuration","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/#adding-warmcolds3-jobs","title":"Adding Warm/Cold/S3 Jobs","text":"<p>To configure a new table job, navigate to \"Table Job Configuration\" under the \"Configuration Management\" menu. If you want to configure a warm data table job, click on \"Warm Data Table Job Configuration.\" For cold data table job configuration, click on \"Cold Data Table Job Configuration.\" Similarly, for S3 table job configuration, click on \"S3 Table Job Configuration.\" Click the type that you want to add, and then a table will appear displaying the respective job information. The process for adding each type of job is similar.</p> <p>After selecting the data source and target source, you can choose options such as consistency verification, archiving method, and data processing mode. If you choose consistency verification, you can fill in the verification percentage. When the archiving mode is \"Full Update,\" you don't need to enter SQL conditions, as the platform archives the entire table data directly. When the archiving mode is \"Incremental Update,\" an input field for SQL conditions will appear along with a \"Custom SQL Configuration\" button, as shown in the third image. If you want to configure custom SQL, you can click the button to enter the visual configuration interface for table fields, as shown in the fourth image. When both the data source and target source are MongoDB, you can choose Gridfs. If Gridfs is enabled, MongoDB's Gridfs data type will be synchronized.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/#editing-warmcolds3-jobs","title":"Editing Warm/Cold/S3 Jobs","text":"<p>Click the blue button on the right to edit a job. After making the necessary changes to the job, click \"Save\" to save the modifications.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/#deleting-warmcolds3-jobs","title":"Deleting Warm/Cold/S3 Jobs","text":"<p>Click the red button on the right to delete a job. A confirmation prompt will appear. If you intend to delete the job, click \"Confirm.\" If not, click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/#searching-warmcolds3-jobs","title":"Searching Warm/Cold/S3 Jobs","text":"<p>Click the search button at the top and fill in the first three condition boxes to filter all table job configurations that meet the specified criteria on the platform.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TableJobConfiguration/#viewing-warmcolds3-jobs","title":"Viewing Warm/Cold/S3 Jobs","text":"<p>Click the \"View\" button on the right to see the job configuration details. However, you won't be able to perform any actions in this view.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TaskConfiguration/","title":"TaskConfiguration","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/TaskConfiguration/#task-configuration","title":"Task Configuration","text":""},{"location":"whalealData/UserManual/ConfigurationManagement/TaskConfiguration/#adding-warmcolds3-tasks","title":"Adding Warm/Cold/S3 Tasks","text":"<p>To configure a new task, go to \"Task Configuration\" under the \"Configuration Management\" menu. Click on \"Warm Data Task Configuration\" to view all warm data archiving task information. Click on \"Cold Data Task Configuration\" to view all cold data archiving task information. Similarly, click on \"S3 Task Configuration\" to view all S3 archiving task information. After selecting the type of task you want to add, click the \"Add\" button to bring up the table shown in the second image. Click \"Add Job\" to show the already configured table job configuration, and then associate the desired table jobs with the task configuration, as shown in the third image. A task can have multiple table jobs associated with it. You can choose between manual tasks, recurring tasks, and one-time tasks. For one-time tasks, you can set the execution time using a Cron expression, while recurring tasks must have a Cron expression for scheduling. Since a task can have multiple table jobs, you can configure the execution mode to be either serial or parallel. You can also set the task timeout and configure the number of retries in case of failure. Additionally, you can set up email notifications for task success or failure. Once the configuration is complete, as shown in the fourth image, click \"Confirm.\" After configuration, the task needs to be reviewed by a management user.</p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TaskConfiguration/#editing-warmcolds3-tasks","title":"Editing Warm/Cold/S3 Tasks","text":"<p>Click the edit button to open the table shown in the first image. This task configuration can be edited or deleted until it is reviewed by a management user. Once reviewed, the task cannot be edited or deleted. After editing the task, click \"Confirm\" to save the changes.</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TaskConfiguration/#deleting-warmcolds3-tasks","title":"Deleting Warm/Cold/S3 Tasks","text":"<p>Before being reviewed by a management user, tasks can be edited or deleted. Click the red \"Delete\" button to show a confirmation prompt. If you are sure you want to delete the task, click \"Delete.\" If not, click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/ConfigurationManagement/TaskConfiguration/#searching-warmcolds3-tasks","title":"Searching Warm/Cold/S3 Tasks","text":"<p>There are two condition boxes before the search button. Fill in the criteria and click \"Search\" to filter the task configurations that match the specified criteria.</p> <p></p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/","title":"HomepageDisplay","text":""},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#homepage-display","title":"Homepage Display","text":"<p>The homepage displays various statistics and information related to the system's activities. Users can customize the time range for which they want to see the data. Here's a breakdown of the different sections on the homepage:</p> <p></p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#task-execution-statistics","title":"Task Execution Statistics","text":"<p>The \"Task Execution Statistics\" pie chart depicts the distribution of task execution results within a specific time range. Task execution statuses include running (in progress), succeeded (successfully completed), failed (execution failed), and other (remaining types).</p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#archiving-capacity-statistics","title":"Archiving Capacity Statistics","text":"<p>The \"Archiving Capacity Statistics\" section displays the total size of data synchronized from different source types to various destination types. The first column represents source types, the second column represents destination types, and the third column represents either cold data destination files or S3. The capacity statistics depend on the source and destination types, and certain combinations are supported based on compatibility.</p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#user-activity-statistics","title":"User Activity Statistics","text":"<p>The \"User Activity Statistics\" section scrolls through and displays the actions taken by a user during a specific time period. It showcases login actions, task executions, and other relevant activities performed by users.</p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#table-job-statistics","title":"Table Job Statistics","text":"<p>The \"Table Job Statistics\" section presents a line chart depicting the quantity of different types of table jobs executed within the chosen time range. This helps users observe recent trends in task execution. Users can select different job types from the dropdown menu to view the corresponding line chart.</p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#business-access-number-of-sources","title":"Business Access (Number of Sources)","text":"<p>The \"Business Access (Number of Sources)\" section displays the number of data source accesses made to the platform during the specified time period. It shows the growth trend of data source accesses over time. Similarly, users can choose different data source types from the dropdown menu.</p>"},{"location":"whalealData/UserManual/HomepageDisplay/HomepageDisplay/#total-archiving-volume","title":"Total Archiving Volume","text":"<p>The \"Total Archiving Volume\" section presents a line chart illustrating the total data volume archived by the platform within the selected time range. This helps users track the growth trend of archiving volume over time.</p>"},{"location":"whalealData/UserManual/LoginPage/UserFirstLogin/","title":"UserFirstLogin","text":""},{"location":"whalealData/UserManual/LoginPage/UserFirstLogin/#first-time-user-login","title":"First-Time User Login","text":"<p>During the system initialization, the administrator account is set as \"admin\" with the password \"123456\". When logging in for the first time, users will be prompted to change their password. After modifying the password during the initial login, users can proceed to log in with the new password.</p> <p></p>"},{"location":"whalealData/UserManual/LoginPage/UserRegistration/","title":"UserRegistration","text":""},{"location":"whalealData/UserManual/LoginPage/UserRegistration/#user-registration","title":"User Registration","text":"<p>The platform supports self-registration of user accounts. After registering, the administrator user can assign resource permissions to new users.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/AbnormalJobExecutionStatistics/","title":"AbnormalJobExecutionStatistics","text":""},{"location":"whalealData/UserManual/StatisticalReports/AbnormalJobExecutionStatistics/#abnormal-job-execution-statistics","title":"Abnormal Job Execution Statistics","text":"<p>Clicking on the \"Abnormal Job Execution Statistics\" under the \"Statistics Report\" menu allows you to query the archival information of all abnormal table jobs. This page includes a search button, search criteria fields, a clear criteria button, and an export button.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/AbnormalJobExecutionStatistics/#search","title":"Search","text":"<p>The green button in the image above is the search button. On the left side, there's a criteria field. After filling in the filtering criteria, click \"Search\" to filter out abnormal table job statistics that match the criteria.</p>"},{"location":"whalealData/UserManual/StatisticalReports/AbnormalJobExecutionStatistics/#clear","title":"Clear","text":"<p>The black button is the clear button, which clears the time criteria fields.</p>"},{"location":"whalealData/UserManual/StatisticalReports/AbnormalJobExecutionStatistics/#export","title":"Export","text":"<p>The yellow button is the export button, which allows you to export the abnormal table job statistics information as an XLSX file.</p>"},{"location":"whalealData/UserManual/StatisticalReports/DataHistoricalFlow/","title":"DataHistoricalFlow","text":""},{"location":"whalealData/UserManual/StatisticalReports/DataHistoricalFlow/#data-historical-flow","title":"Data Historical Flow","text":"<p>Clicking on the \"Data Historical Flow\" under the \"Statistics Report\" menu displays the data source flow within the platform. This page includes a search button, search criteria fields, and a clear criteria button.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/DataHistoricalFlow/#search","title":"Search","text":"<p>The green button in the image above is the search button. On the left side, there are three criteria fields. After filling in the filtering criteria, click \"Search\" to filter out data flows that match the criteria.</p>"},{"location":"whalealData/UserManual/StatisticalReports/JobDetails/","title":"JobDetails","text":""},{"location":"whalealData/UserManual/StatisticalReports/JobDetails/#job-details","title":"Job Details","text":"<p>Clicking on \"Job Details\" under the \"Statistics Report\" menu displays the detailed information about jobs within the platform. This page includes a search button, search criteria fields, and an export button.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/JobDetails/#search","title":"Search","text":"<p>The green button in the image above is the search button. On the left side, there are three criteria fields. After filling in the filtering criteria, click \"Search\" to filter out job details that match the criteria.</p>"},{"location":"whalealData/UserManual/StatisticalReports/JobDetails/#export","title":"Export","text":"<p>The yellow button is the export button, which allows you to export the job details statistics information as an xlsx file.</p>"},{"location":"whalealData/UserManual/StatisticalReports/JobDetails/#link","title":"Link","text":"<p>For each job detail, there is a \"Link\" button. Clicking the link button will navigate you to the task monitoring page for that specific job.</p>"},{"location":"whalealData/UserManual/StatisticalReports/RollbackRecordsStatistics/","title":"RollbackRecordsStatistics","text":""},{"location":"whalealData/UserManual/StatisticalReports/RollbackRecordsStatistics/#rollback-records-statistics","title":"Rollback Records Statistics","text":"<p>Clicking on \"Rollback Records Statistics\" under the \"Statistics Report\" menu allows you to query all the rolled-back tasks. This page includes a search button, search criteria fields, and an export button. Each rolled-back task entry includes information such as task name, job name, archive type, execution start and end time, execution status, error message, progress percentage, archived item count, archive path, executed SQL, and rollback status.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/RollbackRecordsStatistics/#search","title":"Search","text":"<p>The green button in the image above is the search button. On the left side, there are three criteria fields. After filling in the filtering criteria, click \"Search\" to filter out rollback records that match the criteria.</p>"},{"location":"whalealData/UserManual/StatisticalReports/RollbackRecordsStatistics/#export","title":"Export","text":"<p>The yellow button is the export button, which allows you to export the rollback records statistics information as an xlsx file.</p>"},{"location":"whalealData/UserManual/StatisticalReports/SystemAccessStatistics/","title":"SystemAccessStatistics","text":""},{"location":"whalealData/UserManual/StatisticalReports/SystemAccessStatistics/#system-access-statistics","title":"System Access Statistics","text":"<p>Clicking on \"System Access Statistics\" under the \"Statistics Report\" menu allows you to query all the businesses that have accessed this platform. This page includes a search button, search criteria fields, a clear criteria button, and an export button. Each entry represents a business that has accessed the platform, and it includes information such as business name, data source type, target source type, and access time.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/SystemAccessStatistics/#search","title":"Search","text":"<p>The green button in the image above is the search button. On the left side, there are two criteria fields. After filling in the filtering criteria, click \"Search\" to filter out access information that matches the criteria.</p>"},{"location":"whalealData/UserManual/StatisticalReports/SystemAccessStatistics/#clear","title":"Clear","text":"<p>The black button is the clear button, which clears the criteria fields.</p>"},{"location":"whalealData/UserManual/StatisticalReports/SystemAccessStatistics/#export","title":"Export","text":"<p>The yellow button is the export button, allowing you to export the system access statistics information as an xlsx file.</p>"},{"location":"whalealData/UserManual/StatisticalReports/SystemAccessStatistics/#details","title":"Details","text":"<p>Clicking on the \"Details\" link for each access record provides more detailed information about that access, including the business name, access type, source and target types, and access time.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/TableJobExecutionStatistics/","title":"TableJobExecutionStatistics","text":""},{"location":"whalealData/UserManual/StatisticalReports/TableJobExecutionStatistics/#table-job-execution-statistics","title":"Table Job Execution Statistics","text":"<p>Clicking on \"Table Job Execution Statistics\" under the \"Statistics Report\" menu allows you to query the archival information for all table jobs. This page includes a search button, search criteria fields, a clear criteria button, and an export button. Each entry represents a table job execution and includes information such as job name, table name, data source type, target source type, execution start and end times, execution status, exception errors, progress percentage, number of archived rows, archival path, executed SQL, and rollback status.</p> <p></p>"},{"location":"whalealData/UserManual/StatisticalReports/TableJobExecutionStatistics/#search","title":"Search","text":"<p>The green button in the image above is the search button. On the left side, there are two criteria fields. After filling in the filtering criteria, click \"Search\" to filter out job executions that match the criteria.</p>"},{"location":"whalealData/UserManual/StatisticalReports/TableJobExecutionStatistics/#clear","title":"Clear","text":"<p>The black button is the clear button, which clears the criteria fields.</p>"},{"location":"whalealData/UserManual/StatisticalReports/TableJobExecutionStatistics/#export","title":"Export","text":"<p>The yellow button is the export button, allowing you to export the table job execution statistics information as an xlsx file.</p> <p>These features help you keep track of and analyze the execution status and details of various table jobs in the system.</p> <p>Please note that due to the screenshot's resolution, some text may be difficult to read.</p>"},{"location":"whalealData/UserManual/SystemManagement/ErrorLog/","title":"ErrorLog","text":""},{"location":"whalealData/UserManual/SystemManagement/ErrorLog/#error-logs","title":"Error Logs","text":""},{"location":"whalealData/UserManual/SystemManagement/ErrorLog/#search","title":"Search","text":"<p>Clicking on \"System Operation Logs\" under the \"System Management\" menu allows administrators to view error logs related to user actions on the platform. The page displays error logs generated from user actions. The green button is the search button. On the left side, there is a criteria field. Fill in the filtering criteria in the field, and then click \"Search\" to filter out the desired error logs. By clicking the \"View Details\" button on the right, you can view the details of the error and its causes.</p> <p></p> <p>These error logs help administrators identify and address issues or unexpected behaviors in the system, providing insights into the activities that led to errors.</p>"},{"location":"whalealData/UserManual/SystemManagement/MenuManagement/","title":"MenuManagement","text":""},{"location":"whalealData/UserManual/SystemManagement/MenuManagement/#menu-management","title":"Menu Management","text":"<p>Clicking on \"Menu Management\" under the \"System Management\" menu allows administrators to manage the menus within the platform. This page is visible only to administrator users. On this page, you can view information about all the menus, as well as perform actions such as searching, adding, modifying, and deleting menus.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/MenuManagement/#search","title":"Search","text":"<p>The green button at the top is the search button. On the left side, there are two criteria fields. Fill in the filtering criteria in these fields, and then click \"Search\" to filter the desired menus.</p>"},{"location":"whalealData/UserManual/SystemManagement/MenuManagement/#add","title":"Add","text":"<p>The blue button is the \"Add\" button. Clicking it will bring up a form, as shown in the image below. In this form, you can customize the menu type, menu icon, external link menu, menu visibility, menu title, route address, menu sorting, parent directory, and more. Once you've configured the menu, click \"Confirm\" to save it.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/MenuManagement/#edit","title":"Edit","text":"<p>Clicking the blue pencil icon next to a menu's name will bring up an edit form where you can modify the menu's configuration according to your needs. Once you're done, click \"Confirm\" to save the changes.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/MenuManagement/#delete","title":"Delete","text":"<p>The delete button for menus is not available, likely to prevent accidental deletion. Instead, menus can be hidden based on requirements.</p>"},{"location":"whalealData/UserManual/SystemManagement/OperationLog/","title":"OperationLog","text":""},{"location":"whalealData/UserManual/SystemManagement/OperationLog/#operation-logs","title":"Operation Logs","text":""},{"location":"whalealData/UserManual/SystemManagement/OperationLog/#search","title":"Search","text":"<p>Clicking on \"Operation Logs\" under the \"System Management\" menu, which is visible only to administrator users, will take you to a page displaying operation logs of platform users. The green button is the search button. On the left side, there are criteria fields. Fill in the filtering criteria in these fields, and then click \"Search\" to filter the desired operation logs.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/","title":"RoleManagement","text":""},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/#role-management","title":"Role Management","text":"<p>Clicking on \"Role Management\" under the \"System Management\" menu, which is visible only to administrator users, will take you to a page where you can view information about all role permissions categories in the platform.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/#search","title":"Search","text":"<p>The green button at the top is the search button. On the left side, there are two criteria fields. Fill in these fields and click \"Search\" to filter the desired role list.</p>"},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/#add","title":"Add","text":"<p>The blue button is the add button. Clicking the \"Add\" button will open the interface as shown in the image. Fill in the role name and role permissions to add role information.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/#edit","title":"Edit","text":"<p>Clicking the blue pencil icon on the right side of a role opens the edit role dialog. You can modify the role's name, permissions, or add a description. Click \"Save\" when done.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/#delete","title":"Delete","text":"<p>The red button on the right side is the delete button. Clicking the delete button will prompt whether you are sure you want to delete the role. If you confirm deletion, click \"OK\"; if not, click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/RoleManagement/#menu-assignment","title":"Menu Assignment","text":"<p>Clicking on a role reveals the menus associated with that role on the right side. Check and assign menus according to the actual permissions and menus the role should have. Save the data to bind the menus that the role can operate with.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/SystemSettings/","title":"SystemSettings","text":""},{"location":"whalealData/UserManual/SystemManagement/SystemSettings/#smtp-email-settings","title":"SMTP Email Settings","text":"<p>Clicking on \"System Settings\" under the \"System Management\" menu, which is visible only to administrator users, will take you to a page where SMTP configuration is displayed. After filling in the basic configuration, click the \"Test Connection\" button. If the test is successful and you receive a test email, a \"Save\" button will appear. Once the SMTP configuration is saved, alert emails for task configurations will be sent from the email address configured here.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/","title":"UserManagement","text":""},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#user-management","title":"User Management","text":"<p>Clicking on \"User Management\" under the \"System Management\" menu, visible only to administrator users, will take you to a page displaying all user information on the platform, including database permissions and bindings.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#search","title":"Search","text":"<p>The green button is the search button. Fill in the left two search boxes with relevant criteria and click the search button to filter the desired user information.</p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#add-user","title":"Add User","text":"<p>The second blue button is the \"Add\" button. Clicking on it will bring up the interface shown in the image above. Fill in the username, email, phone number, and password to add a new user. In the \"Role\" section, you can select the system permissions for the user, as well as the user's status (enabled or disabled).</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#export-users","title":"Export Users","text":"<p>The third yellow button is the \"Export Users\" button. Clicking on it will generate an xlsx file containing information for all users. You can customize the file name.</p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#modify-user-details","title":"Modify User Details","text":"<p>Clicking on the pencil icon on the right side of a user's row will allow you to modify user information. An edit page will pop up with editable fields for all user details except for the password. Modify the information as needed and click \"Confirm\" to save the changes.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#change-password","title":"Change Password","text":"<p>Clicking on the second password icon on the right side of a user's row will allow you to change the user's password. A form will appear where you can enter the new password. After entering the new password, click \"Confirm\" to save the changes.</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#delete-user","title":"Delete User","text":"<p>Clicking on the third red button on the right side of a user's row will prompt a confirmation message asking if you want to delete the user. If you confirm deletion, click \"Confirm.\" If you don't want to delete the user, click \"Cancel.\"</p> <p></p>"},{"location":"whalealData/UserManual/SystemManagement/UserManagement/#database-permissions-data-sources-target-sources-file-sources-s3","title":"Database Permissions (Data Sources, Target Sources, File Sources, S3)","text":"<p>Clicking on a user's row will display the database permissions assigned to that user, including data sources, target sources, file sources, and S3. Check the sources that the user should have access to, then click \"Save.\"</p> <p></p>"},{"location":"whalealData/UserManual/TaskManagement/ColdTaskMonitoring/","title":"ColdTaskMonitoring","text":""},{"location":"whalealData/UserManual/TaskManagement/ColdTaskMonitoring/#task-monitoring-cold","title":"Task Monitoring (Cold)","text":""},{"location":"whalealData/UserManual/TaskManagement/ColdTaskMonitoring/#task-status","title":"Task Status","text":"<p>Clicking on \"Task Monitoring (Cold)\" under the \"Task Management\" menu will display information about the execution status of cold tasks. This page includes information about completed tasks, ongoing tasks, and tasks with exceptions. Each search button is associated with a set of search criteria, allowing you to filter and display tasks efficiently.</p> <p></p>"},{"location":"whalealData/UserManual/TaskManagement/ColdTaskMonitoring/#completed-tasks","title":"Completed Tasks","text":"<p>Clicking on \"Completed Tasks\" will display information about tasks that have been successfully completed. This page includes details such as the execution strategy, start and end times, duration, execution status, progress percentage, archived items, archive path, source table data status, and executed SQL statements. The page also features four buttons: search, modify source table data status, manually delete source table data, and refresh.</p> <p></p> <p>Search</p> <p>The green button at the top is the search button. Enter criteria in the provided search boxes and click the search button to display filtered completed tasks.</p> <p>Modify Source Table Data Status</p> <p>After synchronization is completed, if source table data has been manually deleted, you can click the yellow button to mark the source table data as processed.</p> <p>Manually Delete Source Table Data</p> <p>The red button allows you to manually delete source table data. If the table job configuration does not include automatic deletion and you want to manually delete the source data after synchronization, you can use this button.</p> <p>Refresh</p> <p>The progress percentage of a task is updated every 3 seconds. Clicking the refresh button will update the progress bar and task status.</p>"},{"location":"whalealData/UserManual/TaskManagement/ColdTaskMonitoring/#ongoing-tasks","title":"Ongoing Tasks","text":"<p>Clicking on \"Ongoing Tasks\" will display information about tasks that are currently in progress. This page includes details such as the execution strategy, start and end times, duration, execution status, progress percentage, archived items, and executed SQL statements. The page features three buttons: search, terminate task, and task status validation.</p> <p></p> <p>Search</p> <p>The green button is the search button. Fill in the provided search boxes as needed, and then click the search button to display all ongoing tasks that match the criteria.</p> <p>Terminate Task</p> <p>The red button allows you to terminate an ongoing task. After clicking this button, the task will be terminated and will appear in the list of tasks with exceptions. If the termination is successful, the task will also be marked as completed.</p> <p>Task Status Validation</p> <p>Each task can contain multiple table jobs. When one table job is completed, the next one starts. If the task status does not update after a table job has been completed, you can click the \"Task Status Validation\" button to update the task status.</p>"},{"location":"whalealData/UserManual/TaskManagement/ColdTaskMonitoring/#exception-tasks","title":"Exception Tasks","text":"<p>Clicking on \"Exception Tasks\" will display information about tasks that encountered exceptions. This page includes details such as the execution strategy, start and end times, duration, execution status, exception details, progress percentage, archived items, archive path, executed SQL statements, and rollback status. This page features three buttons: search, rollback, and re-execute.</p> <p></p> <p>Search</p> <p>The green button at the top is the search button. Fill in the provided search boxes with criteria and click the search button to display filtered exception tasks.</p> <p>Rollback</p> <p>Each exception task has a rollback button. Clicking on this button will initiate a rollback of the exception data synchronized by the subtask. If the rollback button of the parent task is clicked, all subtasks under that parent task will be rolled back.</p> <p>Re-execute</p> <p>Each subtask of an exception task has a re-execute button. Clicking this button will generate a new parent task associated with the exception task. The exception task will be linked to the new parent task. After the rollback of the exception data is completed, the task will appear in the ongoing tasks list, and you can re-execute it.</p>"},{"location":"whalealData/UserManual/TaskManagement/S3TaskMonitoring/","title":"S3TaskMonitoring","text":""},{"location":"whalealData/UserManual/TaskManagement/S3TaskMonitoring/#task-monitoring-s3","title":"Task Monitoring (S3)","text":"<p>Clicking on \"Task Monitoring (S3)\" under the \"Task Management\" menu will display information about the execution status of S3 tasks. This page includes information about completed tasks, ongoing tasks, and tasks with exceptions. Each search button is associated with a set of search criteria, allowing you to filter and display tasks efficiently.</p> <p></p>"},{"location":"whalealData/UserManual/TaskManagement/S3TaskMonitoring/#task-status","title":"Task Status","text":""},{"location":"whalealData/UserManual/TaskManagement/S3TaskMonitoring/#completed-tasks","title":"Completed Tasks","text":"<p>Clicking on \"Completed Tasks\" will display information about tasks that have been successfully completed. This page includes details such as the execution strategy, start and end times, duration, execution status, progress percentage, archived items, source table data status, and executed SQL statements. The page also features four buttons: search, modify source table data status, manually delete source table data, and refresh.</p> <p></p> <p>Search</p> <p>The green button at the top is the search button. Enter criteria in the provided search boxes and click the search button to display filtered completed tasks.</p> <p>Modify Source Table Data Status</p> <p>After synchronization is completed, if source table data has been manually deleted, you can click the yellow button to mark the source table data as processed.</p> <p>Manually Delete Source Table Data</p> <p>The red button allows you to manually delete source table data. If the table job configuration does not include automatic deletion and you want to manually delete the source data after synchronization, you can use this button.</p> <p>Refresh</p> <p>The progress percentage of a task is updated every 3 seconds. Clicking the refresh button will update the progress bar and task status.</p>"},{"location":"whalealData/UserManual/TaskManagement/S3TaskMonitoring/#ongoing-tasks","title":"Ongoing Tasks","text":"<p>Clicking on \"Ongoing Tasks\" will display information about tasks that are currently in progress. This page includes details such as the execution strategy, start and end times, duration, execution status, progress percentage, archived items, and executed SQL statements. The page features three buttons: search, terminate task, and task status validation.</p> <p></p> <p>Search</p> <p>The green button is the search button. Fill in the provided search boxes as needed, and then click the search button to display all ongoing tasks that match the criteria.</p> <p>Terminate Task</p> <p>The red button allows you to terminate an ongoing task. After clicking this button, the task will be terminated and will appear in the list of tasks with exceptions. If the termination is successful, the task will also be marked as completed.</p> <p>Task Status Validation</p> <p>Each task can contain multiple table jobs. When one table job is completed, the next one starts. If the task status does not update after a table job has been completed, you can click the \"Task Status Validation\" button to update the task status.</p>"},{"location":"whalealData/UserManual/TaskManagement/S3TaskMonitoring/#exception-tasks","title":"Exception Tasks","text":"<p>Clicking on \"Exception Tasks\" will display information about tasks that encountered exceptions. This page includes details such as the execution strategy, start and end times, duration, execution status, exception details, progress percentage, archived items, executed SQL statements, and rollback status. This page features three buttons: search, rollback, and re-execute.</p> <p></p> <p>Search</p> <p>The green button at the top is the search button. Fill in the provided search boxes with criteria and click the search button to display filtered exception tasks.</p> <p>Rollback</p> <p>Each exception task has a rollback button. Clicking on this button will initiate a rollback of the exception data synchronized by the subtask. If the rollback button of the parent task is clicked, all subtasks under that parent task will be rolled back.</p> <p>Re-execute</p> <p>Each subtask of an exception task has a re-execute button. Clicking this button will generate a new parent task associated with the exception task. The exception task will be linked to the new parent task. After the rollback of the exception data is completed, the task will appear in the ongoing tasks list, and you can re-execute it.</p>"},{"location":"whalealData/UserManual/TaskManagement/TaskScheduling/","title":"TaskScheduling","text":""},{"location":"whalealData/UserManual/TaskManagement/TaskScheduling/#task-scheduling","title":"Task Scheduling","text":"<p>Clicking on \"Task Scheduling\" under the \"Task Management\" menu will display a page that shows tasks that have been approved. The search button with associated search criteria boxes can be used to filter and display tasks based on the specified criteria. For individual tasks, you can modify their status, such as enabling, disabling, taking them offline, or executing them immediately.</p> <p></p>"},{"location":"whalealData/UserManual/TaskManagement/TaskScheduling/#enable-task","title":"Enable Task","text":"<p>After a task has been disabled, it cannot be executed. You can enable a disabled task by clicking the \"Enable Task\" button on the right side of the task. After enabling the task, you can click the \"Run Now\" button to execute the task immediately or let it run automatically at the scheduled time.</p>"},{"location":"whalealData/UserManual/TaskManagement/TaskScheduling/#disable-task","title":"Disable Task","text":"<p>You can click the gray button on the right side of a task to disable it. Once a task is disabled, it will not be executed. You need to enable the task again for it to resume normal operation.</p>"},{"location":"whalealData/UserManual/TaskManagement/TaskScheduling/#run-now","title":"Run Now","text":"<p>The third button on the right side of a task allows you to execute it immediately. For full synchronization tasks, clicking this button will initiate the synchronization immediately. For incremental synchronization tasks, clicking \"Run Now\" will execute the next scheduled task that has not yet reached its execution time.</p>"},{"location":"whalealData/UserManual/TaskManagement/TaskScheduling/#take-task-offline","title":"Take Task Offline","text":"<p>The rightmost button, \"Take Task Offline,\" allows you to take a task offline. Clicking this button will prompt a confirmation dialog to confirm the offline operation. Once a task is taken offline, it cannot be restored, and the task will become unavailable. If you want to proceed with taking the task offline, click \"Take Offline.\" If you want to cancel, click \"Cancel.\"</p>"},{"location":"whalealData/UserManual/TaskManagement/WarmTaskMonitoring/","title":"WarmTaskMonitoring","text":""},{"location":"whalealData/UserManual/TaskManagement/WarmTaskMonitoring/#task-monitoring-warm","title":"Task Monitoring (Warm)","text":"<p>Clicking on \"Task Monitoring (Warm)\" under the \"Task Management\" menu will display a page that shows the execution status of warm tasks. The page includes information about completed tasks, tasks in progress, and exceptional tasks. Each search button is associated with condition boxes that allow you to filter and display tasks based on specified criteria.</p> <p></p>"},{"location":"whalealData/UserManual/TaskManagement/WarmTaskMonitoring/#completed-tasks","title":"Completed Tasks","text":"<p>Clicking on completed tasks will display information about tasks that have been successfully completed. The information includes execution strategy, start and end times, execution duration, execution status, progress percentage, archived records count, source data status, and executed SQL statements. There are four buttons at the top: Search, Modify Source Data Status, Manually Delete Source Data, and Refresh.</p> <p>Search</p> <p>The green button at the top is the search button. By entering conditions in the provided boxes and clicking on the search button, you can filter and display completed tasks that match the criteria.</p> <p>Modify Source Data Status</p> <p>After a synchronization is completed and if source data has been manually deleted, you can click the yellow button to modify the source data status to \"processed.\"</p> <p>Manually Delete Source Data</p> <p>The red button allows you to manually delete source data. If automatic deletion is not configured in the table job settings, you can manually delete the source data from the database. Alternatively, you can click the \"Manually Delete Source Data\" button after selecting a task.</p> <p>Refresh</p> <p>The progress percentage of a task is updated every 3 seconds. As a result, the progress bar display might not be real-time. Clicking the refresh button updates the progress bar and some task statuses.</p>"},{"location":"whalealData/UserManual/TaskManagement/WarmTaskMonitoring/#tasks-in-progress","title":"Tasks in Progress","text":"<p>Clicking on tasks in progress will display information about tasks that are currently being executed and archived. The information includes execution strategy, start and end times, execution duration, execution status, progress percentage, archived records count, executed SQL statements. There are three buttons: Search, Terminate Task, and Verify Task Status.</p> <p>Search</p> <p>The green button is the search button. Enter conditions in the provided boxes and click the search button to filter and display tasks in progress that match the criteria.</p> <p>Terminate Task</p> <p>The red button allows you to terminate a task. After selecting a task and clicking the \"Terminate Task\" button, the task will be terminated. The task will then appear in the exceptional tasks section if it was not completed normally.</p> <p>Verify Task Status</p> <p>A task can include multiple table jobs. When one table job is completed, the next one starts. If a task's status does not update promptly after a table job is completed, you can click the \"Verify Task Status\" button to update the task's status.</p>"},{"location":"whalealData/UserManual/TaskManagement/WarmTaskMonitoring/#exceptional-tasks","title":"Exceptional Tasks","text":"<p>Clicking on exceptional tasks will display information about tasks that encountered exceptions. The information includes execution strategy, start and end times, execution duration, execution status, error details, progress percentage, archived records count, executed SQL statements, and rollback status. There are three buttons: Search, Rollback, and Re-execute.</p> <p>Search</p> <p>The green button is the search button. Enter conditions in the provided boxes and click the search button to filter and display exceptional tasks that match the criteria.</p> <p>Rollback</p> <p>Each exceptional task has a rollback button. Clicking the rollback button for a sub-task will roll back the exceptional data that was synchronized. Clicking the rollback button for a parent task will roll back all sub-tasks under that parent task.</p> <p>Re-execute</p> <p>Sub-tasks under an exceptional task have a re-execute button. Clicking the re-execute button will generate a new parent task. The exceptional task and the new parent task will be linked. After rolling back the exceptional data, both the exceptional task and the new parent task will appear in the \"Tasks in Progress\" section for re-execution.</p>"},{"location":"whalealData/use%20cases/AbnormalTaskFeedback/","title":"AbnormalTaskFeedback","text":""},{"location":"whalealData/use%20cases/AbnormalTaskFeedback/#handling-exceptional-tasks","title":"Handling Exceptional Tasks","text":"<p>When encountering exceptions during cold data archiving, you can follow these steps to address the issue:</p> <ol> <li>Navigate to the \"Archive Management (Cold Data)\" menu and select \"Log Query (Cold)\".</li> <li>This page will display the archived cold data tasks. Click on \"File Rewriting\" to perform a rollback of the archived files into the database.</li> </ol> <p></p> <p>This process allows you to manage and recover from any anomalies that might occur during the cold data archiving process.</p>"},{"location":"whalealData/use%20cases/AddColdDataFullLoadJob/","title":"AddColdDataFullLoadJob","text":""},{"location":"whalealData/use%20cases/AddColdDataFullLoadJob/#adding-a-cold-data-full-job","title":"Adding a Cold Data Full Job","text":"<p>To set up a full job for cold data archiving, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>In the \"Cold Data Table Job\" page, click on the blue \"Add\" button to open the form.</li> <li>Fill out the form by selecting the data source table and file source for synchronization. Choose the archiving mode as \"Full Update\".</li> <li>Note that cold data archiving is applicable only to MongoDB data.</li> <li>The table job comes with consistency validation. Select \"Yes\" and specify the required validation percentage. After synchronization, the platform will perform consistency validation on the synchronized data.</li> <li>Choose the data handling method, either manual deletion or system deletion. This feature allows you to delete the source table after synchronization is completed.</li> </ol> <p></p> <p>Following these steps will enable you to configure a full job for cold data archiving, ensuring efficient and accurate data synchronization and archiving.</p>"},{"location":"whalealData/use%20cases/AddColdDataIncrementalJob/","title":"AddColdDataIncrementalJob","text":""},{"location":"whalealData/use%20cases/AddColdDataIncrementalJob/#adding-a-cold-data-incremental-job","title":"Adding a Cold Data Incremental Job","text":"<p>To set up an incremental job for cold data archiving, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>In the \"Cold Data Table Job\" page, click on the blue \"Add\" button to open the form.</li> <li>Fill out the form by selecting the data source table and file source for synchronization. Choose the archiving mode as \"Incremental Update\".</li> <li>Note that cold data archiving is applicable only to MongoDB data.</li> <li>For the incremental update mode, you need to fill in the SQL configuration. Click the blue \"Custom SQL\" button to open the table shown in the second image. Select the completion conditions and click \"Save\" to generate the SQL.</li> <li>The table job comes with consistency validation. Select \"Yes\" and specify the required validation percentage. After synchronization, the platform will perform consistency validation on the synchronized data.</li> <li>Choose the data handling method, either manual deletion or system deletion. This feature deletes the source table based on the configured batch.</li> </ol> <p></p> <p></p> <p>By following these steps, you can configure an incremental job for cold data archiving, enabling efficient and accurate synchronization of MongoDB data for archiving purposes.</p>"},{"location":"whalealData/use%20cases/AddDataSource/","title":"AddDataSource","text":""},{"location":"whalealData/use%20cases/AddDataSource/#adding-a-data-source","title":"Adding a Data Source","text":"<p>To add a new data source to the platform, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Data Source Management\".</li> <li>Click the blue \"Add\" button to open the form.</li> <li>Fill in the basic information for the new data source and click \"Test\". If you see a \"Test Passed\" message above, click \"Save\" to successfully add the data source. If the test fails, double-check the provided information for accuracy.</li> <li>After adding the data source, go to the \"System Management\" menu and select \"User Management\". Click on the user you want to bind the data source to.</li> <li>In the user details, select the added data source from the list and click \"Save\". This user will now have access to the newly added data source.</li> </ol> <p></p> <p></p> <p>By following these steps, you can easily add and configure new data sources, allowing users to access and utilize these sources for various operations within the Whaleal Data platform.</p>"},{"location":"whalealData/use%20cases/AddDestinationSource/","title":"AddDestinationSource","text":""},{"location":"whalealData/use%20cases/AddDestinationSource/#adding-a-target-source","title":"Adding a Target Source","text":"<p>To add a new target source to the platform, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Target Source Management\".</li> <li>Click the blue \"Add\" button to open the form.</li> <li>Fill in the basic information for the new target source and click \"Test\". If you see a \"Test Passed\" message above, click \"Save\" to successfully add the target source. If the test fails, double-check the provided information for accuracy.</li> <li>After adding the target source, go to the \"System Management\" menu and select \"User Management\". Click on the user you want to bind the target source to.</li> <li>In the user details, select the added target source from the list and click \"Save\". This user will now have access to the newly added target source.</li> </ol> <p></p> <p></p> <p>By following these steps, you can add and configure new target sources, allowing users to utilize these sources as destinations for data operations within the Whaleal Data platform.</p>"},{"location":"whalealData/use%20cases/AddS3FullLoadJob/","title":"AddS3FullLoadJob","text":""},{"location":"whalealData/use%20cases/AddS3FullLoadJob/#adding-an-s3-full-load-job","title":"Adding an S3 Full Load Job","text":"<p>To add a new S3 full load job to the platform, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>In the S3 Table Job page, click the blue \"Add\" button to open the form.</li> <li>Choose the data source database table and the target S3 bucket you want to synchronize. Ensure that the source endpoint is MongoDB's Gridfs data as the source for S3 synchronization.</li> <li>Select \"Full Load\" as the archive mode.</li> <li>The table job also includes data consistency verification. If you choose to enable it, you can set the required verification percentage. After the synchronization, the platform will perform data consistency checks on the synchronized data.</li> <li>Since S3 has the characteristic that files with the same name will overwrite the existing files, you can choose from synchronization modes like \"Replace without Handling\", \"Replace with Newest Files\", or \"ID + Filename\" mode.</li> <li>Choose a data processing method, either manual deletion or automatic deletion, after synchronization. The data source table will be deleted according to your choice after synchronization is completed.</li> </ol> <p></p> <p>By following these steps, you can create an S3 full load job that synchronizes data from a MongoDB Gridfs data source to a target S3 bucket. This allows for efficient management and synchronization of data between different storage systems within the Whaleal Data platform.</p>"},{"location":"whalealData/use%20cases/AddS3IncrementalJob/","title":"AddS3IncrementalJob","text":""},{"location":"whalealData/use%20cases/AddS3IncrementalJob/#adding-an-s3-incremental-load-job","title":"Adding an S3 Incremental Load Job","text":"<p>To add a new S3 incremental load job to the platform, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>In the S3 Table Job page, click the blue \"Add\" button to open the form.</li> <li>Choose the data source database table and the target S3 bucket you want to synchronize. Ensure that the source endpoint is MongoDB's Gridfs data as the source for S3 synchronization.</li> <li>Select \"Incremental Load\" as the archive mode.</li> <li>You'll need to provide SQL configuration since you're choosing incremental mode. Click the blue \"Custom SQL\" button to open the form for defining the SQL conditions.</li> <li>Set up the conditions for the incremental synchronization SQL in the form. After defining the conditions, click \"Save\" to generate the SQL.</li> <li>The table job also includes data consistency verification. If you choose to enable it, you can set the required verification percentage. After the synchronization, the platform will perform data consistency checks on the synchronized data.</li> <li>Since S3 has the characteristic that files with the same name will overwrite the existing files, you can choose from synchronization modes like \"Replace without Handling\", \"Replace with Newest Files\", or \"ID + Filename\" mode.</li> <li>Choose a data processing method, either manual deletion or automatic deletion, after synchronization. The data source table will be deleted according to your choice after synchronization is completed.</li> </ol> <p></p> <p></p> <p>By following these steps, you can create an S3 incremental load job that synchronizes data from a MongoDB Gridfs data source to a target S3 bucket using incremental synchronization based on defined SQL conditions. This allows for efficient and selective data synchronization within the Whaleal Data platform.</p>"},{"location":"whalealData/use%20cases/AddWarmDataFullLoadJob/","title":"AddWarmDataFullLoadJob","text":""},{"location":"whalealData/use%20cases/AddWarmDataFullLoadJob/#adding-a-warm-data-full-load-job","title":"Adding a Warm Data Full Load Job","text":"<p>To add a new warm data full load job to the platform, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>In the Warm Data Table Job page, click the blue \"Add\" button to open the form.</li> <li>Choose the data source database table and the target destination database table that you want to synchronize.</li> <li>Select \"Full Load\" as the archive mode.</li> <li>The warm data table job also includes data consistency verification. If you choose to enable it, you can set the required verification percentage. After the synchronization, the platform will perform data consistency checks on the synchronized data.</li> <li>For MySQL-related jobs, you can choose the isolation level for synchronization. For MongoDB to MongoDB synchronization, you can choose whether to sync Gridfs. If you choose \"No,\" the platform will only synchronize regular documents.</li> <li>Choose a data processing method, either manual deletion or automatic deletion, after synchronization. The data source table will be deleted according to your choice after synchronization is completed.</li> </ol> <p></p> <p>By following these steps, you can create a warm data full load job that synchronizes data from a data source database table to a target destination database table using full load mode. This allows for comprehensive synchronization of data within the Whaleal Data platform.</p>"},{"location":"whalealData/use%20cases/AddWarmDataIncrementalJob/","title":"AddWarmDataIncrementalJob","text":""},{"location":"whalealData/use%20cases/AddWarmDataIncrementalJob/#adding-a-warm-data-incremental-load-job","title":"Adding a Warm Data Incremental Load Job","text":"<p>To add a new warm data incremental load job to the platform, follow these steps:</p> <ol> <li>Click on the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>In the Warm Data Table Job page, click the blue \"Add\" button to open the form.</li> <li>Choose the data source database table and the target destination database table that you want to synchronize.</li> <li>Select \"Incremental Load\" as the archive mode.</li> <li>If you choose the incremental load mode, you need to fill in the SQL configuration. Click the blue \"Custom SQL\" button to open the form where you can select the completion conditions for the SQL. Click \"Save\" to generate the SQL.</li> <li>The warm data table job also includes data consistency verification. If you choose to enable it, you can set the required verification percentage. After the synchronization, the platform will perform data consistency checks on the synchronized data.</li> <li>For MySQL-related jobs, you can choose the isolation level for synchronization. For MongoDB to MongoDB synchronization, you can choose whether to sync Gridfs. If you choose \"No,\" the platform will only synchronize regular documents.</li> <li>Choose a data processing method, either manual deletion or automatic deletion, after synchronization. The data source table will be deleted according to your choice after synchronization is completed.</li> </ol> <p></p> <p>By following these steps, you can create a warm data incremental load job that synchronizes data from a data source database table to a target destination database table using incremental load mode. This allows for continuous synchronization of data within the Whaleal Data platform.</p>"},{"location":"whalealData/use%20cases/ColdDataFullTextSearch/","title":"ColdDataFullTextSearch","text":""},{"location":"whalealData/use%20cases/ColdDataFullTextSearch/#cold-data-full-text-search","title":"Cold Data Full-Text Search","text":"<p>To perform a full-text search on archived cold data, follow these steps:</p> <ol> <li>Click on the \"Archive Management\" menu and select \"File Full-Text Search\". This will display all file full-text search log information.</li> <li>Click the \"Create Search Task\" button to create a file full-text search task. The system will execute a global search on the files. For the files that match the search criteria, you can perform a file rollback operation.</li> </ol> <p></p>"},{"location":"whalealData/use%20cases/ColdDataFullTextSearch/#searching","title":"Searching","text":"<p>The green button on the top is the search button. The left-side filter options can be filled in as needed. After filling in the conditions, click the search button to filter the desired search content.</p>"},{"location":"whalealData/use%20cases/ColdDataFullTextSearch/#creating-a-search-task","title":"Creating a Search Task","text":"<p>Click the blue button to create a search task. This will open a form where you can enter the necessary details. After filling in the required information, click \"Confirm\".</p> <p></p> <p>By following these steps, you can search for archived cold data using the full-text search feature in the Whaleal Data platform. You can filter and retrieve specific files based on your search criteria and even perform file rollback operations as needed.</p>"},{"location":"whalealData/use%20cases/ColdDataWriteBack/","title":"ColdDataWriteBack","text":""},{"location":"whalealData/use%20cases/ColdDataWriteBack/#cold-data-rollback","title":"Cold Data Rollback","text":"<p>If there are issues with cold data archiving, you can perform a rollback operation. Here's how:</p> <ol> <li>Go to the \"Archive Management\" menu and select \"Log Query (Cold)\" under \"Cold Data\". This page displays the archived cold data tasks.</li> <li>Click on the \"File Rollback\" button to perform a rollback operation for a specific task. This action will roll back the archived file into the database.</li> </ol> <p></p> <p>After clicking the task, you will see a yellow \"File Rollback\" button next to it. Click this button to initiate the rollback process.</p> <p></p> <p>Creating a Rollback Task</p> <p>Clicking the \"File Rollback\" button will open a form. Fill in the required information and click \"Confirm\" to create the rollback task.</p> <p></p> <p>By following these steps, you can initiate a rollback operation for archived cold data files that need to be brought back into the database. This ensures that the data remains accessible and consistent within your system.</p>"},{"location":"whalealData/use%20cases/ColdWorkDemo/","title":"ColdWorkDemo","text":""},{"location":"whalealData/use%20cases/ColdWorkDemo/#cold-job-demo","title":"Cold Job Demo","text":"<p>Here's a step-by-step demonstration of how to create and manage a cold data archiving job in the platform:</p>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#1-add-data-source-and-file-source","title":"1. Add Data Source and File Source","text":""},{"location":"whalealData/use%20cases/ColdWorkDemo/#add-data-source","title":"Add Data Source","text":"<ol> <li>Go to the \"Configuration Management\" menu and select \"Data Source Management\".</li> <li>Click the blue \"Add\" button and fill in the required information for the data source. Test the connection and save it if the test is successful.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#add-file-source","title":"Add File Source","text":"<ol> <li>Go to the \"Configuration Management\" menu and select \"Target Source Management\".</li> <li>Click on \"Cold Data File Source\" and then click the blue \"Add\" button.</li> <li>Fill in the necessary information related to cold data archiving and save the file source.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#2-assign-permissions","title":"2. Assign Permissions","text":"<p>After adding the data source and file source, administrators need to assign database permissions in the \"User Management\" page under \"System Management\".</p> <p></p>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#3-create-a-cold-job","title":"3. Create a Cold Job","text":"<ol> <li>Go to the \"Configuration Management\" menu and select \"Table Job Configuration\".</li> <li>Click the blue \"Add\" button in the \"Cold Data Table Job\" section.</li> <li>Fill in the required information, including selecting the data source and file source.</li> <li>Optionally, configure data consistency validation and choose the data handling method after synchronization.</li> <li>Save the job configuration.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#4-create-a-task","title":"4. Create a Task","text":"<ol> <li>Click on the \"Task Configuration\" menu and then \"Cold Data Task Configuration\".</li> <li>Click the blue \"Add\" button to create a new task configuration.</li> <li>Fill in the necessary details according to your requirements.</li> <li>Optionally, configure execution mode, task timeout, retry attempts, and notification settings.</li> <li>Choose the notification strategy and add email addresses for alerts.</li> <li>Save the task configuration.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#add-table-jobs-to-the-task","title":"Add Table Jobs to the Task","text":"<ol> <li>Click \"Add Job\" to associate table jobs with the created task.</li> <li>Select the desired table jobs and click \"Confirm\" to add them to the task.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#admin-approval","title":"Admin Approval","text":"<ol> <li>After configuring the task, an administrator can review and approve it if needed.</li> <li>The task is ready for execution after approval.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#5-task-scheduling","title":"5. Task Scheduling","text":"<ol> <li>Navigate to the \"Task Management\" menu and select \"Task Scheduling\".</li> <li>Monitor the status of the task in this section.</li> <li>Click \"Execute Now\" to immediately execute the task.</li> </ol>"},{"location":"whalealData/use%20cases/ColdWorkDemo/#6-task-monitoring","title":"6. Task Monitoring","text":"<ol> <li>In the task scheduling section, you can monitor the execution status of the task.</li> <li>Visit the \"Task Monitoring (Cold)\" page to view the detailed execution status of the task.</li> </ol> <p>By following these steps, you can successfully create, configure, and manage cold data archiving jobs in the platform. This allows you to archive data from various sources and monitor the execution of tasks for data consistency and reliability.</p>"},{"location":"whalealData/use%20cases/CreateLoopTask/","title":"CreateLoopTask","text":""},{"location":"whalealData/use%20cases/CreateLoopTask/#creating-recurring-tasks","title":"Creating Recurring Tasks","text":"<p>Creating a recurring task is similar to creating a one-time task. The key difference is that you need to set the execution interval for the recurring task, which determines when the task will be executed again in the future. Here's how you can create and manage recurring tasks:</p> <ol> <li>Follow the same steps for creating a task configuration, just like you did for the one-time task.</li> <li>In the task configuration, set the execution mode to \"Recurring.\"</li> <li>Specify the execution interval, which determines how often the task will be repeated.</li> <li>Fill in the rest of the task configuration details and save the configuration.</li> </ol> <p>After configuring the recurring task, an administrator needs to review and approve it, just like with one-time tasks. Once the recurring task is approved, you can find it in the \"Task Scheduling\" section.</p> <p>To execute a recurring task:</p> <ol> <li>Navigate to the \"Task Management\" menu and select \"Task Scheduling.\"</li> <li>Locate the recurring task you want to execute.</li> <li>Click the \"Execute Now\" button next to the task. This will trigger the immediate execution of the task according to the predefined execution interval.</li> </ol> <p>By creating recurring tasks, you can automate data archiving and synchronization at regular intervals, ensuring that your data remains up-to-date and consistent over time.</p> <p></p>"},{"location":"whalealData/use%20cases/CreateManualTask/","title":"CreateManualTask","text":""},{"location":"whalealData/use%20cases/CreateManualTask/#creating-manual-tasks","title":"Creating Manual Tasks","text":"<p>Creating a manual task follows the same steps as creating a one-time task. The key difference with manual tasks is that they don't require setting an execution time, as they are intended to be triggered manually when needed. Here's how you can create and manage manual tasks:</p> <ol> <li>Begin by creating a task configuration, just as you did for the one-time task.</li> <li>In the task configuration, set the execution mode to \"Manual.\"</li> <li>Complete the rest of the task configuration details and save the configuration.</li> </ol> <p>Once the manual task is configured, it will be available for execution by authorized users. An administrator needs to review and approve the manual task, just like with other tasks, before it can be executed.</p> <p>To execute a manual task:</p> <ol> <li>Navigate to the \"Task Management\" menu and select \"Task Scheduling.\"</li> <li>Locate the manual task you want to execute.</li> <li>Click the \"Execute Now\" button next to the task. This will trigger the immediate execution of the task.</li> </ol> <p>Manual tasks are particularly useful when you want to perform specific data archiving or synchronization tasks on-demand, giving you full control over when these tasks are executed.</p> <p></p>"},{"location":"whalealData/use%20cases/CreateSingleTask/","title":"CreateSingleTask","text":""},{"location":"whalealData/use%20cases/CreateSingleTask/#creating-one-time-tasks","title":"Creating One-Time Tasks","text":"<p>To create a one-time task, follow these steps:</p> <ol> <li>Navigate to the \"Task Configuration\" menu and select \"Task Configuration.\"</li> <li>Click the blue \"New\" button to open the task creation form.</li> <li>In the task creation form (second image), select the task mode as \"One-Time.\"</li> <li>Choose a specific execution time using a Cron expression. Cron expressions allow you to define the exact date and time when the task should be executed.</li> <li>Configure other settings as needed, such as execution mode, task timeout, and retry attempts.</li> <li>Optionally, set up a notification strategy by adding email addresses for alerts. Notifications will be sent based on the chosen strategy after the task completes.</li> <li>Click the \"Add Job\" button to attach a job (table job) to the task. In the job configuration form (third image), select the desired job(s) to be associated with this task.</li> <li>Click \"OK\" or \"Confirm\" to save the task configuration.</li> </ol> <p>Please note that one-time tasks need to be reviewed and approved by an administrator before they can be executed. Once the task is approved, it will be scheduled for execution based on the specified time using the Cron expression.</p> <p>One-time tasks are suitable for tasks that need to be executed at a specific point in time, such as data synchronization or archiving activities that are scheduled to happen once.</p> <p></p> <p></p> <p></p>"},{"location":"whalealData/use%20cases/ManuallyDeleteSourceData/","title":"ManuallyDeleteSourceData","text":""},{"location":"whalealData/use%20cases/ManuallyDeleteSourceData/#manual-deletion-of-source-data","title":"Manual Deletion of Source Data","text":"<p>When configuring table jobs in the \"Table Job Configuration\" section under the \"Configuration Management\" menu, there's an option for \"Data Processing Method.\" By selecting \"Manual Deletion,\" along with providing a batch value, you can control how the source data is managed after archiving.</p> <ul> <li>If you choose \"Manual Deletion\" and set a batch value, the source data won't be automatically deleted after archiving is completed. Instead, it will be marked as archived with the specified batch value.</li> </ul> <p>To manually delete the source data after archiving:</p> <ol> <li>Go to the \"Task Monitoring (Cold)\" section.</li> <li>Find the task for which you want to delete the source data.</li> <li>Click on the task to view its details.</li> <li>Click \"Modify Source Table Data Status\" to change the status of the source table data.</li> <li>Alternatively, click \"Manual Deletion of Source Table Data\" to manually delete the source table data.</li> </ol> <p>This provides you with control over when and how the source data is deleted after archiving, allowing you to manage your data archiving process according to your specific needs.</p> <p></p>"},{"location":"whalealData/use%20cases/RetryAbnormalTask/","title":"RetryAbnormalTask","text":""},{"location":"whalealData/use%20cases/RetryAbnormalTask/#re-execution-of-failed-tasks","title":"Re-Execution of Failed Tasks","text":"<p>Under the \"Task Management\" menu, there are three sections for task monitoring: \"Completed,\" \"In Progress,\" and \"Exception.\" For tasks that have encountered exceptions or failures, you have the option to manually trigger a re-execution of these tasks.</p> <p>Here's how you can re-execute a failed task:</p> <ol> <li>Go to the \"Task Monitoring\" section.</li> <li>Click on the \"Exception\" tab to view tasks that encountered exceptions.</li> <li>Find the specific task you want to re-execute and click on it to view its details.</li> <li>Within the task details view, you'll find an option to \"Re-Execute.\" Clicking this option will initiate the re-execution process.</li> <li>The task will first be rolled back to its previous state, and then it will be re-executed.</li> </ol> <p>This functionality provides a way to address and resolve exceptions that may have occurred during task execution, allowing you to retry the task and ensure its successful completion.</p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/","title":"S3JobDemo","text":""},{"location":"whalealData/use%20cases/S3JobDemo/#s3-job-demo","title":"S3 Job Demo","text":""},{"location":"whalealData/use%20cases/S3JobDemo/#1-adding-data-source-and-target-s3","title":"1. Adding Data Source and Target S3","text":""},{"location":"whalealData/use%20cases/S3JobDemo/#adding-data-source","title":"Adding Data Source","text":"<p>Navigate to the \"Configuration Management\" menu and select \"Data Source Management.\" Click the blue \"Add\" button and provide the necessary information for the data source. After testing and confirmation, save the data source. </p>"},{"location":"whalealData/use%20cases/S3JobDemo/#adding-target-s3","title":"Adding Target S3","text":"<p>In the \"Configuration Management\" menu, select \"Target Source Management.\" Click on the S3 section, then click the blue \"Add\" button to provide the relevant information for the target S3. After successful testing, confirm and save the target S3. </p>"},{"location":"whalealData/use%20cases/S3JobDemo/#2-permission-assignment","title":"2. Permission Assignment","text":"<p>After adding the data source and target S3, the administrator can assign database permissions to users through the \"User Management\" page under the \"System Management\" menu.</p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/#3-creating-an-s3-job","title":"3. Creating an S3 Job","text":"<p>Navigate to the \"Configuration Management\" menu and select \"Table Job Configuration.\" On the S3 job configuration page, click the blue \"Add\" button to open the form. Choose the data source and target S3 you want to sync. The S3 job includes consistency verification, where you can set the required verification percentage. After synchronization, the platform will perform consistency checks on the synced data. You can also select the data handling method as either manual deletion or system deletion. After completion, the source table will be deleted according to batch numbers.</p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/#4-creating-a-task","title":"4. Creating a Task","text":""},{"location":"whalealData/use%20cases/S3JobDemo/#adding-a-task-configuration","title":"Adding a Task Configuration","text":"<p>Navigate to the \"Task Configuration\" menu and click the blue \"Add\" button to open the form. Fill in the required details based on your needs. If there are multiple jobs within the task, you can customize the execution mode, task timeout, and retry count. Select a notification strategy and add email addresses for notifications. After task completion, notifications will be sent based on the selected strategy.</p> <p></p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/#adding-table-jobs-to-the-task","title":"Adding Table Jobs to the Task","text":"<p>Click the \"Add Job\" button to select and add table jobs to the task. Once added, click \"Confirm\" to bind the jobs to the task. Multiple table jobs can be added to a single task.</p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/#administrator-approval","title":"Administrator Approval","text":"<p>After configuring the task, administrators can review and approve the task. Once approved, the task can be executed.</p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/#5-task-scheduling","title":"5. Task Scheduling","text":"<p>Navigate to the \"Task Scheduling\" menu and check the status of the tasks. Click \"Execute Now\" to initiate immediate execution of a task.</p> <p></p>"},{"location":"whalealData/use%20cases/S3JobDemo/#6-task-monitoring","title":"6. Task Monitoring","text":"<p>After executing or reaching the scheduled execution time, go to the \"Task Monitoring\" (S3) section under \"Task Management\" to view the status of the task.</p> <p></p>"},{"location":"whalealData/use%20cases/SMTPConfig/","title":"SMTPConfig","text":""},{"location":"whalealData/use%20cases/SMTPConfig/#smtp-email-configuration","title":"SMTP Email Configuration","text":"<p>To configure SMTP email settings, follow these steps:</p> <ol> <li>Click on the \"System Management\" menu and select \"System Settings.\" This page is only accessible to the administrator user. The page displays SMTP configuration options.</li> </ol> <p></p> <ol> <li> <p>Fill in the required information for the SMTP configuration, including SMTP server, port, username, password, sender email, and recipient email.</p> </li> <li> <p>After filling in the basic configuration, click the \"Test Connection\" button. If the test is successful and you receive a test email, the \"Save\" button will appear. Click on \"Save\" to save the SMTP configuration.</p> </li> </ol> <p>Once the SMTP configuration is saved, all task configuration alerts will be sent using the email settings provided in this configuration.</p> <p>Please note that proper SMTP configuration is essential for receiving alerts and notifications from the system. Make sure to verify the accuracy of the configuration before saving it.</p>"},{"location":"whalealData/use%20cases/SystemDeleteSourceData/","title":"SystemDeleteSourceData","text":""},{"location":"whalealData/use%20cases/SystemDeleteSourceData/#system-deletion-of-source-data","title":"System Deletion of Source Data","text":"<p>When configuring table jobs in the \"Table Job Configuration\" section under the \"Configuration Management\" menu, you have the option to choose the data processing method. If you select \"System Deletion,\" you will need to specify the batch value in the provided field. After the data archiving is completed, the system will automatically delete the source data based on the specified batch.</p> <p></p> <p>Please exercise caution when using system deletion, as it will permanently remove source data based on the batch value you provide. Make sure to verify your configuration settings before proceeding.</p>"},{"location":"whalealData/use%20cases/TaskExecutionMonitoring/","title":"TaskExecutionMonitoring","text":""},{"location":"whalealData/use%20cases/TaskExecutionMonitoring/#task-execution-monitoring","title":"Task Execution Monitoring","text":"<p>After clicking \"Execute Now\" on the task scheduling page or when the scheduled execution time is reached, different types of tasks will appear in different sections of the task monitoring page under the \"Task Management\" menu. For example, warm data tasks will appear in the \"Task Monitoring (Warm)\" section, cold data tasks will appear in the \"Task Monitoring (Cold)\" section, and so on. Each section provides information about the task's status, including \"Completed,\" \"In Progress,\" and \"Exception.\"</p> <p></p> <p>You can monitor the execution status of your tasks in the respective monitoring sections for warm, cold, and S3 data tasks.</p>"},{"location":"whalealData/use%20cases/UserLogin/","title":"UserLogin","text":""},{"location":"whalealData/use%20cases/UserLogin/#user-login","title":"User Login","text":"<p>To log in, enter the registered account credentials. For the first login of an administrator, the initial password is \"123456.\" After logging in, you will be prompted to change the password. Other registered users have user-level permissions. Administrator users can assign permissions to new users.</p> <p></p>"},{"location":"whalealData/use%20cases/UserRegistration/","title":"UserRegistration","text":""},{"location":"whalealData/use%20cases/UserRegistration/#user-registration","title":"User Registration","text":"<p>After accessing the homepage, there is an \"Register Now\" button located at the bottom right corner of the login section. Clicking this button will take you to the registration page as shown in the second image. Fill in the required registration information and click \"Register\" to complete the process.</p> <p></p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/","title":"WarmJobDemo","text":""},{"location":"whalealData/use%20cases/WarmJobDemo/#warm-job-demo","title":"Warm Job Demo","text":""},{"location":"whalealData/use%20cases/WarmJobDemo/#1-add-data-source-and-target-source","title":"1. Add Data Source and Target Source","text":""},{"location":"whalealData/use%20cases/WarmJobDemo/#add-data-source","title":"Add Data Source","text":"<p>Click on the \"Data Source Management\" page under the \"Configuration Management\" menu. On this page, click the blue \"Add\" button and fill in the relevant information for the data source. After passing the test, click \"Confirm\" to save this data source. </p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#add-target-source","title":"Add Target Source","text":"<p>Click on the \"Target Source Management\" page under the \"Configuration Management\" menu. On this page, click the blue \"Add\" button and fill in the relevant information for the target source. After passing the test, click \"Confirm\" to save this target source. </p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#2-permission-assignment","title":"2. Permission Assignment","text":"<p>After adding the data source and target source, the administrator user can assign database permissions to users on the \"User Management\" page under the \"System Management\" menu.</p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#3-create-warm-job","title":"3. Create Warm Job","text":"<p>Click on the \"Table Job Configuration\" under the \"Configuration Management\" menu. On the warm data table job page, click the blue \"Add\" button to open the following form. Choose the data source and target source you want to synchronize. Table jobs have consistency verification functionality. After selecting \"Yes,\" you can enter the desired verification percentage. After synchronization, the platform will perform consistency checks on the synchronized data. For MySQL-related jobs, you can choose the isolation level. When synchronizing from MongoDB to MongoDB, you can choose whether to synchronize Gridfs. If you choose \"No,\" the platform will only synchronize ordinary documents. The data processing mode can be selected as manual deletion or system deletion. This feature will delete the source table by batch after synchronization is completed.</p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#4-create-task","title":"4. Create Task","text":""},{"location":"whalealData/use%20cases/WarmJobDemo/#add-task-configuration","title":"Add Task Configuration","text":"<p>Click on the \"Task Configuration\" under the \"Task Configuration\" menu. This page displays all tasks. Click the blue \"Add\" button to open the form shown in the second image. Fill in the task configuration according to your needs. If there are many table jobs in this task, you can set the execution mode, task timeout, and failure retry times according to your needs. After selecting a reminder strategy, you can add email addresses for receiving alert notifications. After the task is completed, alerts will be sent via email according to the selected strategy. </p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#add-table-jobs-to-the-task","title":"Add Table Jobs to the Task","text":"<p>Click on \"Add Job\" to open the data configuration shown in the third image. Check the desired job and click \"OK\" to bind this job to the newly created task. A task can be bound to multiple table jobs.</p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#administrator-approval","title":"Administrator Approval","text":"<p>After configuring the task, the administrator user can review the task configuration. After approval, the task can be executed.</p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#5-task-scheduling","title":"5. Task Scheduling","text":"<p>Click on \"Task Scheduling\" under the \"Task Management\" menu to view the status of the task. Click \"Execute Now\" to immediately run the task.</p> <p></p>"},{"location":"whalealData/use%20cases/WarmJobDemo/#6-task-monitoring","title":"6. Task Monitoring","text":"<p>After clicking \"Execute Now\" on the task scheduling page or when the task execution time arrives, you can view the execution status of the task in the task monitoring (Warm) section under the \"Task Management\" menu.</p> <p></p>"},{"location":"whalealJMC/","title":"Index","text":"<p>whaleal</p>"}]}